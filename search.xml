<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>受限玻尔兹曼机</title>
      <link href="/2022/03/03/shou-xian-bo-er-zi-man-ji/"/>
      <url>/2022/03/03/shou-xian-bo-er-zi-man-ji/</url>
      
        <content type="html"><![CDATA[<h1>简介</h1><p>  受限玻尔兹曼机（英语：restricted Boltzmann machine, RBM）是一种可通过输入数据集学习概率分布的随机生成神经网络。受限玻兹曼机在降维、分类、协同过滤、特征学习和主题建模中得到了应用。根据任务的不同，受限玻兹曼机可以使用监督学习或无监督学习的方法进行训练。受限玻尔兹曼机是玻尔兹曼机(Boltzman machine，BM)的一种特殊拓扑结构。BM的原理起源于统计物理学，是一种基于能量函数的建模方法，能够描述变量之间的高阶相互作用，BM的学习算法较复杂，但所建模型和学习算法有比较完备的物理解释和严格的数理统计理论作基础。BM是一种对称耦合的随机反馈型二值单元神经网络，由可见层和多个隐层组成，网络节点分为可见单元(visible unit)和隐单元(hidden unit)，用可见单元和隐单元来表达随机网络与随机环境的学习模型，通过权值表达单元之间的相关性。正如名字所提示的那样，受限玻兹曼机是一种玻兹曼机的变体，但限定模型必须为二分图。模型中包含对应输入参数的输入（可见）单元和对应训练结果的隐单元，每条边必须连接一个可见单元和一个隐单元。（与此相对，“无限制”玻兹曼机包含隐单元间的边，使之成为递归神经网络。）这一限定使得相比一般玻兹曼机更高效的训练算法成为可能，特别是基于梯度的对比分歧（contrastive divergence）算法。受限玻兹曼机也可被用于深度学习网络。具体地，深度信念网络可使用多个RBM堆叠而成，并可使用梯度下降法和反向传播算法进行调优。</p><h1>结构</h1><p>  RBM可以说是所有神经网络中最简单的架构之一，属于两层神经网络，并且这些浅层神经网络是DBN（深度信念网络）的构建块。如下图所示，一个受限玻尔兹曼机包含一个输入层visible layer（第一层）和隐藏层hidden layer（第二层）。<br><img src="/2022/03/03/shou-xian-bo-er-zi-man-ji/1.png" alt="在这幅图片中"><br>  因为所有可见（或输入）节点的输入都被传递到所有的隐藏节点了，所以 RBM 可以被定义为对称二分图。对称意味着每个可见节点都与一个隐藏节点相连。二分则意味着它具有两部分，或者两层。图是一个数学术语，指的是由节点和边组成的网络。<br>  在每一个隐藏节点，每个输入 x 都与对应的权重 w 相乘。也就是说，一个输入 x 会拥有 12 个权重（4 个输入节点 × 3 个输出节点）。两层之间的权重总会形成一个矩阵，矩阵的行数等于输入节点的个数，列数等于输出节点的个数。每个隐藏节点会接收 4 个与对应权重相乘的输入。这些乘积的和再一次与偏置相加，并将结果馈送到激活函数中以作为隐藏单元的输出。<br>  如果这两层是更深网络的一部分，那么第一个隐藏层的输出会被传递到第二个隐藏层作为输入，从这里开始就可以有很多隐藏层，直到它们增加到最终的分类层。对于简单的前馈网络，RBM 节点起着自编码器的作用，除此之外，别无其它。<br><img src="/2022/03/03/shou-xian-bo-er-zi-man-ji/2.png" alt="在这幅图片中"></p><h1>能量模型</h1><p>  有些深度学习架构使用能量来衡量模型的质量，深度学习模型的目的之一是编码变量间的依赖关系。给变量的每种配置分配一个标量作为能量，可以描述这一依赖关系。能量较高意味着变量配置的兼容性不好。能量模型总是尝试最小化一个预先定义的能量函数。<br>  RBM的能量函数定义为：<br>$$ E(v,h) =  - \sum\limits_i { {a_i}{v_i} - \sum\limits_j { {b_j}{h_j} - \sum\limits_{i,j} { {v_i}{h_j}{w_{ij} } } } } $$<br>  由定义可知，能量函数的值取决于变量/输入状态、隐藏状态、权重和偏置的配置。RBM的训练包括为给定的输入值寻找使能量达到最小值的参数。</p><h1>能量模型</h1><p>  受限玻尔兹曼机是一个概率模型。这一模型并不分配离散值，而是分配概率。在每一时刻RBM位于一个特定的状态。该状态指输入层 $v$ 和隐藏层 $h$ 的神经元值。观察到 $v$ 和 $h$ 的特定状态的概率由以下联合分布给出：<br>$$<br>\begin{array}{l}<br>p(v,h) = \frac{1}{Z}{e^{ - E(v,h)} } \\<br>Z = \sum\limits_{v,h} { {e^{ - E(v,h)} } }<br>\end{array}<br>$$<br>  这里 $Z$ 被称为<b>配分函数</b>（partition function），该函数累加所有输入向量和隐藏向量的可能组合。<br>  在物理学中，这一联合分布称为玻尔兹曼分布，它给出一个微粒能够在能量 $E$ 的状态下被观测到的概率。就像在物理中一样，我们分配一个观测到状态 $v$ 和 $h$ 的概率，这一概率取决于整个模型的能量。不幸的是，由于配分函数 $Z$ 中 $v$ 和 $h$ 所有可能的组合数目十分巨大，计算这一联合分布十分困难。而给定状态 $v$ 计算状态 $h$ 的条件概率，以及给定状态 $h$ 计算状态 $v$ 的条件概率则要容易得多：<br>$$<br>\begin{array}{l}<br>p(h|v) = \prod\limits_i {p({h_i}|v)} \\<br>p(h|v) = \prod\limits_i {p({v_i}|h)}<br>\end{array}<br>$$<br>  RBM中的每个神经元只可能是二元状态0或1中的一种。我们最关心的因子是隐藏层或输入层地神经元位于状态1（激活）的概率。给定一个输入向量 $v$ ，单个隐藏神经元 $j$ 激活的概率为：<br>$$ p({h_j} = 1|v) = \frac{1}{ {1 + {e^{( - ({b_j} + {W_j}{v_i}))} } } } = \sigma ({b_j} + \sum\limits_i { {v_i}{w_{ij} } } ) $$<br>  其中， $\sigma$ 为sigmoid函数。以上等式可由对之前的条件概率等式应用贝叶斯定理推导得出，类似地，单个输入神经元 $i$ 为 1 的概率为：<br>$$<br>p({v_j} = 1|h) = \frac{1}{ {1 + {e^{( - ({a_i} + {W_i}{h_j}))} } } } = \sigma ({a_i} + \sum\limits_j { {h_j}{w_{ij} } } )<br>$$</p>]]></content>
      
      
      <categories>
          
          <category> 科研学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>差分隐私个人理解（一）</title>
      <link href="/2022/01/24/chai-fen-yin-si-ge-ren-li-jie-yi/"/>
      <url>/2022/01/24/chai-fen-yin-si-ge-ren-li-jie-yi/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> 科研学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 差分隐私、人工智能 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>内存管理（一）</title>
      <link href="/2021/04/12/nei-cun-guan-li-yi/"/>
      <url>/2021/04/12/nei-cun-guan-li-yi/</url>
      
        <content type="html"><![CDATA[<h1>内存管理概念</h1><h2 id="内存管理的基本原理和要求"><a class="header-anchor" href="#内存管理的基本原理和要求">¶</a>内存管理的基本原理和要求</h2><p>  内存管理就是操作系统对内存的管理和分配。<br>  内存管理的功能有：<br>  （1）<strong>内存空间的分配与回收</strong>：由操作系统完成主存储器空间的分配和管理。尤其是在编程时，可以提高编程效率。<br>  （2）<strong>地址转换</strong>：在多道程序环境下，程序中的逻辑地址与内存中的物理地址不可能一致，因此存储管理必须提供地址变换功能，把逻辑地址转换成相应的物理地址。<br>  （3）<strong>内存空间的扩充</strong>：利用虚拟存储技术或自动覆盖技术，从逻辑上扩充内存。<br>  （4）<strong>存储保护</strong>：保证各道作业在各自的存储空间内运行，互不干扰。</p><h3 id="程序装入和链接"><a class="header-anchor" href="#程序装入和链接">¶</a>程序装入和链接</h3><p>  创建进程首先要将程序和数据装入内存。将用户源程序变为可在内存中执行的程序，其主要经过以下几个步骤：<br>  （1）<strong>编译</strong>：由编译程序将用户源代码编译成若干目标模块<br>  （2）<strong>链接</strong>：由链接程序将编译后形成的一组目标模块及所需的库函数链接在一起，形成一个完整的装入模块。<br>  （3）<strong>装入</strong>：由装入程序将装入模块装入内存运行。<br><img src="/2021/04/12/nei-cun-guan-li-yi/1.png" alt="将用户程序变为可在内存中执行的程序的步骤"><br>  程序的链接有以下三种方式：<br>  （1）<strong>静态链接</strong>：在程序运行之前，先将各目标模块及它们所需的库函数链接成一个完整的可执行程序，以后不再拆开。<br>  （2）<strong>装入时动态链接</strong>：将用户源程序编译后所得到的一组目标模块，在装入内存时，采用边装入边链接的方式。<br>  （3）<strong>运行时动态链接</strong>：对某些目标模块的链接，是在程序执行中需要该目标模块时才进行的，其优点是便于修改和更新，便于实现对目标模块的共享。<br>  内存的装入模块在装入内存时，同样有以下三种方式：<br>  （1）<strong>绝对装入</strong>：在编译时，如果知道程序将驻留在内存的某个位置，编译程序将产生绝对地址的目标代码。绝对装入程序按照装入模块中的地址，将程序和数据装入内存。由于程序中的逻辑地址与实际内存地址完全相同，故不需对程序和数据的地址进行修改。<strong>绝对装入方式只适用于单道程序环境</strong>。另外，程序中所使用的绝对地址,可在编译或汇编时给出，也可由程序员直接赋予。而通常情况下在程序中采用的是符号地址，编译或汇编时再转换为绝对地址。<br><img src="/2021/04/12/nei-cun-guan-li-yi/2.png" alt="绝对装入方式"><br>  （2）<strong>可重定位装入</strong>：在多道程序环境下，多个目标模块的起始地址通常都是从$0$开始，程序中的其他地址都是相对于起始地址的,此时应采用可重定位装入方式。根据内存的当前情况，将装入模块装入到内存的适当位置。<strong>装入时对目标程序中指令和数据的修改过程称为重定位</strong>，地址变换通常是在装入时一次完成的，所以又称为静态重定位。静态重定位的特点是在一个作业装入内存时，必须分配其要求的全部内存空间，如果没有足够的内存，就不能装入该作业。此外，作业一旦进入内存后，在整个运行期间不能在内存中移动，也不能再申请内存空间。<br><img src="/2021/04/12/nei-cun-guan-li-yi/3.png" alt="可重装定位装入方式"><br>  （3）<strong>动态运行时装入</strong>：又称<strong>动态重定位</strong>，装入程序把装入模块装入内存后，并不立即把装入模块中的相对地址转化为绝对地址，而是推迟到程序要真正执行时才进行。因此，装入内存后的所有地址均为相对地址。这种方法需要一个<strong>重定位寄存器</strong>的支持。动态重定位有如下特点：**可以将程序分配到不连续的存储区中；在程序运行之前可以只装入它的部分代码即可投入运行，然后在程序运行期间，根据需要动态申请分配内；便于程序段的共享，可以向用户提供一个比存储空间大得多的地址空间。**如下图所示：<br><img src="/2021/04/12/nei-cun-guan-li-yi/4.png" alt="动态重定位"></p><h3 id="逻辑地址空间与物理地址空间"><a class="header-anchor" href="#逻辑地址空间与物理地址空间">¶</a>逻辑地址空间与物理地址空间</h3><p>  程序经过编译后，每个目标模块都是从$0$号单元开始编址，称为该目标模块的<strong>相对地址（或逻辑地址）</strong>。当链接程序将各个模块链接成一个完整的<font color="red"><strong>可执行目标程序</strong></font>时，链接程序顺序依次按各个模块的相对地址构成统一的从$0$号单元开始编址的<strong>逻辑地址空间</strong>。并且用户程序和程序员<font color="red"><strong>只需要知道逻辑地址而内存管理的具体机制则是完全透明的</strong></font>。<strong>不同进程可以有相同的逻辑地址，因为这些相同的逻辑地址可以映射到主存的不同位置</strong>。<br>  <font color="blue"><strong>物理地址空间</strong></font>是指内存中<strong>物理单元</strong>的集合，它是地址转换的最终地址，进程在运行时<strong>执行指令和访问数据</strong>都要通过物理地址从主存中存取。当装入程序将可执行代码装入内存时，<strong>必须通过地址转换将逻辑地址转换成物理地址</strong>，这个过程称为<font color="blue"><strong>地址重定位</strong></font>。</p><h3 id="内存保护"><a class="header-anchor" href="#内存保护">¶</a>内存保护</h3><p>  内存分配前，需要保护操作系统不受用户进程的影响，同时保护用户进程不受其他用户进程的影响。可以采取的两种内存保护的方法：<br>  （1）在$CPU$中设置一对<font color="blue"><strong>上、下限寄存器</strong></font>，存放用户在主存中的下限和上限地址，每当CPU要访问一个地址时，分别和两个寄存器的值相比，判断有无越界。<br>  （2）通过采用<font color="blue"><strong>重定位寄存器（基址寄存器）</strong></font>和<font color="blue"><strong>界地址寄存器（限长寄存器）</strong></font>来实现这种保护。重定位寄存器含最小的物理地址值，界地址寄存器含逻辑地址的最大值。每个逻辑地址值必须小于界地址寄存器，内存管理机构动态的将逻辑地址与界地址寄存器进行比较，如果未发生地址越界，则加上重定位寄存器的值后映射成物理地址，再送交内存单元。其中，<strong>界地址寄存器是用来与逻辑地址进行比较的，如果界地址寄存器中存储的逻辑地址的最大值小于逻辑地址，则未发生越界。而重定位寄存器是用来“加”的，逻辑地址加上重定位寄存器中的值就能得到物理地址</strong>。<br><img src="/2021/04/12/nei-cun-guan-li-yi/5.png" alt="重定位和界地址寄存器的硬件支持"></p><h2 id="覆盖与交换"><a class="header-anchor" href="#覆盖与交换">¶</a>覆盖与交换</h2><p>  在多道程序环境下，计算机的内存往往并不充裕，操作系统需要对内存进行管理，进行合理的划分和有效的动态分配，并且需要<strong>进行内存的扩充</strong>，而<font color="red"><strong>覆盖</strong></font>与<font color="red"><strong>交换</strong></font>这两种技术就是用来扩充内存的方法。</p><h3 id="覆盖"><a class="header-anchor" href="#覆盖">¶</a>覆盖</h3><p>  早期的计算机内存很小，经常会出现内存大小不够的情况。后来人们引入了覆盖技术，用来解决<strong>程序大小超过物理内存总和</strong>的问题。<br>  <strong>覆盖的基本思想</strong>：因为程序并非任何时候都要访问程序及数据各个部分，因此，将程序分为多个段（多个模块）。常用的段常驻内存，不常用的段在需要时调入内存。内存中分为一个<strong>固定区</strong>和若干个<strong>覆盖区</strong>。需要常驻内存的段放在<strong>固定区</strong>中，其余部分按调用关系分段，首先将那些即将要访问的段放入覆盖区，其他段放在外存中，在需要调用前，系统再将其调入覆盖区，替换覆盖区中原有的段。例如在下图中：该程序正文段所需要的内存空间是：<br>$$A(20KB) + B(50KB) + F(30KB) + C(30KB) + D(20KB) + E(40KB) = 190KB$$<br>但在采用了覆盖技术后，只需要空间：<br>$$A(20KB) + B(50KB) + E(40KB) = 110KB$$<br><img src="/2021/04/12/nei-cun-guan-li-yi/6.png" alt="覆盖技术示例图"><br>  覆盖技术的特点：（1）打破了必须将一个程序的全部信息装入主存后才能运行的限制。（2）当同时运行程序的代码量大于主存时仍不能运行。（3）内存中能够更新的地方只有覆盖区的段，不在覆盖区中的段会常驻内存。</p><h3 id="交换"><a class="header-anchor" href="#交换">¶</a>交换</h3><p>  <strong>交换（对换）技术的设计思想</strong>：内存空间紧张时，系统将内存中某些处于等待状态（或在$CPU$调度原则下被剥夺运行权利）的程序从内存移到外存，这一过程称为<strong>换出</strong>。把外存中某些已具备运行条件的进程换入内存（进程在内存与磁盘间动态调度）这一过程称为<strong>换入</strong>。那些被换出至外存的进程称为挂起状态，再根据换出之前进程所处的状态又可以分为<font color="blue"><strong>就绪挂起</strong></font>以及<font color="blue"><strong>阻塞挂起</strong></font>两种状态。在之前中提到的<strong>中级调度采用的就是交换技术</strong>。下面是进程各种状态之间的转化关系：<br><img src="/2021/04/12/nei-cun-guan-li-yi/7.png" alt="进程各状态之间的转换关系"><br>  交换需要注意的问题：（1）交换需要备份存储。（2）为了有效使用$CPU$，需要使每个进程的执行时间比交换时间长。（3）若换出进程，则必须保证该进程完全处于空闲状态。（4）交换空间通常作为磁盘的一整块，且独立于系统文件。（5）交换通常在有许多进程运行且内存空间吃紧时开始启动，而在系统负荷降低时暂停。<br>  <font color="red"><strong>交换技术主要在不同进程（或作业）中进行，而覆盖则用于同一个程序或进程中</strong></font>。现代操作系统是通过虚拟内存技术来解决覆盖技术对于用户和程序员不透明，主存无法存放用户程序的矛盾的。</p><h2 id="连续分配管理方式"><a class="header-anchor" href="#连续分配管理方式">¶</a>连续分配管理方式</h2><p>  连续分配方式是指为一个用户程序分配一个连续的内存空间，连续分配的方式主要包括<strong>单一连续分配</strong>、<strong>固定分区分配</strong>和<strong>动态分区分配</strong>。</p><h3 id="单一连续分配"><a class="header-anchor" href="#单一连续分配">¶</a>单一连续分配</h3><p>  </p>]]></content>
      
      
      <categories>
          
          <category> 课本学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 操作系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>进程管理（四）</title>
      <link href="/2021/04/07/jin-cheng-guan-li-si/"/>
      <url>/2021/04/07/jin-cheng-guan-li-si/</url>
      
        <content type="html"><![CDATA[<h1>死锁</h1><h2 id="死锁的概念"><a class="header-anchor" href="#死锁的概念">¶</a>死锁的概念</h2><h3 id="死锁的定义"><a class="header-anchor" href="#死锁的定义">¶</a>死锁的定义</h3><p>  在多道程序系统中，多个进程会并发执行，提高了处理器的吞吐量和资源的利用率。但是在多个进程的并发执行过程中，经常会出现死锁的问题，死锁就是：<strong>多个进程因竞争资源而造成的一种僵局（互相等待），若无外力作用，这些进程都将无法向前进行</strong>。</p><h3 id="死锁产生的原因"><a class="header-anchor" href="#死锁产生的原因">¶</a>死锁产生的原因</h3><h4 id="系统资源的竞争"><a class="header-anchor" href="#系统资源的竞争">¶</a>系统资源的竞争</h4><p>  通常系统拥有的不可剥夺的资源在数量上不足以满足多个进程运行的需求，使得进程在运行过程中，会因资源争夺而陷入僵局，例如：磁带、打印机等。只有对不可剥夺资源的竞争才可能产生死锁。</p><h4 id="进程推进顺序非法"><a class="header-anchor" href="#进程推进顺序非法">¶</a>进程推进顺序非法</h4><p>  （1）进程在运行过程中，请求和释放资源顺序不当，也会导致死锁。例如：并发进程$P_{1}, P_{2}$分别保持了资源$R_{1}, R_{2}$，而进程$P_{1}$申请资源$R_{2}$、进程$P_{2}$申请资源$R_{1}$时，两者都会因为所需资源被占用而阻塞。<br>  （2）信号量使用不当。<br>  （3）进程间彼此相互等待对方发来的消息，也会使得这些进程间无法继续向前推进。例如：进程$A$等待进程$B$发的消息，进程$B$也在等待进程$A$发送的消息，所以可以看出进程$A$和进程$B$不是因为竞争同一资源，而是等待对方的资源导致死锁。</p><h4 id="死锁产生的必要条件"><a class="header-anchor" href="#死锁产生的必要条件">¶</a>死锁产生的必要条件</h4><p>  死锁必须同时满足以下的$4$个条件，只要其中任意一个条件不成立，死锁就不会发生。<br>  （1）<strong>互斥条件</strong>：指进程对所分配到的资源进行排它性使用，即在一段时间内某资源只由一个进程占用。如果此时还有其它进程请求资源，则请求者只能等待，直至占有资源的进程用毕释放。<br>  （2）<strong>不剥夺条件</strong>：指进程已获得的资源，在未使用完之前，不能被剥夺，只能在使用完时由自己释放（主动释放）。<br>  （3）<strong>请求并保持条件</strong>：指进程已经保持至少一个资源，但又提出了新的资源请求，而该资源已被其它进程占有，此时请求进程阻塞，但又对自己已获得的其它资源保持不放。<br>  （4）<strong>循环等待条件</strong>：即存在一个等待队列：$P_{1}$占有$P_{2}$的资源，$P_{2}$占有$P_{3}$的资源，$P_{3}$占有$P_{1}$的资源。这样就形成了一个等待环路。若干进程之间形成一种头尾相接的循环等待资源关系。如下图所示：<br><img src="/2021/04/07/jin-cheng-guan-li-si/1.png" alt="循环等待示例图"></p><h2 id="死锁的处理策略"><a class="header-anchor" href="#死锁的处理策略">¶</a>死锁的处理策略</h2><p>  设法破坏产生死锁的$4$个必要条件之一，或者允许产生死锁，但是当死锁发生时有能力检测出死锁，并有能力实现恢复。</p><h3 id="死锁预防"><a class="header-anchor" href="#死锁预防">¶</a>死锁预防</h3><p>  <strong>通过设置一些限制条件，破坏死锁的四个必要条件中的一个或几个，让死锁无法发生</strong>。例如，将资源分层，得到上一层资源后才能够申请下一层资源，这样就破坏了循环等待条件。用户申请资源时，要求一次性申请所需要的全部资源，这就破坏了占有并等待条件。当一个已经占有某些不可剥夺资源的进程，请求新的资源而得不到满足时，它必须释放已经占有的所有资源，待以后需要时再重新申请，这就破坏了不剥夺条件。<br>  这些预防死锁的方法破坏了系统的并行性和并发性，通常会降低系统的效率。</p><h3 id="避免死锁"><a class="header-anchor" href="#避免死锁">¶</a>避免死锁</h3><p>  在资源的动态分配过程中，用某种方法防止系统进入不安全状态，从而避免死锁。<br>  预防死锁的几种策略，会严重地损害系统性能。因此在避免死锁时，要施加较弱的限制，从而获得较满意的系统性能。由于在避免死锁的策略中，允许进程动态地申请资源。因而，系统在进行资源分配之前预先计算资源分配的安全性。若此次分配不会导致系统进入不安全状态，则将资源分配给进程；否则，进程等待。其中最具有代表性的避免死锁算法是银行家算法。</p><h3 id="死锁的检测及解除"><a class="header-anchor" href="#死锁的检测及解除">¶</a>死锁的检测及解除</h3><p>  无须采取任何限制性措施，允许进程在运行过程中发生死锁。通过系统的检测机构及时地检测出死锁的发生，然后采取某种措施解除死锁。<br>  三种思索策略的比较如下表所示：<br><img src="/2021/04/07/jin-cheng-guan-li-si/2.png" alt="死锁处理策略的比较"></p><h2 id="死锁预防-v2"><a class="header-anchor" href="#死锁预防-v2">¶</a>死锁预防</h2><p>  只需要破坏死锁产生的$4$个必要条件之一即可。<br>  （1）<strong>破坏互斥条件</strong>：例如允许系统资源都能共享使用。但是这种方法不可行。<br>  （2）<strong>破坏不剥夺条件</strong>：当一个已保持了某些不可剥夺的进程请求新的资源而得不到满足时，它必须释放已经保持的所有资源，待以后需要时重新申请，但是这样会导致已获得的资源可能造成前一阶段工作的失效，同时反复的申请和释放资源会增加系统开销，降低系统吞吐量。<br>  （3）<strong>破坏请求并保持条件</strong>：采取预先静态分配方法，即进程在运行前一次申请完它所需要的全部资源，在他的资源未满足前，不投入运行，一旦投入运行，不再提出其他资源请求。但这样会导致系统资源被严重浪费。<br>  （4）<strong>破坏循环等待条件</strong>：将系统中的所有资源统一编号，进程可在任何时刻提出资源申请，但所有申请必须按照资源的编号顺序（升序）提出。这样做就能保证系统不出现死锁。这种方法存在的问题是，编号必须稳定，这就限制了新类型设备的增加，而且经常会发生作业使用资源的顺序与系统规定顺序不同，造成资源浪费。</p><h2 id="死锁避免"><a class="header-anchor" href="#死锁避免">¶</a>死锁避免</h2><p>  死锁避免同样属于事先预防策略，但是并不是事先采取某种限制措施破坏死锁的必要条件，而是在资源动态分配的过程中，防止系统进入不安全状态，以避免发生死锁。并且这种方法施加的限制条件比较弱，可以获得较好的系统性能。</p><h3 id="系统安全状态"><a class="header-anchor" href="#系统安全状态">¶</a>系统安全状态</h3><p>  安全状态是指系统按某种进程推进顺序$(P_{1},P_{2},P_{3},…,P_{n})$为每个进程$P_{i}$分配其所需的资源，直至满足每个进程对资源的最大需求，使每个进程都可顺序完成。此时称$(P_{1},P_{2},P_{3},…,P_{n})$为安全序列。若系统无法找到一个安全序列，则称系统处于不安全状态。<br>  例如系统中有三个进程$P_{1}$、$P_{2}$和$P_{3}$,共有$12$台磁带机。进程$P_{1}$总共需要$10$台磁带机，$P_{2}$和$P_{3}$ 分别需要$4$台和$9$台。假设在$T_{0}$时刻，进程$P_{1}$、$P_{2}$和$P_{3}$已分别获得$5$合、$2$台和$2$台，尚有$3$台未分配，见下表：<br><img src="/2021/04/07/jin-cheng-guan-li-si/3.png" alt="资源分配表"><br>  如果要满足各进程的最大进程，$p_{1}$差$5$台，$p_{2}$差$2$台，$p_{3}$差$7$台，当前可用资源只有$3$台。<br>  将所有进程推进顺序的情况一一列举：<br>  （1）$(P_{1}, P_{2}, P_{3})$，因为$3 &lt; 5$，$P_{1}$没法完成，不符合。<br>  （2）$(P_{1}, P_{3}, P_{2})$，因为$3 &lt; 5$，$P_{1}$没法完成，不符合。<br>  （3）$(P_{2}, P_{1}, P_{3})$，因为$3 &gt; 2$，$P_{2}$可以完成，$P_{2}$完成后释放资源，可用资源为$5$台，$5 = 5$，$P_{1}$可以完成；$P_{1}$完成后释放资源，可用资源为$10$台，$10 &gt; 7$，$P_{3}$可以完成；所有进程都可以完成，符合。<br>  （4）$(P_{2}, P_{3}, P_{1})$，因为$3 &gt; 2$，$P_{2}$可以完成；$P_{2}$完成后释放资源，可用资源为$5$台，$5 &lt; 7$，$P_{3}$没法完成，不符合。<br>  （5）$(P_{3}, P_{1}, P_{2})$，$3 &lt; 7$，$P_{3}$没法完成，不符合。<br>  （5）$(P_{3}, P_{2}, P_{1})$，$3 &lt; 7$，$P_{3}$没法完成，不符合。<br>  综上，存在一个安全序列$(P_{2}, P_{1}, P_{3})$，即只要系统按此进程序列分配资源，则每个进程都能顺利完成,此时系统便进入安全状态,否则进入不安全状态。</p><h3 id="银行家算法"><a class="header-anchor" href="#银行家算法">¶</a>银行家算法</h3><p>  在银行中，客户申请贷款的数量是有限的，每个客户在第一次申请贷款时要声明完成该项目所需的最大资金量，在满足所有贷款要求时，客户应及时归还。银行家在客户申请的贷款数量不超过自己拥有的最大值时，都应尽量满足客户的需要。<br>  因此银行家算法的思想是：把操作系统视为银行家，操作系统管理的资源相当于银行家管理的资金，进程向操作系统请求分配资源相当于用户向银行家贷款。操作系统按照银行家制定的规则为进程分配资源。进程运行之前先声明对各种资源的最大需求量，当进程在执行中继续申请资源时，先测试该进程已占用的资源数与本次申请的资源数之和是否超过该进程声明的最大需求量。若超过则拒绝分配资源，若未超过则再测试系统现存的资源能否满足该进程尚需的最大资源量，若能满足则按当前的申请量分配资源，否则也要推迟分配。</p><h4 id="银行家算法数据结构"><a class="header-anchor" href="#银行家算法数据结构">¶</a>银行家算法数据结构</h4><p>  为了实现银行家算法，在系统中必须设置这样四个数据结构，分别用来描述系统中可利用的资源、所有进程对资源的最大需求、系统中的资源分配，以及所有进程还需要多少资源的情况。<br>  （1）可利用资源向量$Available$。这是一个含有$m$个元素的数组，其中的每一个元素代表一类可利用的资源数目，其初始值是系统中所配置的该类全部可用资源的数目，其数值随该类资源的分配和回收而动态地改变。如果$Available[j] = K$，则表示系统中现$R_{j}$类资源$K$个。<br>  （2）最大需求矩阵$Max$。这是一个$n * m$的矩阵，它定义了系统中$n$个进程中的每个进程对$m$类资源的最大需求。如果$Max[i, j] = K$，则表示进程$i$需要$R_{j}$ 类资源的最大数目为$K$。<br>  （3）分配矩阵$Allocation$。这也是一个$n * m$的矩阵，它定义了系统中每一类资源当前已分配给每一进程的资源数。如果$Allocation[i, j] = K$，则表示进程$i$当前己分得$R_{j}$类资源的数目为$K$。<br>  （4）需求矩阵$Need$.这也是一个$n * m$的矩阵，用以表示每一个进程尚需的各类资源数。如果$Need[i, j] = K$，则表示进程$i$还需要$R_{j}$类资源$K$个方能完成其任务。<br>  上述三个矩阵间存在下述关系:<br>$$Need[i, j] = Max[i, j] - allocation[i, j]$$</p><h4 id="银行家算法描述"><a class="header-anchor" href="#银行家算法描述">¶</a>银行家算法描述</h4><p>  设$Request_{i}$是进程$P_{i}$的请求向量，如果$Requesti_{i}[j] = K$，表示进程$P_{i}$需要$K$个$R_{j}$类型的资源。当$P_{i}$发出资源请求后，系统按下述步骤进行检査:<br>  （1）如果$Request_{i}[j] ≤ Need[i, j]$便转向步骤$(2)$；否则认为出错，因为它所需要的资源数已超过它所宣布的最大值。<br>  （2）如果$Request_{i}[j] ≤ Available[j]$，便转向步骤$(3)$；否则，表示尚无足够资源，$P_{i}$须等待。<br>  （3）系统试探着把资源分配给进程$P_{i}$，并修改下面数据结构中的数值：<br>$$<br>　　Available[j] = Available[j] - Request_{i}[j];\\<br>　　Allocation[i, j] = Allocation[i, j] + Request_{i}[j]; \\<br>　　Need[i, j] = Need[i,j] - Request_{i}[j];<br>$$<br>  （4）系统执行安全性算法，检查此次资源分配后系统是否处于安全状态。若安全，才正式将资源分配给进程$P_{i}$，以完成本次分配；否则，将本次的试探分配作废，恢复原来的资源分配状态，让进程$P_{i}$等待。</p><h4 id="安全性算法"><a class="header-anchor" href="#安全性算法">¶</a>安全性算法</h4><p>  设置工作向量$Work$，它表示系统中的剩余可用资源数目，它含有$m$个元素，在执行安全算法开始时，$Work = Available$；<br>  （1）初始时安全序列为空。<br>  （2）从$Need$矩阵中找出符合下面条件的行：改行对应的进程不再安全序列中，而且该行小于等于$Work$向量，找到后，把对应的进程加入安全序列；若找不到，执行步骤$(4)$<br>  （3）进程$P_{i}$进入安全序列后，可顺利执行，直至完成，并释放分配给它的资源，因此应该执行$Work = Work + Allocation[i]$，其中$Allocatin[i]$表示进程$P_{i}$代表的在$Allocation$矩阵中对应的行，返回步骤$(2)$。<br>  （4）若此时安全序列中已有所有进程，则系统处于安全状态，否则系统处于不安全状态。</p><h2 id="死锁检测和解除"><a class="header-anchor" href="#死锁检测和解除">¶</a>死锁检测和解除</h2><p>  当系统为进程分配资源时，不采取任何措施，则应该提供死锁检测和解除手段。</p><h3 id="资源分配图"><a class="header-anchor" href="#资源分配图">¶</a>资源分配图</h3><p>  系统思索可利用资源分配图来描述，用圆圈代表一个进程，用框代表一类资源，因为一种类型的资源可能有多个，因此用框中的一个圆代表一类资源中的一个资源。从进程到资源的有向边称为<strong>请求边</strong>，表示该进程申请一个单位的该类资源；从资源到进程的边称为<strong>分配边</strong>，表示该类资源已有一个资源分配给了该进程。资源分配图如下图所示：<br><img src="/2021/04/07/jin-cheng-guan-li-si/4.png" alt="资源分配图实例"></p><h3 id="死锁定理"><a class="header-anchor" href="#死锁定理">¶</a>死锁定理</h3><p>  $S$为死锁的条件是当且仅当$S$状态的资源分配图是不可完全简化的，该条件为<strong>死锁定理</strong>。</p><h3 id="死锁解除"><a class="header-anchor" href="#死锁解除">¶</a>死锁解除</h3><p>  （1）<strong>资源剥夺法</strong>：挂起某些死锁进程，并抢占它的资源，将这些资源分配给其他的死锁进程。<br>  （2）<strong>撤销进程法</strong>：强制撤销部分甚至全部死锁进程，并剥夺这些进程的资源。撤销的原则可以按进程优先级和撤销进程代价的高低进行。<br>  （3）<strong>进程回退法</strong>：让一个或（多个）进程回退到足以回避死锁的地步，进程回退时自愿释放资源而非被剥夺。要求系统保持进程的历史信息，设置还原点。</p>]]></content>
      
      
      <categories>
          
          <category> 课本学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 操作系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>经典同步问题</title>
      <link href="/2021/04/06/jing-dian-tong-bu-wen-ti/"/>
      <url>/2021/04/06/jing-dian-tong-bu-wen-ti/</url>
      
        <content type="html"><![CDATA[<h1>经典同步动作</h1><h2 id="生产者-消费者问题"><a class="header-anchor" href="#生产者-消费者问题">¶</a>生产者-消费者问题</h2><p>  <strong>问题描述</strong>：一组生产者进程和一组消费者进程共享一个初始为空、大小为$n$的缓冲区，只有缓冲区没满时，生产者才能把消息放入缓冲区，否则必须等待；只有缓冲区不空时，消费者才能从中取出消息，否则必须等待。由于缓冲区是临界资源，它只允许一个生产者放入消息，或一个消费者从中取出消息。<br>  <strong>问题分析</strong>：<br>  （1）<strong>关系分析</strong>：生产者和消费者对缓冲区互斥访问是互斥关系，因为只有生产者生产之后，消费者才能消费，所以也存在同步关系。<br>  （2）<strong>整理思路</strong>：只有生产者和消费者，<strong>同时存在互斥关系和同步关系</strong>，所以相当于解决互斥和同步的$P/V$操作。<br>  （3）<strong>信号量设置</strong>：信号量$mutex$作为互斥信号量，用于控制互斥访问缓冲池，互斥信号量初值为$1$；信号量$full$用于记录当前缓冲池中的“满”缓冲区数，初值为$0$。信号量$empty$用于记录当前缓冲池中的“空”缓冲区数，初值为$n$。</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">semaphore mutex &#x3D; 1;                  &#x2F;&#x2F; 临界区互斥信号量semaphore empty &#x3D; n;                  &#x2F;&#x2F; 空闲缓冲区semaphore full &#x3D; 0;                   &#x2F;&#x2F; 缓冲区初始化为空producer() &#123;                          &#x2F;&#x2F; 生产者进程    while(1) &#123;        produce an item in nextp;     &#x2F;&#x2F; 生产数据        P(empty);                     &#x2F;&#x2F; 获取空缓冲区单元        P(mutex);                     &#x2F;&#x2F; 进入临界区        add nextp to buffer;          &#x2F;&#x2F; 将数据放入缓冲区        V(mutex);                     &#x2F;&#x2F; 离开临界区，释放互斥信号量        V(full);                      &#x2F;&#x2F; 满缓冲区数加1    &#125;&#125;consumer() &#123;                          &#x2F;&#x2F; 消费者进程    while(1) &#123;        P(full);                      &#x2F;&#x2F; 获取满缓冲区单元        P(mutex);                     &#x2F;&#x2F; 进入临界区        remove an item from buffer;   &#x2F;&#x2F; 从缓冲区中取出数据        V(mutex);                     &#x2F;&#x2F; 离开临界区，释放互斥信号量        V(empty);                     &#x2F;&#x2F; 空缓冲区数加1        consume the item;             &#x2F;&#x2F; 消费数据    &#125;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>  需要注意的是：（1）<strong>当缓冲区中有空时，便可对empty变量执行$P$操作，一旦取走一个产品便要执行$V$操作以释放空闲区</strong>。（2）<strong>对$empty$和$full$变量的操作必须放在对$mutex$的$P$操作之前</strong>。</p><h2 id="生产者-消费者问题（扩展）"><a class="header-anchor" href="#生产者-消费者问题（扩展）">¶</a>生产者-消费者问题（扩展）</h2><p>  <strong>问题描述</strong>：桌子上有一个盘子，每次只能向其中放一个水果。爸爸专门向盘子中放入苹果，妈妈专向盘子中放橘子，儿子专等吃盘子中的橘子，女儿专等吃盘子中的苹果。只有当盘子为空时，爸爸或妈妈才可向盘子中放一个水果；仅当盘子中有自己需要的水果时，儿子或女儿可以从盘子中取出。<br>  <strong>问题分析</strong>：<br>  <strong>关系分析</strong>：因为每次只能向其中放入一只水果可知，爸爸和妈妈是互斥关系。爸爸和女儿、妈妈和儿子是同步关系，而且这两对进程必须连起来，儿子和女儿之间没有互斥和同步关系，因此他们是选择条件执行，不可能并发。<br><img src="/2021/04/06/jing-dian-tong-bu-wen-ti/1.png" alt="进程之间的关系"><br>  <strong>整理思路</strong>：在这个问题中有四个进程，但是可抽象为两个生产者和消费者被连接到大小为$1$的缓冲区上。<br>  <strong>信号量设置</strong>：首先设置互斥信号量$plate$，表示是否允许向盘子中放入水果，初值为$1$表示允许放入且只允许放入一个。信号量$apple$表示盘子中是否有苹果，初值为$0$表示盘子为空且不允许取，为$1$则相反。信号量$orange$表示盘子中是否有橘子，初值为$0$表示盘子为空，不允许取，为$1$则相反。</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">semaphore plate&#x3D;l, apple&#x3D;0， orange&#x3D;0;dad() &#123;                               &#x2F;&#x2F; 父亲进程    while (1) &#123;        prepare an apple;        P(plate);                     &#x2F;&#x2F; 互斥向盘中取、放水果        put the apple on the plate;   &#x2F;&#x2F; 向盘中放苹果        V(apple);                     &#x2F;&#x2F; 允许取苹果    &#125;mom() &#123;                                &#x2F;&#x2F; 母亲进程    while (1) &#123;        prepare an orange;            &#x2F;&#x2F; 互斥向盘中取、放水果        P(plate);                     &#x2F;&#x2F; 向盘中放橘子        put the orange on the plate;  &#x2F;&#x2F; 允许取橘子        V(orange);    &#125;&#125;son() &#123;                               &#x2F;&#x2F; 儿子进程    while(1) &#123;        P(orange);                    &#x2F;&#x2F; 互斥向盘中取橘子        take an orange from the plate;&#x2F;&#x2F; 允许向盘中取、放水果        V(plate);        eat the orange;    &#125;&#125;daughter() &#123;                          &#x2F;&#x2F; 女儿进程    while(1) &#123;        P(apple);                     &#x2F;&#x2F; 互斥向盘中取苹果        take an apple from the plate;        V(plate);                     &#x2F;&#x2F; 运行向盘中取、放水果        eat the apple;    &#125;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>  在上面的进程中，$dad()$和$daughter()$、$mon()$和$son()$必须连续执行，儿子和女儿也必须在拿走水果后执行$V(plate)$操作。</p><h2 id="读者-写作问题"><a class="header-anchor" href="#读者-写作问题">¶</a>读者-写作问题</h2><p>  <strong>问题描述</strong>：有读者和写者两组并发进程，共享一个文件，当两个或两个以上的进程同时访问共享数据时不会产生副作用，但若某个写进程和其他进程（读进程和写进程）同时访问共享数据时，则可能导致数据不一致的错误。因此要求：（1）<strong>允许多个读者可以同时对文件执行读操作</strong>；（2）<strong>只允许一个写者往文件中写信息</strong>；（3）<strong>任一写者在写完成操作之前不允许其他读者或写者工作</strong>；（4）<strong>写者执行写操作，应让已有的读者和写者全部退出</strong>。<br><img src="/2021/04/06/jing-dian-tong-bu-wen-ti/2.png" alt="读写进程对文件的操作"><br>  <strong>问题分析</strong>：<br>  <strong>关系分析</strong>：在题目分析读者和写者是互斥的，写者和写者也是互斥的，读者和读者不存在互斥问题。<br>  <strong>整理思路</strong>：在这个问题中，有两个进程，读者和写者，写者比较简单，它和任何进程互斥，用互斥信号量的$P$操作、$V$操作即可解决。读者的问题比较复杂，它必须在实现与写者互斥的同时，实现与其他读者的同步，因此一对简单的$P$、$V$操作无法解决问题。这里就需要用到计数器，用来判断当前是否有读者读文件，当有读者时，写者是无法写文件的，此时读者会一只占用文件，当没有读者时，写者才可以写文件，同时，<strong>不同读者对计数器的访问也应该是互斥的</strong>。<br>  <strong>信号量设置</strong>：首先设置信号量$count$为计数器，用于记录当前读者的数量，初值为$0$，设置$mutex$为互斥信号量，用于保护更新$count$变量时的互斥，设置互斥信号量$rw$，用于保证读者和写者的互斥访问。</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">int count&#x3D;0;                         &#x2F;&#x2F; 用于记录当前的读者数量semaphore mutex&#x3D;1;                   &#x2F;&#x2F; 用于保护更新count变量时的互斥semaphore rw&#x3D;1;                      &#x2F;&#x2F; 用于保证读者和写者互斥地访问文件writer() &#123;                           &#x2F;&#x2F; 写者进程    while(1) &#123;        P(rw);                       &#x2F;&#x2F; 互斥访问共享文件        writing;                     &#x2F;&#x2F; 写入        V(rw);                       &#x2F;&#x2F; 释放共享文件    &#125;&#125;reader() &#123;    while(1) &#123;                       &#x2F;&#x2F; 读者进程        P(mutex);                    &#x2F;&#x2F; 互斥访问count变量        if(count &#x3D;&#x3D; 0) &#123;             &#x2F;&#x2F; 当第一一个读进程读共享文件时            P(rW);                   &#x2F;&#x2F; 阻止写进程写        &#125;        count++;                     &#x2F;&#x2F; 读者计数器加1        V(mutex);                    &#x2F;&#x2F; 释放互斥变量count        reading;                     &#x2F;&#x2F; 读取        P(mutex);                    &#x2F;&#x2F; 互斥访问count变量        count--;                     &#x2F;&#x2F; 读者计数器减1        if(count &#x3D;&#x3D; 0) &#123;             &#x2F;&#x2F; 当最后一个读进程读完共享文件            V(rw);                   &#x2F;&#x2F; 允许写进程写        &#125;        V(mutex);                    &#x2F;&#x2F; 释放互斥变量count    &#125;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>  上面的方法时读进程优先，只要存在一个读进程，写进程都需要等待，这种方式会导致写进程长时间等待，出现饿死现象。为了避免这种现象的产生，当有读进程正在读取共享文件时，有些进程请求访问，这时应禁止后续读进程的请求，等到已在共享文件的读进程执行完毕，立即让写进程执行，只有在无写进程执行的情况下，才允许读进程再次运行。</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">int count&#x3D;0;                              &#x2F;&#x2F; 用于记录当前的读者数量semaphore mutex&#x3D;1;                        &#x2F;&#x2F; 用于保护更新count变量时的互斥semaphore rw&#x3D;1 ;                          &#x2F;&#x2F; 用于保证读者和写者互斥地访问文件semaphore w&#x3D;1;                            &#x2F;&#x2F; 用于实现“写优先”writer() &#123;                                &#x2F;&#x2F; 写者进程    while(l) &#123;        P(w);                             &#x2F;&#x2F; 在无写进程请求时进入        P(rw);                            &#x2F;&#x2F; 互斥访问共享文件        writing;                          &#x2F;&#x2F; 写入        V(rw);                            &#x2F;&#x2F; 释放共享文件        V(w);                             &#x2F;&#x2F; 恢复对共享文件的访问    &#125;&#125;reader() &#123;                                &#x2F;&#x2F; 读者进程    while(1) &#123;        P(w);                             &#x2F;&#x2F; 在无写进程请求时进入        P(mutex);                         &#x2F;&#x2F; 互斥访问count变量        if(count &#x3D;&#x3D; 0) &#123;                  &#x2F;&#x2F; 当第一个读进程读共享文件时            P(rw);                        &#x2F;&#x2F; 阻止写进程写        &#125;        count++;                          &#x2F;&#x2F; 读者计数器加1        V(mutex);                         &#x2F;&#x2F; 释放互斥变量count        V(w);                             &#x2F;&#x2F; 恢复对共享文件的访问，如果在这里不即使回复对共享文件的访问，则会出现后续读进程无法同时与该进程读取文件，形成互斥，与实际情况不符        reading;                          &#x2F;&#x2F; 读取        P(mutex);                         &#x2F;&#x2F; 互斥访问count变量        count--;                          &#x2F;&#x2F; 读者计数器减1        if(count &#x3D;&#x3D; 0) &#123;                  &#x2F;&#x2F; 当最后一个读进程读完共享文件            V(rw);                        &#x2F;&#x2F; 允许写进程写        &#125;        V(mutex);                         &#x2F;&#x2F; 释放互斥变量count    &#125;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>  这个并不是一个完全的写操作优先的方式，因为当一个写进程访问文件时，若有一些读进程要求访问文件，后又另一个写进程请求访问文件，则当前访问文件的写进程结束对文件的写操作时，会是一个读进程而不是写进程占用文件。</p><h2 id="哲学家进餐问题"><a class="header-anchor" href="#哲学家进餐问题">¶</a>哲学家进餐问题</h2><p>  <strong>问题描述</strong>：一张圆桌边上坐着5名哲学家，每两秒哲学家之间的桌子上摆一根筷子，两根筷子中间是一碗米饭，哲学家们倾注毕生经历用于思考和进餐，哲学家在思考时，并不影响他人，只有当哲学家饥饿时，才试图拿起左、右两根筷子（一根一根的拿起）。若筷子已在他人手上，则需要等待。饥饿的哲学家只有同时拿到了两根筷子才可以开始进餐，进餐完毕后，放下筷子继续思考。具体样例如下图所示。<br><img src="/2021/04/06/jing-dian-tong-bu-wen-ti/3.png" alt="5名哲学家进餐"><br>  <strong>问题分析</strong>：<br>  <strong>关系分析</strong>：$5$名哲学家与左右邻居对其中间筷子的访问是互斥关系。<br>  <strong>整理思路</strong>：在这个问题中，存在$5$个进程，最关键的地方在于如何让一名哲学家拿到左右两根筷子而不造成死锁或饥饿现象。解决方法有两个：（1）让他们同时拿两根筷子。（2）对每个哲学家的动作制定规则，避免饥饿或死锁现象发生。<br>  <strong>信号量设置</strong>：定义互斥信号量数组$chopstick[5] = {1, 1, 1, 1, 1}$，用于对5个筷子的互斥访问，哲学家按照顺序编号为$0\sim4$，哲学家$i$左边筷子的编号为$i$，哲学家右边筷子的编号为$(i+1)$ % $5$。</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">semaphore chopstick[5] &#x3D; &#123;1, 1, 1, 1, 1&#125;; &#x2F;&#x2F; 定义信号量数组chopstick[5]，并初始化Pi() &#123;                                    &#x2F;&#x2F; i号哲学家的进程    do&#123;        P(chopstick[i]);                  &#x2F;&#x2F; 取左边筷子        P(chopstick[(i + 1) % 5]);        &#x2F;&#x2F; 取右边筷子        eat;                              &#x2F;&#x2F; 进餐        V(chopstick[i]);                  &#x2F;&#x2F; 放回左边筷子        V(chopstick[(i + 1) % 5]);        &#x2F;&#x2F; 放回右边筷子        think;                            &#x2F;&#x2F; 思考    &#125; while(1);&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>  该算法存在一下问题：当$5$名哲学家都想要进餐并分别拿起左边的筷子时（都恰好执行完$chopstick[i]$；），筷子已经被拿光，等到他们再想拿右边的筷子时（执行$wait(chopstick[i + 1] \% 5)$；）就全被阻塞，出现死锁。为了防止死锁发生，可对哲学家进行一些限制条件。比如：（1）至多允许4名哲学家同时进餐；（2）仅当一名哲学家左右两边的筷子都可用时，才允许他抓取筷子；（3）对哲学家顺序编号，要求奇数号哲学家先拿左边的筷子，然后拿右边的筷子，而偶数号哲学家刚好相反。</p><h3 id="采用第一种改进方法"><a class="header-anchor" href="#采用第一种改进方法">¶</a>采用第一种改进方法</h3><p>  设置一个初值为$4$的信号量$r$，只允许$4$个哲学家同时去拿左筷子，这样就能保证至少有一个哲学家可以就餐，不会出现饿死和死锁的现象。具体代码如下所示：</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">semaphore chopstick[5]&#x3D;&#123;1, 1, 1, 1, 1&#125;;semaphore r&#x3D;4;void pi(int i) &#123;    while(true) &#123;        P(r);                        &#x2F;&#x2F; 请求进餐        P(chopstick[i]);             &#x2F;&#x2F; 请求左手边的筷子        P(chopstick[(i+ 1) % 5]);    &#x2F;&#x2F; 请求右手边的筷子        eat();        V(chopstick[(i+1) mod 5]);   &#x2F;&#x2F; 释放右手边的筷子        V(chopstick[i);              &#x2F;&#x2F; 释放左手边的筷子        V(r);                        &#x2F;&#x2F; 释放信号量r        think();    &#125;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="采用第二种改进方法"><a class="header-anchor" href="#采用第二种改进方法">¶</a>采用第二种改进方法</h3><p>  利用信号量的保护机制实现。通过互斥信号量$mutex$对$eat()$之前取左侧和右侧筷子的操作进行保护，可以防止死锁的出现。</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">semaphore mutex &#x3D; 1;semaphore chopstick[5] &#x3D; &#123;1, 1, 1, 1, 1&#125;;void Pi(int i) &#123;    while(true) &#123;        P(mutex);        P(chopstick[i]);        P(chopstick[(i+ 1) % 5]);        V(mutex);        eat();        V(chopstick[(i+ 1) % 5]);        V(chopstick[i]);        think();    &#125;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="采用第三种改进方法"><a class="header-anchor" href="#采用第三种改进方法">¶</a>采用第三种改进方法</h3><p>  规定奇数号哲学家先拿左筷子再拿右筷子，而偶数号哲学家相反。按照下图，将是$2$，$3$号哲学家竞争$3$号筷子，$4$，$5$号哲学家竞争$5$号筷子。$1$号哲学家不需要竞争。最后总会有一个哲学家能获得两支筷子而进餐。<br><img src="/2021/04/06/jing-dian-tong-bu-wen-ti/4.png" alt="哲学家进餐编号示意图"></p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">semaphore chopstick[5] &#x3D; &#123;1, 1, 1, 1, 1&#125;;void philosopher(int i) &#123;    while(true) &#123;        if(i % 2 &#x3D;&#x3D; 0) &#123;       &#x2F;&#x2F; 偶数哲学家,先右后左            P(chopstick[(i + 1) % 5]);            P(chopstick[i]) ;            eat();            V(chopstick[i]);            V(chopstick[(i+ 1) % 5]);        &#125;        else &#123;                   &#x2F;&#x2F; 奇数哲学家，先左后右            P(chopstick[i]);            P(chopstick[(i + 1) % 5]);            eat();            V(chopstick[(i + 1) % 5]);            V(chopstick[i]);        &#125;    &#125;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="吸烟者问题"><a class="header-anchor" href="#吸烟者问题">¶</a>吸烟者问题</h2><p>  <strong>问题描述</strong>：假设一个系统有三个抽烟者进程和一个供应者进程，每个抽烟者不停地卷烟并抽调它，但是卷起来并抽调一支烟，抽烟者需要有：烟草、纸和胶水。三个抽烟者中，第一个拥有烟草，第二个拥有纸，第三个拥有胶水。供应者进程无限地提供三种材料。供应者每次将两种材料放在桌子上，拥有剩下那种材料的抽烟者卷一根烟并抽掉它，并给供应者一个信号告诉已完成，此时供应者就会将另外两种材料放到桌上，如此重复（让三个抽烟者轮流地抽烟）。<br>  <strong>问题分析</strong>：<br>  <strong>关系分析</strong>：在上述问题中，供应者与三个抽烟者是同步关系，抽烟者与抽烟者之间是互斥关系。<br>  <strong>整理思路</strong>：整体有$4$个进程。<br>  <strong>信号量设置</strong>：信号量$offer1$、$offer2$、$offer3$分别表示烟草和纸的组合，烟草和胶水的组合、纸和胶水组合。信号量$finish$用于互斥进行抽烟的动作。</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">int num&#x3D;0;               &#x2F;&#x2F; 存储随机数semaphore offer1 &#x3D; 0;      &#x2F;&#x2F; 定义信号量对应烟草和纸组合的资源semaphore offer2 &#x3D; 0;      &#x2F;&#x2F; 定义信号量对应烟草和胶水组合的资源semaphore offer3 &#x3D; 0;      &#x2F;&#x2F; 定义信号量对应纸和胶水组合的资源semaphore finish &#x3D; 0;      &#x2F;&#x2F; 定义信号量表示抽烟是否完成process P1() &#123;           &#x2F;&#x2F; 供应者    while(1) &#123;        num++;        num &#x3D; num % 3;        if(num &#x3D;&#x3D; 0) &#123;            V(offer1);   &#x2F;&#x2F; 提供烟草和纸        &#125;        else if (num &#x3D;&#x3D; 1) &#123;            V(offer2) ;  &#x2F;&#x2F; 提供烟草和胶水        &#125;        else &#123;            V(offer3);   &#x2F;&#x2F; 提供纸和胶水        &#125;        任意两种材料放在桌子上;        P(finish);    &#125;&#125;process P2 () &#123;          &#x2F;&#x2F; 拥有烟草者    while(1) &#123;        P(offer3);        拿纸和胶水，卷成烟，抽掉;        V(finish);    &#125;&#125;process P3() &#123;           &#x2F;&#x2F; 拥有纸者    while(1) &#123;        P(offer2);        拿烟草和胶水，卷成烟，抽掉;        V(finish);    &#125;&#125;process P4() &#123;           &#x2F;&#x2F; 拥有胶水者    while(1) &#123;        P(offerl);        拿烟草和纸，卷成烟，抽掉;        V(finish);    &#125;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="个人总结"><a class="header-anchor" href="#个人总结">¶</a>个人总结</h2><p>  （1）在解决进程同步问题中，首先是要理解所有进程之间的同步、互斥等关系，了解哪些进程之间是可以同时执行的，这样有利于在整体上把控解决方案。<br>  （2）信号量个数的设置往往与互斥进程数和进程执行条件有关。<br>  （3）了解$P/V$操作的具体含义，对解题会更加有益。<br>  （4）所写的代码并不是串行执行的，而是要具有并行的思想，多考虑如果这些进程同时发生会有什么样的影响。</p>]]></content>
      
      
      <categories>
          
          <category> 课本学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 操作系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>进程管理（三）</title>
      <link href="/2021/03/31/jin-cheng-guan-li-san/"/>
      <url>/2021/03/31/jin-cheng-guan-li-san/</url>
      
        <content type="html"><![CDATA[<h1>进程同步</h1><h2 id="进程同步的基本概念"><a class="header-anchor" href="#进程同步的基本概念">¶</a>进程同步的基本概念</h2><p>  并发执行的进程之间存在相互制约的关系，为了协调进程之间的相互制约关系，进入了进程同步的概念。例如在系统计算算式：$1+2*3$，其中乘法进程一定要在加法进程之前进行运算（在这里把加、乘运算比作进程），但是因为操作系统具有异步性，如果不加以制约，会出现运行顺序相反的情况。同时熟悉以下概念</p><h3 id="临界资源"><a class="header-anchor" href="#临界资源">¶</a>临界资源</h3><p>  在操作系统中，虽然多个进程可以共享系统中的各种资源，但其中许多资源一次只能为一个进程所用，将这些一次仅允许一个进程使用的资源称为<strong>临界资源</strong>，许多物理资源如打印机等都属于临界资源，一些变量、数据等都可以被若干进程共享，也属于临界资源。在每个进程中，访问临界资源的那段代码称为<strong>临界区</strong>。为了保证临界资源的正确使用，把其访问过程分为4个部分：<br>  （1）进入区：在进入区要检查可否进入临界区，若能进入临界区，则应设置正在访问临界区的标志，以阻止其他进程同时进入临界区。<br>  （2）临界区：访问临界资源的那段代码称。<br>  （3）退出区：将正在访问临界区的标志清除。<br>  （4）剩余区：代码中的剩余部分。</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">do &#123;    entry section     &#x2F;&#x2F; 进入区    critical section  &#x2F;&#x2F; 临界区    exit section      &#x2F;&#x2F; 退出区    remainder section &#x2F;&#x2F; 剩余区 &#125; while(true)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="同步"><a class="header-anchor" href="#同步">¶</a>同步</h3><p>  同步即直接制约关系，是指为完成某种任务而建立的两个或多个进程，这些进程因为需要在某些位置上协调它们的工作次序而等待、传递信息所产生的制约关系。</p><h3 id="互斥"><a class="header-anchor" href="#互斥">¶</a>互斥</h3><p>  互斥即间接制约关系，当一个进程进入临界区使用临界资源时，另一个进程必须等待，当占用临界资源的进程退出临界区后，另一进程才允许去访问此临界资源。为了禁止两个进程同时进入临界区，同步机制应遵循以下准则：<br>  （1）<strong>空闲让进</strong><br>  （2）<strong>忙则等待</strong><br>  （3）<strong>有限等待</strong>：对请求访问的进程，应保证能在有限时间内进入临界区。<br>  （4）<strong>让权等待</strong>：当进程不能进入临界区时，应立即释放处理器，防止进程忙等待。</p><h2 id="实现临界区互斥的基本方法"><a class="header-anchor" href="#实现临界区互斥的基本方法">¶</a>实现临界区互斥的基本方法</h2><h3 id="软件实现法"><a class="header-anchor" href="#软件实现法">¶</a>软件实现法</h3><p>  在进入区设置并检查一些标志来标明是否有进程在临界区中，若已有进程在临界区，则在进入临界区通过循环检查进行等待，进程离开临界区后则在退出区修改标志。</p><h4 id="单标志法"><a class="header-anchor" href="#单标志法">¶</a>单标志法</h4><p>  设置一个公用型整数变量turn，用于指示被允许进入临界区的进程编号，即若$turn = 0$，则允许$P_{0}$进程进入临界区。该算法可确保每次只允许一个进程进入临界区。但两个进程必须交替进入临界区。若某个进程不再进入临界区，则另一个进程也无法进入临界区，这样很容易造成资源利用不充分。该情况如下所示：<br>  $P_{0}$进程：</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">while(turn !&#x3D; 0);  &#x2F;&#x2F; 进入区critical section;  &#x2F;&#x2F; 临界区turn &#x3D; 1;          &#x2F;&#x2F; 退出区remainder section; &#x2F;&#x2F; 剩余区 <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>  $P_{1}$进程：</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">while(turn !&#x3D; 1);  &#x2F;&#x2F; 进入区critical section;  &#x2F;&#x2F; 临界区turn &#x3D; 0;          &#x2F;&#x2F; 退出区remainder section; &#x2F;&#x2F; 剩余区 <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>  若$P_{0}$顺利进入临界区并从临界区离开，则此时临界区是空闲的，但$P_{1}$并没有进入临界区的打算，$turn = 1$一直成立，$P_{0}$就无法再次进入临界区（一直被while循环困住）。</p><h4 id="双标志法先检查"><a class="header-anchor" href="#双标志法先检查">¶</a>双标志法先检查</h4><p>  基本思想是在每个进程访问临界区资源之前，先查看临界资源是否正被访问，若正在被访问，该进程需等待；否则，进程才进入自己的临界区。因此，设置一个数据$flag[i]$,如果第$i$个元素值为$FALSE$，表示$P_{i}$进程未进入临界区，值为$TRUE$，表示$P_{i}$进程进入临界区。例如下面的代码表示：<br>  $P_{i}$进程：</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">while(flag[j]);      &#x2F;&#x2F; 进入区  （1）flag[i] &#x3D; TRUE;      &#x2F;&#x2F; 进入区  （3）critical section;    &#x2F;&#x2F; 临界区flag[i] &#x3D; FALSE;     &#x2F;&#x2F; 退出区remainder section;   &#x2F;&#x2F; 剩余区 <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>  $P_{j}$进程：</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">while(flag[i]);      &#x2F;&#x2F; 进入区  （2）flag[j] &#x3D; TRUE;      &#x2F;&#x2F; 进入区  （3）critical section;    &#x2F;&#x2F; 临界区flag[j] &#x3D; FALSE;     &#x2F;&#x2F; 退出区remainder section;   &#x2F;&#x2F; 剩余区 <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>  这样做的优点是：<strong>不用交替进入，可连续使用</strong>。<br>  缺点是：$P_{i}$和$P_{j}$可能同时进入临界区。当两个进程都没有进入时，$flag[i]$和$flag[j]$全部为$FALSE$，上述算法按照（1）（2）（3）（4）执行时，会同时进入临界区（违背了“忙则等待”）。即在检查对方的$flag$后和切换自己的$flag$前有一段时间，结果都检查通过。这里的问题出在检查和修改操作不能一次进行。</p><h4 id="双标志法后检查"><a class="header-anchor" href="#双标志法后检查">¶</a>双标志法后检查</h4><p>  与<strong>双标志法先检查</strong>不同的是，该算法先将自己的标志设置为$TRUE$，再检测对方的状态标志，若对方标志为$TRUE$，则进程等待；否则进入临界区。<br>  $P_{i}$进程：</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">flag[i] &#x3D; TRUE;      &#x2F;&#x2F; 进入区  while(flag[j]);      &#x2F;&#x2F; 进入区  critical section;    &#x2F;&#x2F; 临界区flag[i] &#x3D; FALSE;     &#x2F;&#x2F; 退出区remainder section;   &#x2F;&#x2F; 剩余区 <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>  $P_{j}$进程：</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">flag[j] &#x3D; TRUE;      &#x2F;&#x2F; 进入区  while(flag[i]);      &#x2F;&#x2F; 进入区  critical section;    &#x2F;&#x2F; 临界区flag[j] &#x3D; FALSE;     &#x2F;&#x2F; 退出区remainder section;   &#x2F;&#x2F; 剩余区 <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>  在这种情况下，可能会发生两个进程同时都想进入临界区时，它们分别将自己的标志值$flag$设置为$TRUE$，并且同时检测对方的状态（执行$while$语句），发现对方也要进入临界区时，双方互相谦让，结果两个进程都无法进入临界区，从而导致“饥饿”现象。</p><h4 id="Peterson’s-Algorithm"><a class="header-anchor" href="#Peterson’s-Algorithm">¶</a>Peterson’s Algorithm</h4><p>  为了防止两个进程为进入临界区而无限期等待，又设置了变量$turn$，每个进程在先设置自己的标志后再设置$turn$标志。这时，再同时检测另一个进程状态标志和不允许进入标志，以便保证两个进程同时要求进入临界区时，只允许一个进程进入临界区。<br>  $P_{i}$进程：</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">flag[i] &#x3D; TRUE; turn &#x3D; j;      &#x2F;&#x2F; 进入区  while(flag[j] &amp;&amp; turn &#x3D;&#x3D; j);   &#x2F;&#x2F; 进入区  critical section;              &#x2F;&#x2F; 临界区flag[i] &#x3D; FALSE;               &#x2F;&#x2F; 退出区remainder section;             &#x2F;&#x2F; 剩余区 <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>  $P_{j}$进程：</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">flag[j] &#x3D; TRUE; turn &#x3D; i;      &#x2F;&#x2F; 进入区  while(flag[i] &amp;&amp; turn &#x3D;&#x3D; i);   &#x2F;&#x2F; 进入区  critical section;              &#x2F;&#x2F; 临界区flag[j] &#x3D; FALSE;               &#x2F;&#x2F; 退出区remainder section;             &#x2F;&#x2F; 剩余区 <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>  当进程$P_{i}$设置$flag[i] = true$时，就表示该进程想要进入临界区，同时$turn = j$，此时进程$P_{j}$已在临界区中，符合进程$P_{i}$中的循环条件，所以$P_{i}$不能进入临界区。若$P_{j}$不想要进入临界区，即$flag[i] = false$,循环条件不符合，则$P_{i}$可以顺利进入，反之亦然。</p><h3 id="硬件实现方法"><a class="header-anchor" href="#硬件实现方法">¶</a>硬件实现方法</h3><p>  计算机提供了特殊的硬件指令，允许对一个字中的内容进行检测和修正，或对两个字的内容进行交换。通过硬件支持实现临界段问题的方法称为<strong>低级方法</strong>，或者<strong>元方法</strong>。</p><h4 id="中断屏蔽方法"><a class="header-anchor" href="#中断屏蔽方法">¶</a>中断屏蔽方法</h4><p>  当一个进程正在使用处理机执行它的临界区代码时，防止其他进程进入其临界区进行访问的最简方法是，禁止一切中断发生，或称之为屏蔽中断、关中断。因为CPU只发生在中断时引起进程切换，因此屏蔽中断能够保证当前允许的进程让临界区代码顺利地执行完，进而保证互斥的正确实现，然后执行开中断。其典型模式为：</p><pre class="line-numbers language-none"><code class="language-none">...关中断临界区开中断...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>  但是<strong>这种方法限制了处理机交替执行程序的能力，因此执行的效率会明显降低</strong>。对内核来说，在它执行更新变量或列表的几条指令期间，关中断是很方便的，但关中断的权力交给用户则很不明智，若一个进程关中断后不再开中断，则系统可能会因此终止。</p><h4 id="硬件指令方法"><a class="header-anchor" href="#硬件指令方法">¶</a>硬件指令方法</h4><p>  $TestAndSet$指令：这条指令为原子操作，即执行代码时不允许被中断，其功能是读出指定标志后把该标志设置为真。具体指令功能如下：</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">boolean TestAndSet(boolean *lock) &#123;    boolean old;    old &#x3D; *lock;    *lock &#x3D; true;    return old;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>  为每个临界资源设置一个共享变量$lock$，表示资源的两种状态：$ture$表示正在被占用，其初值为$false$。在进程访问临界资源之前，利用$TsetAndSet$检查和修改标志$lock$；若有进程在临界区，则重复检查，直到退出进程，利用该指令实现进程互斥算法描述如下：</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">while TestAndSet(&amp;lock);&#x2F;&#x2F; 进程的临界区代码段lock &#x3D; false;&#x2F;&#x2F; 进程的其他代码<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>  $Swap$指令：功能是交换两个字（字节）的内容，具体功能描述如下:</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">Swap(boolean *a, boolean *b) &#123;    boolean temp;    temp &#x3D; *a;    a* &#x3D; *b;    *b &#x3D; temp;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>  <strong>上述两个指令的描述仅是功能实现，而并非软件实现的定义，真正是由硬件逻辑直接实现的，不会被中断</strong>。利用$Swap$指令实现进程互斥的算法描述如下：</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">key &#x3D; true;while(key !&#x3D; false) &#123;    Swap(&amp;lock, &amp;key);&#125;&#x2F;&#x2F; 进程的临界区代码段lock &#x3D; false;&#x2F;&#x2F; 进程的其他代码<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>  为每个临界资源设置一个变量$lock$，初值为$false$；在每个进程中再设置一个局部布尔变量$key$，用于与$lock$交换信息。在进入临界区前，先利用$Swap$指令交换$lock$与$key$的内容，然后检查$key$的状态；有进程在临界区时，重复交换和检查过程，直到进程退出。</p><p>  硬件方法的优点是：（1）适用于任意数目的进程，不管是单处理机还是多处理机.（2）简单，容易验证其正确性。（3）支持进程内有多个临界区，只需要为每个临界区设立一个布尔值变量。<br>  但是其任然存在缺点：（1）进程等待进入临界区时要耗费处理机时间，不能实现让权等待。（2）从等待进程中随机选择一个进入临界区，有的进程可能一直选不上，从而导致“饥饿”现象。</p><h2 id="信号量"><a class="header-anchor" href="#信号量">¶</a>信号量</h2><p>  信号量机制是一种功能较强的机制，可以用来解决互斥与同步问题，只能被两个原语“$P$操作”和“$V$操作”访问。<strong>原语是指完成某种功能且不被分割，不被中断执行的操作序列</strong>，通常由硬件实现。该特性在单处理机上可由软件通过屏蔽中断方法实现。<strong>原语之所以不能被中断执行，是因为原语对变量的操作过程若被打断，可能会去允许另一个对同一变量的操作过程。从而出现临界段问题</strong>。</p><h3 id="整型信号量"><a class="header-anchor" href="#整型信号量">¶</a>整型信号量</h3><p>  整型信号量被定义为一个用于表示资源数目的整型量$S$，$wait$和$signal$操作可描述为</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">wait(S) &#123;    while(S &lt;&#x3D; 0);    S &#x3D; S - 1;&#125;signal(S) &#123;    S &#x3D; S + 1;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>  $wait$操作中，只要信号量$S &lt;= 0$，就会不断测试，因此一直使进程处于“忙等状态”。</p><h3 id="记录型信号量"><a class="header-anchor" href="#记录型信号量">¶</a>记录型信号量</h3><p>  记录型信号量是不存在“忙等”现象的进程同步机制。除需要一个用于代表资源数目的整型变量$value$外，再增加一个进程链表$L$，用于链接所有等待该资源的进程。其结构体如下：</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">typedef struct &#123;    int value;    struct process *L;&#125; semaphore;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>  相应的$wait$和$signal$操作如下：</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">void wait(semaphore S) &#123;     &#x2F;&#x2F; 相当于申请资源    S.value--;    if(S.value &lt; 0) &#123;        add this process to S.L;        block(S.L);    &#125;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>  在$wait$操作中，$S.value–$表示进程请求一个该类资源，当$S.value &lt; 0$时，表示该资源已分配完毕，因此进程应调用$block$原语，进行自我阻塞，放弃处理机，并插入该类资源的等待队列$S.L$。</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">void signal(semaphore S) &#123;   &#x2F;&#x2F;相当于释放资源    S.value++;    if(S.value &lt;&#x3D; 0) &#123;        remove a process P from S.L;        wakeup(P);    &#125;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>  $signal$操作，表示释放一个资源，使系统中可供分配的该类资源数增$1$，因此有$S.value++$。若加$1$后仍是$S.value &lt;= 0$，则表示在$S.L$中仍有等待该资源的进程被阻塞，因此还应调用$wakeup$原语，将$S.L$中的第一个等待进程唤醒。</p><h3 id="利用信号量实现同步"><a class="header-anchor" href="#利用信号量实现同步">¶</a>利用信号量实现同步</h3><p>  信号量机制能用于解决进程间的各种同步问题。设$S$为实现进程$P_{1}$和$P_{2}$同步的公共信号量，初值为$0$。<strong>进程$P_{2}$中的语句$y$要使用进程$P_{1}$中语句$x$的允许结果，所以只有当语句$x$执行完成之后，语句$y$才可以执行</strong>。</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">semaphore S &#x3D; 0;     &#x2F;&#x2F; 初始化信号量P1() &#123;    sqrt(10000);    x;               &#x2F;&#x2F; 语句x    V(s)             &#x2F;&#x2F; 告诉进程P2，语句 x 已经完成    ...&#125;P2() &#123;    ...    P(S);            &#x2F;&#x2F; 检查语句 x 是否运行完成    y;               &#x2F;&#x2F; 检查无误， 运行 y 语句    ...&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>  若$P_{2}$先执行到$P(S)$时，$S$为$0$，执行$P$操作会把进程$P_{2}$阻塞，并放入阻塞队列，当进程$P_{1}$中的$x$执行完后，执行$V$操作，把$P_{2}$从阻塞队列中放回就绪队列，当$P_{2}$得到处理机时，就继续执行。</p><h3 id="利用信号量实现进程互斥"><a class="header-anchor" href="#利用信号量实现进程互斥">¶</a>利用信号量实现进程互斥</h3><p>  设$S$为实现进程$P_{1}$，$P_{2}$互斥的信号量，由于每次只允许一个进程进入临界区，所以$S$的初值应为$1$（即资源可用数为$1$）。只需要把临界区置于$P(S)$和$V(S)$之间，即可实现两个进程对临界区的互斥访问。</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">semaphore S &#x3D; 1;          &#x2F;&#x2F; 初始化信号量P1() &#123;    ...    P(S);                 &#x2F;&#x2F; 准备开始访问临界资源，加锁    进程 P1 的临界区       V(S);                 &#x2F;&#x2F; 访问结束，解锁    ...&#125;P2() &#123;    ...    P(S);                 &#x2F;&#x2F; 准备开始访问临界资源，加锁    进程 P2 的临界区    V(S);                 &#x2F;&#x2F; 访问结束，解锁&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>  当没有进程在临界区时，任意一个进程要进入临界区，就要执行$P$操作，把$S$的值减为$0$，然后进入临界区；当有进程存在于临界区时，$S$的值为$0$，在有进程要进入临界区，执行$P$操作时将会被阻塞，直至在临界区中的进程退出，这样便实现了临界区的互斥。</p><h3 id="信号量实现前驱关系"><a class="header-anchor" href="#信号量实现前驱关系">¶</a>信号量实现前驱关系</h3><h2 id="管程"><a class="header-anchor" href="#管程">¶</a>管程</h2><p>  在信号量机制中，每个要访问临界资源的进程都必须自备同步的$PV$操作，大量分散的同步操作给系统管理带来了麻烦，且容易因同步操作不当而导致系统死锁。于是产生了一种新的进程同步工具——管程，降低了思索发生的可能性。</p><h3 id="管程的定义"><a class="header-anchor" href="#管程的定义">¶</a>管程的定义</h3><p>  系统中的各种硬件资源和软件资源，均可用数据接结构抽象地描述其资源特性。利用共享数据结构抽象地表示系统中的共享资源，而把对数据结构实施的操作定义为一组过程。进程对共享资源的申请、释放等操作，都通过这组过程来实现，这组过程还可以根据资源情况，或接受或阻塞进程的访问，实现进程互斥。<strong>这个代表共享数据结构，以及由对该共享数据结构实施操作的一组过程所组成的资源管理程序，称为管程</strong>。因此管程由以下$4$部分组成：<br>  （1）管程的名称<br>  （2）局部于管程内部的共享结构数据说明。<br>  （3）对该数据结构进行操作的一组过程（或函数）<br>  （4）对局部于管程内部的共享数据设置初始值的语句。</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">monitor Demo &#123; &#x2F;&#x2F; 定义一个名称为“Demo”的管程    &#x2F;&#x2F; 定义共享数据结构，对应系统中的某种共享资源    &#x2F;&#x2F; 共享数据结构 S；    &#x2F;&#x2F; 对共享数据结构初始化的语句    init_code() &#123;        S &#x3D; 5;     &#x2F;&#x2F; 初始资源数等于 5    &#125;    &#x2F;&#x2F; 过程 1：申请一个资源    take_away() &#123;        &#x2F;&#x2F; 对共享数据结构的 x 的一系列处理        S--;       &#x2F;&#x2F; 可用资源数 -1        ...    &#125;    &#x2F;&#x2F; 过程 2：归还一个资源    give_back() &#123;        &#x2F;&#x2F; 对共享数据结构 x 的一系列处理；        S++;       &#x2F;&#x2F; 可用资源数 +1        ...    &#125;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>  管程很像面向对象程序设计中的一个类，<strong>会把所有的共享资源的操作封装起来</strong>，<strong>并且每次仅允许一个进程进入管程</strong>。</p><h3 id="条件变量"><a class="header-anchor" href="#条件变量">¶</a>条件变量</h3><p>  当一个进程进入管程后被阻塞，直到阻塞的原因被解除时，在此期间，如果该进程不释放管程，则其他进程无法进入管程。因此将阻塞原因定义为<strong>条件变量$condition$</strong>,因为一个进程被阻塞的原因有多个，因此在管程中设置了多个条件变量，每个条件变量保存了一个等待队列，用于记录因该条件变量而阻塞的所有进程，对条件变量只能进行两种操作，$wait$和$signal$。<br>  <strong>$x.wait$</strong>：当$x$对应的条件不满足时，正在调用管程的进程调用$x.wait$将自己插入$x$条件的等待队列，并释放管程。此时其他进程可以使用该管程。<br>  <strong>$x.signal$</strong>：$x$对应的条件发生了变化，则调用$x.signal$，唤醒一个因$x$条件而阻塞的进程。</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">monitor Demo &#123;    共享数据结构 S;    condition x;                         &#x2F;&#x2F; 定义一个条件变量    init_code() &#123;...&#125;    take_away() &#123;        if(S &lt;&#x3D; 0) x.wait();            &#x2F;&#x2F; 资源不够，在条件变量x上阻塞等待        &#x2F;&#x2F; 资源足够，分配资源，做一系列相应处理    &#125;    give_back() &#123;        &#x2F;&#x2F; 归还资源，做一系列相应处理；        if(&#x2F;*有进程在等待*&#x2F;) x.xignal;    &#x2F;&#x2F; 唤醒一个阻塞进程    &#125;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>  条件变量和信号量的比较：<br>  相似点：条件变量的$wait/signal$操作类似于信号量的$P/V$操作，可以实现进程的阻塞/唤醒。<br>  不同点：条件变量是“没有值的”，仅实现了“排队等待”功能；而信号量是“有值”的，信号量的值反映了剩余资源数，而在管程中，剩余资源数用共享数据结构记录。</p><h2 id="经典的同步问题"><a class="header-anchor" href="#经典的同步问题">¶</a>经典的同步问题</h2><p>  这部分内容单独用一章博客进行讲述。</p>]]></content>
      
      
      <categories>
          
          <category> 课本学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 操作系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2021华为软件精英挑战赛初赛代码及思路</title>
      <link href="/2021/03/30/2021-hua-wei-ruan-jian-jing-ying-tiao-zhan-sai-chu-sai-dai-ma-ji-si-lu/"/>
      <url>/2021/03/30/2021-hua-wei-ruan-jian-jing-ying-tiao-zhan-sai-chu-sai-dai-ma-ji-si-lu/</url>
      
        <content type="html"><![CDATA[<h2 id="2021华为软件精英挑战赛训练赛、正式赛思路分享"><a class="header-anchor" href="#2021华为软件精英挑战赛训练赛、正式赛思路分享">¶</a>2021华为软件精英挑战赛训练赛、正式赛思路分享</h2><p>    有幸再次参加了华为软件精英挑战赛（去年由于不知道数据集有坑，导致没能进入复赛，今年决定再来一次弥补去年的遗憾）<br>    今年的赛题相比去年个人感觉还是好了一些的，从任务指导书所给的评分规则来看，确实要比去年单一的按程序运行时间来评判要好一些。并且题目属于开放性赛题，没有唯一的标准答案，所以在逻辑思维上可以很好的区分参赛选手（至少我是这么认为的）。具体的赛题可以到比赛官网中进行下载，或者点击这个链接<a href="https://developer.huaweicloud.com/hero/forum.php?mod=viewthread&amp;tid=112802">初赛赛题下载</a><br>    说说我们队伍的情况吧，我们是武长赛区正式赛排行榜中的第七名。<br><img src="/2021/03/30/2021-hua-wei-ruan-jian-jing-ying-tiao-zhan-sai-chu-sai-dai-ma-ji-si-lu/2.png" alt="队伍最终最好成绩"></p><p>但是因为队友题目出来当晚，官方没有禁止开源代码的情况下，开源了一份baseline（只开源了一次），那份baseline没有加任何迁移算法，只是一个很基础的供选手参赛的代码，在训练赛中也只是50e的分数，（参赛的同学应该知道50e的分数是一个什么水平，就是垫底的分数）在大赛继续进行到12号的时候，因为开源代码的选手零零星星出现了不少，官方禁止了开源，我们也没有对外透漏过任何代码，在正式赛结束之后，很不幸，被查重了，我很呵呵，我加了迁移的算法怎么与其他人去冲突？？？？查重不应该是在逻辑上查重吗？难道有人用了我的代码，自动的在我们的思路带领下，和我们写了一样的调度算法？？？？很迷惑，申诉之后，官方的回信也的内容只有大赛的四条比赛规则（感觉只是走了一个流程），而且我们知道的其他一些开源的队伍，竟然没有被查到，更加迷惑了。我大三下了，为了这个比赛放弃了一段时间的考研复习，就是希望在这个赛事中找回去年的不爽，结果再次寒心……。吃一堑长一智吧。<br>    说点开心的吧，在正式赛中团队整体奋斗的是我和另外一位老哥，老哥实力很强，在开始冲的还是很猛的，后期因为一些其他的事情，没有把太多精力放在这个上面，因为进复赛很稳了，但是没想到，呵呵呵。当然在这次比赛中，还认识了其他不少的大佬，比赛嘛，最开心的是认识很多朋友了。</p><h3 id="赛题分析"><a class="header-anchor" href="#赛题分析">¶</a>赛题分析</h3><p>    在分析赛提前提醒大家，想要尽快写baseline、出结果、上分，一定要先读题，认认真真读题，好好分析赛题。<br>    题目大致是给你一些服务器和虚拟机的类型，服务器分为两个节点A、B，<strong>服务器拥有的资源（CPU 和内存）均匀分布在这两个节点上</strong>。这句话是重点！！！这句话是重点！！！这句话是重点！！！也就意味着，如果服务器的类型为NV603 ，其CPU为92C，内存为324G，那么其 A、B 两个节点分别包含的资源为：CPU核数：46C 和，内存大小162G 的资源。并且保证服务器的CPU 核数和内存大小均为偶数。并且在题目中还给出了服务器的硬件成本以及每日耗能成本。<br>    题目中所给的虚拟机有两种部署方式，分别为单双节点部署，单节点部署指的是一台虚拟机所需的资源（CPU和内存）完全由主机上的一个节点提供；<strong>双节点部署指的是一台虚拟机所需的资源（CPU 和内存）必须由一台服务器的两个节点同时提供，并且每个节点提供总需求资源的一半</strong>。<br>    赛题要求根据所给的请求序列，创建服务器，部署虚拟机，或者按照用户请求在对应的服务器上删除相应的虚拟机。但要注意，服务器上的任意一个节点(A和 B)上的资源负载(CPU 和内存)均不能超过其容量上限。在完成每一天的服务器的扩容之后，在处理每一天的新请求之前，你还可以对当前存量虚拟机进行一次迁移，即把虚拟机从一台服务器迁移至另一台服务器。对于单节点部署的虚拟机，将其从一台服务器的 A 节点迁移至 B 节点(或反之)也是允许的。但迁移的虚拟机总量不超过当前存量虚拟机数量的千分之五。<br>    通读赛题所有要求之后，其实我们可以发现这是一个类似于装箱的问题，把服务器比作箱子，把虚拟机比作需要放进去的货物。在一般的装箱问题中，我们首先要考虑的就是如何选择箱子，即选择用什么样的箱子来装什么样的货物是最合理的。这就需要涉及到对所有的箱子进行特征上的分析。接下来就是我们队伍对于整个赛题的思路（谨代表团队思路，如果讲解有误，勿喷！）</p><h3 id="购买服务器思路"><a class="header-anchor" href="#购买服务器思路">¶</a>购买服务器思路</h3><p>    首先最开始我们想到的当然就是如何购买服务器，买容量最大的？买价格最便宜的？买CPU和内存大小最接近的？……上面的这几种思路并不没有一个标准的正确，首先在这种调度问题中，是没有一个正确的答案的，通过这些思路最终得到的结果是好是坏，很大一部分是取决于数据集的，但是我们也不能因为没有正确的答案，而且五花八门的胡乱猜测。首先，我们继续回到题目背景中去，背景中有如下一句话：<br><img src="/2021/03/30/2021-hua-wei-ruan-jian-jing-ying-tiao-zhan-sai-chu-sai-dai-ma-ji-si-lu/1.png" alt="赛题中的背景信息"><br>众所周知，这种比赛的目的一方面是为了选拔优秀选手，另一方面也是为了给自己公司当前所存在的问题，在民间寻找解决方法，可能你的思路在这个比赛中节约了一点点成本，放在真正的市场中，可以让华为的成本节约<strong>亿点点</strong>。<br>    我们队伍在题目中所给数据中的服务器的规格进行了一个粗略的分析，服务器的种类比较丰富，每种服务器上CPU和内存的大小也不同，我们按照以下的几种方式对服务器进行了排序，并在每种排序后面写了我们的思考依据：</p><ol><li>CPU+内存：这样为了保证可以选择资源足够大的服务器</li><li>每日的耗能：如果请求天数足够多，服务器开启时间足够长，那么每日耗能的费用要远远大于其硬件成本</li><li>CPU * 0.75 + 内存 * 0.25：魔法数字，后面还有部分也会用到，对于我们版本的代码来说，很重要！！！。</li><li>服务器的硬件成本：在请求天数较小，每天请求数量较小的情况下， 硬件成本所占的费用比重较大</li><li>CPU：仅作为参考</li><li>内存：仅作为参考</li><li>abs(CPU - 内存)：大规模虚拟机的部署情况下，所有虚拟机所需的内存和CPU总和是接近的或者会趋近于某一个比值，为了让服务器可以部署更多的虚拟机，我们就尽量使服务器的CPU和内存大小接近，</li><li>服务器的硬件成本 / (CPU + 内存)：考虑服务器的性价比。</li></ol><h3 id="处理请求思路"><a class="header-anchor" href="#处理请求思路">¶</a>处理请求思路</h3><p>    本题中的数据输入是一次性输入的，我们可以先把所有的数据保存下来，然后去对这些信息集中处理，这样我们就可以用一个上帝视角来解决这个问题，也可以按照每一条请求进行中规中距的进行处理（因为我们队伍依次对请求进行处理的分数还是比较客观的，又因为是初赛，也没有去花太多功夫去更改已经写好的baseline，所以没有采用上面看似比较良好的上帝视角去处理）在得到每一次的请求之后，判断其为“add”，还是“del”，依次进行请求处理。</p><h3 id="选择服务器"><a class="header-anchor" href="#选择服务器">¶</a>选择服务器</h3><p>    在刚开始遇到“add”请求，或者在当前已有服务器无法满足请求中虚拟机所需要的资源时，我们需要重新开启新的服务器，在这时我们就会遇到服务器的选择问题。我们队伍根据上面的选择思路以及实验中得到结果进行对比后，采用的是第二种排序方式，然后对排好序的服务器从前到后依次遍历，选择刚好符合该虚拟机的服务器，具体代码如下：</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">int ii;for (ii &#x3D; 0; ii &lt; model_pair_size; ii++)&#123; &#x2F;&#x2F;找到一个最合适虚拟机的服务器，vv代表的是虚拟机信息的结构体    if (vv.cpu &lt; model_pair[ii].first.cpu &#x2F; 2 &amp;&amp; vv.Memory &lt; model_pair[ii].first.Memory &#x2F; 2 &amp;&amp; !vv.Is_Double_node)    &#123;        break;    &#125;    if (vv.cpu &lt; model_pair[ii].first.cpu &amp;&amp; vv.Memory &lt; model_pair[ii].first.Memory &amp;&amp; vv.Is_Double_node)    &#123;        break;    &#125;&#125;server ss &#x3D; model_pair[ii].first;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>    在我们初赛的代码中，其他排序得到的结果没有这种排序的方式费用低，并且在线下数据集和正式赛中，（3）、（4）两种排序方式最终得到的分数是相同的，并且在线下数据集中，根据这两种方式排序，得到的服务器的顺序大致是相同的。（很可能是我们猜测的系数刚好符合简化后数据集的系数）。</p><h3 id="添加虚拟机"><a class="header-anchor" href="#添加虚拟机">¶</a>添加虚拟机</h3><p>    如果在当前服务器有满足需要部署的虚拟机所需要资源的情况下，我们部署的策略是，首先遍历所有服务器，找到当前虚拟机部署在第一次出现的合适的服务器，对于双节点虚拟机，计算其部署后剩余资源的大小，即<strong>剩余CPU * 0.75 + 剩余内存 * 0.25</strong>，如果为单节点虚拟机，<br>只计算其一个节点的剩余资源，计算公式还是如上所示。<strong>在单节点中，选取A、B节点也要考虑两个节点之间的负载均衡，因为后面可能会出现双节点虚拟机不会因为负载不均衡而无法部署</strong>。最终找到剩余资源最小的那个服务器进行部署，具体代码如下所示：</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">for (int i &#x3D; 0; i &lt; sizes; i++)&#123;    if (vv.Is_Double_node)    &#123;        if (server_myselfs[i].A_cpu &gt;&#x3D; vv.cpu &#x2F; 2 &amp;&amp; server_myselfs[i].A_Memory &gt;&#x3D; vv.Memory &#x2F; 2 &amp;&amp; server_myselfs[i].B_cpu &gt;&#x3D; vv.cpu &#x2F; 2 &amp;&amp; server_myselfs[i].B_Memory &gt;&#x3D; vv.Memory &#x2F; 2)        &#123;            if (((server_myselfs[i].A_cpu + server_myselfs[i].B_cpu - vv.cpu) * Q3 + (server_myselfs[i].A_Memory + server_myselfs[i].B_Memory - vv.Memory) * Q4) &lt; myself_max)            &#123;            myself_max &#x3D; (server_myselfs[i].A_cpu + server_myselfs[i].B_cpu - vv.cpu) * Q3 + (server_myselfs[i].A_Memory + server_myselfs[i].B_Memory - vv.Memory) * Q4;                myself_idnex &#x3D; i;                flag &#x3D; 1;            &#125;        &#125;    &#125;    else    &#123;    int flag1 &#x3D; 0, flag2 &#x3D; 0;        if (server_myselfs[i].A_cpu &gt;&#x3D; vv.cpu &amp;&amp; server_myselfs[i].A_Memory &gt;&#x3D; vv.Memory)        &#123;        if (((server_myselfs[i].A_cpu - vv.cpu) * Q3 + (server_myselfs[i].A_Memory - vv.Memory) * Q4) &lt; myself_max)            &#123;            myself_max &#x3D; (server_myselfs[i].A_cpu - vv.cpu) * Q3 + (server_myselfs[i].A_Memory - vv.Memory) * Q4;                myself_idnex &#x3D; i;                A_or_B &#x3D; 1;                flag &#x3D; 1;                flag1 &#x3D; 1;            &#125;        &#125;        int myself_max_tmp &#x3D; myself_max;        if (server_myselfs[i].B_cpu &gt;&#x3D; vv.cpu &amp;&amp; server_myselfs[i].B_Memory &gt;&#x3D; vv.Memory)        &#123;        if (((server_myselfs[i].B_cpu - vv.cpu) * Q3 + (server_myselfs[i].B_Memory - vv.Memory) * Q4) &lt; myself_max)            &#123;            myself_max &#x3D; (server_myselfs[i].B_cpu - vv.cpu) * Q3 + (server_myselfs[i].B_Memory - vv.Memory) * Q4;                myself_idnex &#x3D; i;                A_or_B &#x3D; 0;                flag &#x3D; 1;                flag2 &#x3D; 1;            &#125;        &#125;        if (myself_max_tmp &lt;&#x3D; myself_max &amp;&amp; flag1 &#x3D;&#x3D; 1 &amp;&amp; flag2 &#x3D;&#x3D; 1)        &#123;        myself_max &#x3D; myself_max_tmp;            A_or_B &#x3D; 1;            flag &#x3D; 1;        &#125;        if (myself_max_tmp &gt;&#x3D; myself_max &amp;&amp; flag1 &#x3D;&#x3D; 1 &amp;&amp; flag2 &#x3D;&#x3D; 1)        &#123;        A_or_B &#x3D; 0;            flag &#x3D; 1;        &#125;    &#125;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="迁移调度"><a class="header-anchor" href="#迁移调度">¶</a>迁移调度</h3><p>    在迁移过程中，我们使用的是一层虚拟机循环，一层服务器循环，我们对上一天中的所有虚拟机进行遍历，在循环中将这个虚拟机部署到其他合适的服务器上，首先去计算当前虚拟机在当前服务器CPU和内存的使用率，**当前CPU和内存的剩余资源所占总资源的百分比小于0.07，那么我们直接跳过，**这样做的理由如下：</p><ol><li>首先可以加速，在正式赛中，数据量比线下的数据量要大很多，我们可以在牺牲一部分迁移的情况下来避免超时，正式赛的超时现象很严重。</li><li>其次，在服务器所剩余资源较小的情况下，我们可以认为当前服务器已经达到了负载均衡，满足理想中的条件，如果再加迁移，可能会影响均衡。</li></ol><p>    在正式赛的提交中，我们的代码在取该值为0.07时，得到的分数是最好的。由于迁移代码较长，就不在此处进行放置，大家可以在我们公布的源码中进行理解。</p><h3 id="可以优化的思路"><a class="header-anchor" href="#可以优化的思路">¶</a>可以优化的思路</h3><p>    因为我们的当前版本的分数可以进入复赛，加上队友后期有事，就没有花太多精力去进行其他方面的优化（也是本人比较菜，写了几个bug，懒得改了）现在分享一些其我们想到的他方面的一些没有实现的优化吧：</p><ol><li>可以将每天的请求进行提前保存，对需要部署的虚拟机进行排序选择，或者可以根据当天的虚拟机的CPU和内存进行拟合，对服务器重新排序，选择合适的服务器。</li><li>可以在每次迁移前，对所有的服务器进行排序，将利用率较小的服务器迁移到利用率较高的服务器上去。</li><li>可以在整个添加服务器上进行单双节点分治，即单节点部署的虚拟机可以迁移到有双节点部署的服务器上去，但是双节点部署的虚拟机不可以迁移到只有单节点部署的服务器上面，这点在我们中间版本的代码中是有一定提升的，但是因为后面的版本有了一些改动，所以就没有继续采用，大佬们可以自己实验以下。</li><li>服务器的选择，线上和线下的服务器中了以及特征是差不多的，因为上面有两种排序得到结果是相同的，线下的数据也是相同的。我们的服务器选择不算差，但是与前排大佬比起来还是逊色一些的，所以服务器的选择可以使用一些更高级的拟合来进行。</li></ol><h3 id="队伍正式赛分数最优代码"><a class="header-anchor" href="#队伍正式赛分数最优代码">¶</a>队伍正式赛分数最优代码</h3><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;vector&gt;#include &lt;unordered_map&gt;#include &lt;fstream&gt;#include &lt;algorithm&gt;#include &lt;ctime&gt;using namespace std;&#x2F;&#x2F;clock_t startTime, endTime;&#x2F;&#x2F; 服务器typedef struct A&#123;    &#x2F;&#x2F;型号, CPU核数, 内存大小, 硬件成本, 能耗成本    string model;              &#x2F;&#x2F;型号    double cpu;                &#x2F;&#x2F;CPU核数    double Memory;             &#x2F;&#x2F;内存大小    long long Hardware_cost;   &#x2F;&#x2F;硬件成本    long long Energy_cost_day; &#x2F;&#x2F;每日能耗成本&#125; server;&#x2F;&#x2F; 虚拟机typedef struct B&#123;    &#x2F;&#x2F;型号, CPU核数, 内存大小, 是否双节点部署    string model;       &#x2F;&#x2F;型号    double cpu;         &#x2F;&#x2F;CPU核数    double Memory;      &#x2F;&#x2F;内存大小    int Is_Double_node; &#x2F;&#x2F;是否双节点部署&#125; VM;&#x2F;&#x2F;用来存放当前所有服务器的信息的typedef struct C&#123;    string model; &#x2F;&#x2F;型号    double A_cpu; &#x2F;&#x2F;已经当前还未使用数量    double A_Memory;    double B_cpu;    double B_Memory;    long long Energy_cost_day;    int flag;    vector&lt;pair&lt;int, int&gt;&gt; VM_ids;&#125; server_myself;&#x2F;&#x2F; 每一天中增加的虚拟机信息typedef struct D&#123;    string model;    int index;    int server_id;      &#x2F;&#x2F;存放在哪一个server中    int Is_Double_node; &#x2F;&#x2F;是否使用双节点部署    int A_or_B;         &#x2F;&#x2F;如果使用的是单节点部署，那么部署在哪个节点,1代表A&#125; add_VM;typedef struct E&#123;    string op;    string model;    int id;&#125; operators;int cost;                                 &#x2F;&#x2F;这个用来记录消费，用来评估算法水平unordered_map&lt;string, server&gt; server_map; &#x2F;&#x2F;存储所有服务器的信息server server_buf;vector&lt;pair&lt;server, double&gt;&gt; model_pair;unordered_map&lt;string, VM&gt; VM_map;VM VM_buf;vector&lt;pair&lt;int, int&gt;&gt; ids_pair;unordered_map&lt;int, add_VM&gt; adds;vector&lt;server_myself&gt; server_myselfs;int day &#x3D; 0;int migrations_index &#x3D; 0;int sum_vm &#x3D; 0;vector&lt;int&gt; cin_size;vector&lt;operators&gt; cin_buf;string buf;double Q1 &#x3D; 0.75, Q2 &#x3D; 0.25;double Q3 &#x3D; 0.75, Q4 &#x3D; 0.25;void InitServer(string buf)&#123;    int j &#x3D; 1;    server_buf.model.clear();    &#x2F;&#x2F; 服务器型号    while (buf[j] !&#x3D; &#39;,&#39;)    &#123;        server_buf.model.push_back(buf[j]);        j++;    &#125;    j++;    while (buf[j] &#x3D;&#x3D; &#39; &#39;)    &#123;        j++;    &#125;    &#x2F;&#x2F; 服务CPU大小    server_buf.cpu &#x3D; 0;    while (buf[j] !&#x3D; &#39;,&#39;)    &#123;        server_buf.cpu &#x3D; server_buf.cpu * 10 + buf[j] - &#39;0&#39;;        j++;    &#125;    j++;    while (buf[j] &#x3D;&#x3D; &#39; &#39;)    &#123;        j++;    &#125;    &#x2F;&#x2F; 服务内存大小    server_buf.Memory &#x3D; 0;    while (buf[j] !&#x3D; &#39;,&#39;)    &#123;        server_buf.Memory &#x3D; server_buf.Memory * 10 + buf[j] - &#39;0&#39;;        j++;    &#125;    j++;    while (buf[j] &#x3D;&#x3D; &#39; &#39;)    &#123;        j++;    &#125;    &#x2F;&#x2F; 服务硬件成本    server_buf.Hardware_cost &#x3D; 0;    while (buf[j] !&#x3D; &#39;,&#39;)    &#123;        server_buf.Hardware_cost &#x3D; server_buf.Hardware_cost * 10 + buf[j] - &#39;0&#39;;        j++;    &#125;    j++;    while (buf[j] &#x3D;&#x3D; &#39; &#39;)    &#123;        j++;    &#125;    &#x2F;&#x2F; 服务耗能成本    server_buf.Energy_cost_day &#x3D; 0;    while (buf[j] !&#x3D; &#39;)&#39;)    &#123;        server_buf.Energy_cost_day &#x3D; server_buf.Energy_cost_day * 10 + buf[j] - &#39;0&#39;;        j++;    &#125;    server_map[server_buf.model] &#x3D; server_buf;    &#x2F;&#x2F;double weight &#x3D; server_buf.cpu * 0.75 + server_buf.Memory * 0.25;    double weight &#x3D; server_buf.Energy_cost_day;    model_pair.push_back(make_pair(server_buf, weight));&#125;void InitVM(string buf)&#123;    int j &#x3D; 1;    VM_buf.model.clear();    while (buf[j] !&#x3D; &#39;,&#39;)    &#123;        VM_buf.model.push_back(buf[j]);        j++;    &#125;    j++;    while (buf[j] &#x3D;&#x3D; &#39; &#39;)    &#123;        j++;    &#125;    VM_buf.cpu &#x3D; 0;    while (buf[j] !&#x3D; &#39;,&#39;)    &#123;        VM_buf.cpu &#x3D; VM_buf.cpu * 10 + buf[j] - &#39;0&#39;;        j++;    &#125;    j++;    while (buf[j] &#x3D;&#x3D; &#39; &#39;)    &#123;        j++;    &#125;    VM_buf.Memory &#x3D; 0;    while (buf[j] !&#x3D; &#39;,&#39;)    &#123;        VM_buf.Memory &#x3D; VM_buf.Memory * 10 + buf[j] - &#39;0&#39;;        j++;    &#125;    j++;    while (buf[j] &#x3D;&#x3D; &#39; &#39;)    &#123;        j++;    &#125;    VM_buf.Is_Double_node &#x3D; buf[j] - &#39;0&#39;;    VM_map[VM_buf.model] &#x3D; VM_buf;&#125;string Operation(string buf, int &amp;index)&#123;    string op;    while (buf[index] !&#x3D; &#39;,&#39;)    &#123;        op.push_back(buf[index]);        index++;    &#125;    index++;    while (buf[index] &#x3D;&#x3D; &#39; &#39;)    &#123;        index++;    &#125;    return op;&#125;bool static cmp(pair&lt;server, double&gt; &amp;A, pair&lt;server, double&gt; &amp;B)&#123;    return A.second &lt; B.second;&#125;bool static cmp2(server_myself &amp;A, server_myself &amp;B)&#123;    return A.A_cpu + A.B_cpu &lt; B.A_cpu + B.B_cpu;&#125;&#x2F;*bool static cmp3(server_myself &amp;A, server_myself &amp;B)&#123;    return A.id &lt; B.id;&#125;*&#x2F;&#x2F;&#x2F;ofstream outfile(&quot;out2.txt&quot;, ios::trunc);&#x2F;&#x2F;ofstream outfile2(&quot;out.txt&quot;, ios::trunc);void Select(int &amp;sum, vector&lt;string&gt; &amp;migrations)&#123;    int j &#x3D; migrations_index;    int server_myselfs_len &#x3D; (int)server_myselfs.size();    int ids_pair_len &#x3D; (int)ids_pair.size();    int find_sum &#x3D; 0;    &#x2F;&#x2F; sort(server_myselfs.begin(), server_myselfs.end(), cmp2);    while (1)    &#123;        j++;        find_sum++;        j &#x3D; j % ids_pair_len;                if (j &#x3D;&#x3D; migrations_index)        &#123;            break;        &#125;        &#x2F;&#x2F; if(find_sum&gt;ids_pair_len&#x2F;2)&#123;        &#x2F;&#x2F;     break;        &#x2F;&#x2F; &#125;        &#x2F;&#x2F;调度不能超过总数的5&#x2F;1000;        if (sum &gt;&#x3D; (sum_vm &#x2F; 1000 * 5 - 1))        &#123;            break;        &#125;        if (ids_pair[j].second)        &#123; &#x2F;&#x2F;表示当前虚拟机还存在的            add_VM temp &#x3D; adds[ids_pair[j].first];            int max_index &#x3D; temp.server_id;            int max_index_or &#x3D; max_index;            &#x2F;*            if (max_index !&#x3D; server_myselfs[max_index].id)            &#123;                cout &lt;&lt; &quot;Error&quot; &lt;&lt; endl;            &#125;            *&#x2F;            double max, max1, max2;            if (temp.Is_Double_node)            &#123;                max &#x3D; (server_myselfs[max_index].A_cpu + server_myselfs[max_index].B_cpu) * Q1 + (server_myselfs[max_index].A_Memory + server_myselfs[max_index].B_Memory) * Q2;                max1 &#x3D; (server_myselfs[max_index].A_cpu + server_myselfs[max_index].B_cpu) * 1.0 &#x2F; (server_map[server_myselfs[max_index].model].cpu);                max2 &#x3D; (server_myselfs[max_index].A_Memory + server_myselfs[max_index].B_Memory) * 1.0 &#x2F; (server_map[server_myselfs[max_index].model].Memory);            &#125;            else            &#123;                if (temp.A_or_B)                &#123;                    max &#x3D; server_myselfs[max_index].A_cpu * Q1 + server_myselfs[max_index].A_Memory * Q2;                    max1 &#x3D; server_myselfs[max_index].A_cpu * 1.0 &#x2F; (server_map[server_myselfs[max_index].model].cpu &#x2F; 2);                    max2 &#x3D; server_myselfs[max_index].A_Memory * 1.0 &#x2F; (server_map[server_myselfs[max_index].model].Memory &#x2F; 2);                &#125;                else                &#123;                    max &#x3D; server_myselfs[max_index].B_cpu * Q1 + server_myselfs[max_index].B_Memory * Q2;                    max1 &#x3D; server_myselfs[max_index].B_cpu * 1.0 &#x2F; (server_map[server_myselfs[max_index].model].cpu &#x2F; 2);                    max2 &#x3D; server_myselfs[max_index].B_Memory * 1.0 &#x2F; (server_map[server_myselfs[max_index].model].Memory &#x2F; 2);                &#125;            &#125;                        if (max1 &lt; 0.07 &amp;&amp; max2 &lt; 0.07)            &#123;                continue;            &#125;                        int flag &#x3D; 0;            int A_or_B &#x3D; 0;            VM vv &#x3D; VM_map[temp.model];            for (int i &#x3D; 0; i &lt; server_myselfs_len; i++)            &#123;                if (i &#x3D;&#x3D; max_index_or)                &#123;                    continue;                &#125;                if (vv.Is_Double_node)                &#123;                    if (server_myselfs[i].A_cpu &gt;&#x3D; vv.cpu &#x2F; 2 &amp;&amp; server_myselfs[i].A_Memory &gt;&#x3D; vv.Memory &#x2F; 2 &amp;&amp; server_myselfs[i].B_cpu &gt;&#x3D; vv.cpu &#x2F; 2 &amp;&amp; server_myselfs[i].B_Memory &gt;&#x3D; vv.Memory &#x2F; 2)                    &#123;                        if (((server_myselfs[i].A_cpu + server_myselfs[i].B_cpu - vv.cpu) * Q1 + (server_myselfs[i].A_Memory + server_myselfs[i].B_Memory - vv.Memory) * Q2) &lt; max)                        &#123;                            max &#x3D; (server_myselfs[i].A_cpu + server_myselfs[i].B_cpu - vv.cpu) * Q1 + (server_myselfs[i].A_Memory + server_myselfs[i].B_Memory - vv.Memory) * Q2;                            max_index &#x3D; i;                            flag &#x3D; 1;                        &#125;                    &#125;                &#125;                else                &#123;                    if (server_myselfs[i].A_cpu &gt;&#x3D; vv.cpu &amp;&amp; server_myselfs[i].A_Memory &gt;&#x3D; vv.Memory)                    &#123;                        if (((server_myselfs[i].A_cpu - vv.cpu) * Q1 + (server_myselfs[i].A_Memory - vv.Memory) * Q2) &lt; max)                        &#123;                            max &#x3D; (server_myselfs[i].A_cpu - vv.cpu) * Q1 + (server_myselfs[i].A_Memory - vv.Memory) * Q2;                            max_index &#x3D; i;                            A_or_B &#x3D; 1;                            flag &#x3D; 1;                        &#125;                    &#125;                    if (server_myselfs[i].B_cpu &gt;&#x3D; vv.cpu &amp;&amp; server_myselfs[i].B_Memory &gt;&#x3D; vv.Memory)                    &#123;                        if (((server_myselfs[i].B_cpu - vv.cpu) * Q1 + (server_myselfs[i].B_Memory - vv.Memory) * Q2) &lt; max)                        &#123;                            max &#x3D; (server_myselfs[i].B_cpu - vv.cpu) * Q1 + (server_myselfs[i].B_Memory - vv.Memory) * Q2;                            max_index &#x3D; i;                            A_or_B &#x3D; 0;                            flag &#x3D; 1;                        &#125;                    &#125;                &#125;            &#125;            if (flag)            &#123;                &#x2F;&#x2F;outfile2 &lt;&lt; &quot;day: &quot; &lt;&lt; day &lt;&lt; &quot;j: &quot; &lt;&lt; j &lt;&lt; &quot; ,&quot; &lt;&lt; ids_pair_len &lt;&lt; endl;                add_VM tt &#x3D; adds[ids_pair[j].first];                sum++;                if (vv.Is_Double_node)                &#123;                    &#x2F;&#x2F;还原                    server_myselfs[max_index_or].A_cpu +&#x3D; vv.cpu &#x2F; 2;                    server_myselfs[max_index_or].A_Memory +&#x3D; vv.Memory &#x2F; 2;                    server_myselfs[max_index_or].B_cpu +&#x3D; vv.cpu &#x2F; 2;                    server_myselfs[max_index_or].B_Memory +&#x3D; vv.Memory &#x2F; 2;                    server_myselfs[max_index].A_cpu -&#x3D; vv.cpu &#x2F; 2;                    server_myselfs[max_index].A_Memory -&#x3D; vv.Memory &#x2F; 2;                    server_myselfs[max_index].B_cpu -&#x3D; vv.cpu &#x2F; 2;                    server_myselfs[max_index].B_Memory -&#x3D; vv.Memory &#x2F; 2;                    tt.server_id &#x3D; max_index;                    tt.Is_Double_node &#x3D; 1;                    migrations.push_back(&quot;(&quot; + to_string(ids_pair[j].first) + &quot;,&quot; + to_string(max_index) + &quot;)&quot;);                &#125;                else                &#123;                    if (tt.A_or_B)                    &#123;                        server_myselfs[max_index_or].A_cpu +&#x3D; vv.cpu;                        server_myselfs[max_index_or].A_Memory +&#x3D; vv.Memory;                    &#125;                    else                    &#123;                        server_myselfs[max_index_or].B_cpu +&#x3D; vv.cpu;                        server_myselfs[max_index_or].B_Memory +&#x3D; vv.Memory;                    &#125;                    if (A_or_B)                    &#123;                        tt.A_or_B &#x3D; 1;                        tt.server_id &#x3D; max_index;                        server_myselfs[max_index].A_cpu -&#x3D; vv.cpu;                        server_myselfs[max_index].A_Memory -&#x3D; vv.Memory;                        migrations.push_back(&quot;(&quot; + to_string(ids_pair[j].first) + &quot;,&quot; + to_string(max_index) + &quot;,A&quot; + &quot;)&quot;);                    &#125;                    else                    &#123;                        tt.A_or_B &#x3D; 0;                        tt.server_id &#x3D; max_index;                        server_myselfs[max_index].B_cpu -&#x3D; vv.cpu;                        server_myselfs[max_index].B_Memory -&#x3D; vv.Memory;                        migrations.push_back(&quot;(&quot; + to_string(ids_pair[j].first) + &quot;,&quot; + to_string(max_index) + &quot;,B&quot; + &quot;)&quot;);                    &#125;                &#125;                if ((server_myselfs[max_index_or].A_cpu + server_myselfs[max_index_or].B_cpu) &#x3D;&#x3D; server_map[server_myselfs[max_index_or].model].cpu)                &#123;                    if ((server_myselfs[max_index_or].A_Memory + server_myselfs[max_index_or].B_Memory) &#x3D;&#x3D; server_map[server_myselfs[max_index_or].model].Memory)                    &#123;                        server_myselfs[max_index_or].flag &#x3D; 0;                    &#125;                &#125;                adds[ids_pair[j].first] &#x3D; tt;            &#125;        &#125;    &#125;    migrations_index &#x3D; j;&#125;void ReadallData(int T)&#123;    for (int k &#x3D; 0; k &lt; T; k++)    &#123;        int R;        cin &gt;&gt; R;        getchar();        cin_size.push_back(R);        for (int j &#x3D; 0; j &lt; R; j++)        &#123;            getline(cin, buf);            int index &#x3D; 1;            operators ops;            ops.op &#x3D; Operation(buf, index);            if (ops.op &#x3D;&#x3D; &quot;add&quot;)            &#123;                while (buf[index] !&#x3D; &#39;,&#39;)                &#123;                    ops.model.push_back(buf[index]);                    index++;                &#125;                index++;                while (buf[index] &#x3D;&#x3D; &#39; &#39;)                &#123;                    index++;                &#125;                ops.id &#x3D; 0; &#x2F;&#x2F; 虚拟机ID                while (buf[index] !&#x3D; &#39;)&#39;)                &#123;                    ops.id &#x3D; ops.id * 10 + buf[index] - &#39;0&#39;;                    index++;                &#125;            &#125;            else            &#123;                ops.id &#x3D; 0;                while (buf[index] !&#x3D; &#39;)&#39;)                &#123;                    ops.id &#x3D; ops.id * 10 + buf[index] - &#39;0&#39;;                    index++;                &#125;            &#125;            cin_buf.push_back(ops);        &#125;    &#125;&#125;int main()&#123;    &#x2F;&#x2F;startTime &#x3D; clock();    int N; &#x2F;&#x2F;服务器种类    cin &gt;&gt; N;    getchar();    for (int i &#x3D; 0; i &lt; N; i++)    &#123;        getline(cin, buf);        InitServer(buf);    &#125;    server server_tem;    int max &#x3D; 10000000, server_tem_index &#x3D; 0;    server_tem_index &#x3D; 11;    sort(model_pair.begin(), model_pair.end(), cmp);    &#x2F;&#x2F;M    int M;    cin &gt;&gt; M;    getchar();    for (int i &#x3D; 0; i &lt; M; i++)    &#123;        getline(cin, buf);        InitVM(buf);    &#125;    &#x2F;&#x2F;T    int T;    cin &gt;&gt; T;    ReadallData(T);    int model_pair_size &#x3D; model_pair.size();    long long cost_min &#x3D; 5000000000;    long long cost &#x3D; 0;    vector&lt;string&gt; res_min;    int i1_index &#x3D; 0;    cost &#x3D; 0;    vector&lt;string&gt; res;    unordered_map&lt;string, int&gt; purchase;    &#x2F;&#x2F;用来存放服务器当天使用种类    vector&lt;pair&lt;string, int&gt;&gt; purchase_num; &#x2F;&#x2F;用来存放服务器当天使用种类个数    for (int k &#x3D; 0; k &lt; T; k++)    &#123;        day++;        vector&lt;string&gt; migrations;        int sum &#x3D; 0;        if (day % 1 &#x3D;&#x3D; 0 &amp;&amp; day !&#x3D; 1)        &#123;            Select(sum, migrations);        &#125;        purchase.clear();        purchase_num.clear();        purchase_num.push_back(make_pair(&quot;000&quot;, 0)); &#x2F;&#x2F;purchase_num第0个是没有用的        vector&lt;string&gt; dis;        int len &#x3D; server_myselfs.size();        vector&lt;vector&lt;int&gt;&gt; ids;        vector&lt;int&gt; dis_id;        vector&lt;operators&gt; day_ops;                for (int j &#x3D; 0; j &lt; cin_size[k]; j++)        &#123;            operators ops &#x3D; cin_buf[i1_index++];            if (ops.op &#x3D;&#x3D; &quot;add&quot;)            &#123;                sum_vm++;                int flag &#x3D; 0;                VM vv &#x3D; VM_map[ops.model];                add_VM add_tt;                add_tt.model &#x3D; ops.model;                add_tt.Is_Double_node &#x3D; 0;                dis_id.push_back(ops.id);                int myself_idnex &#x3D; 0, A_or_B &#x3D; 0;                double myself_max &#x3D; 10000000;                int sizes &#x3D; server_myselfs.size();                for (int i &#x3D; 0; i &lt; sizes; i++)                &#123;                    if (vv.Is_Double_node)                    &#123;                        if (server_myselfs[i].A_cpu &gt;&#x3D; vv.cpu &#x2F; 2 &amp;&amp; server_myselfs[i].A_Memory &gt;&#x3D; vv.Memory &#x2F; 2 &amp;&amp; server_myselfs[i].B_cpu &gt;&#x3D; vv.cpu &#x2F; 2 &amp;&amp; server_myselfs[i].B_Memory &gt;&#x3D; vv.Memory &#x2F; 2)                        &#123;                            if (((server_myselfs[i].A_cpu + server_myselfs[i].B_cpu - vv.cpu) * Q3 + (server_myselfs[i].A_Memory + server_myselfs[i].B_Memory - vv.Memory) * Q4) &lt; myself_max)                            &#123;                                myself_max &#x3D; (server_myselfs[i].A_cpu + server_myselfs[i].B_cpu - vv.cpu) * Q3 + (server_myselfs[i].A_Memory + server_myselfs[i].B_Memory - vv.Memory) * Q4;                                myself_idnex &#x3D; i;                                flag &#x3D; 1;                            &#125;                        &#125;                    &#125;                    else                    &#123;                        int flag1 &#x3D; 0, flag2 &#x3D; 0;                        if (server_myselfs[i].A_cpu &gt;&#x3D; vv.cpu &amp;&amp; server_myselfs[i].A_Memory &gt;&#x3D; vv.Memory)                        &#123;                            if (((server_myselfs[i].A_cpu - vv.cpu) * Q3 + (server_myselfs[i].A_Memory - vv.Memory) * Q4) &lt; myself_max)                            &#123;                                myself_max &#x3D; (server_myselfs[i].A_cpu - vv.cpu) * Q3 + (server_myselfs[i].A_Memory - vv.Memory) * Q4;                                myself_idnex &#x3D; i;                                A_or_B &#x3D; 1;                                flag &#x3D; 1;                                flag1 &#x3D; 1;                            &#125;                        &#125;                        int myself_max_tmp &#x3D; myself_max;                        if (server_myselfs[i].B_cpu &gt;&#x3D; vv.cpu &amp;&amp; server_myselfs[i].B_Memory &gt;&#x3D; vv.Memory)                        &#123;                            if (((server_myselfs[i].B_cpu - vv.cpu) * Q3 + (server_myselfs[i].B_Memory - vv.Memory) * Q4) &lt; myself_max)                            &#123;                                myself_max &#x3D; (server_myselfs[i].B_cpu - vv.cpu) * Q3 + (server_myselfs[i].B_Memory - vv.Memory) * Q4;                                myself_idnex &#x3D; i;                                A_or_B &#x3D; 0;                                flag &#x3D; 1;                                flag2 &#x3D; 1;                            &#125;                        &#125;                        if (myself_max_tmp &lt;&#x3D; myself_max &amp;&amp; flag1 &#x3D;&#x3D; 1 &amp;&amp; flag2 &#x3D;&#x3D; 1)                        &#123;                            myself_max &#x3D; myself_max_tmp;                            A_or_B &#x3D; 1;                            flag &#x3D; 1;                        &#125;                        if (myself_max_tmp &gt;&#x3D; myself_max &amp;&amp; flag1 &#x3D;&#x3D; 1 &amp;&amp; flag2 &#x3D;&#x3D; 1)                        &#123;                            A_or_B &#x3D; 0;                            flag &#x3D; 1;                        &#125;                    &#125;                &#125;                if (flag)                &#123;                    server_myselfs[myself_idnex].VM_ids.push_back(make_pair(ops.id, 1));                    server_myselfs[myself_idnex].flag &#x3D; 1;                    if (vv.Is_Double_node)                    &#123;                        add_tt.Is_Double_node &#x3D; 1;                        server_myselfs[myself_idnex].A_cpu -&#x3D; vv.cpu &#x2F; 2;                        server_myselfs[myself_idnex].A_Memory -&#x3D; vv.Memory &#x2F; 2;                        server_myselfs[myself_idnex].B_cpu -&#x3D; vv.cpu &#x2F; 2;                        server_myselfs[myself_idnex].B_Memory -&#x3D; vv.Memory &#x2F; 2;                        add_tt.server_id &#x3D; myself_idnex;                        if (myself_idnex &gt;&#x3D; len)                        &#123;                            ids[myself_idnex - len].push_back(ops.id);                        &#125;                    &#125;                    else                    &#123;                        if (A_or_B)                        &#123;                            add_tt.A_or_B &#x3D; 1;                            server_myselfs[myself_idnex].A_cpu -&#x3D; vv.cpu;                            server_myselfs[myself_idnex].A_Memory -&#x3D; vv.Memory;                            add_tt.server_id &#x3D; myself_idnex;                            if (myself_idnex &gt;&#x3D; len)                            &#123;                                ids[myself_idnex - len].push_back(ops.id);                            &#125;                        &#125;                        else                        &#123;                            add_tt.A_or_B &#x3D; 0;                            server_myselfs[myself_idnex].B_cpu -&#x3D; vv.cpu;                            server_myselfs[myself_idnex].B_Memory -&#x3D; vv.Memory;                            add_tt.server_id &#x3D; myself_idnex;                            if (myself_idnex &gt;&#x3D; len)                            &#123;                                ids[myself_idnex - len].push_back(ops.id);                            &#125;                        &#125;                    &#125;                &#125;                else                &#123;                    int ii;                                        for (ii &#x3D; 0; ii &lt; model_pair_size; ii++)                    &#123; &#x2F;&#x2F;找到一个最合适服务器的                        if (vv.cpu &lt; model_pair[ii].first.cpu &#x2F; 2 &amp;&amp; vv.Memory &lt; model_pair[ii].first.Memory &#x2F; 2 &amp;&amp; !vv.Is_Double_node)                        &#123;                            break;                        &#125;                        if (vv.cpu &lt; model_pair[ii].first.cpu &amp;&amp; vv.Memory &lt; model_pair[ii].first.Memory &amp;&amp; vv.Is_Double_node)                        &#123;                            break;                        &#125;                    &#125;                                        &#x2F;&#x2F; if((vv.cpu&lt;model_pair[server_tem_index].first.cpu&#x2F;2&amp;&amp;vv.Memory&lt;model_pair[server_tem_index].first.Memory&#x2F;2&amp;&amp;!vv.Is_Double_node)||(vv.cpu&lt;model_pair[server_tem_index].first.cpu&amp;&amp;vv.Memory&lt;model_pair[server_tem_index].first.Memory&amp;&amp;vv.Is_Double_node))&#123;                    &#x2F;&#x2F;     ii &#x3D; server_tem_index;                    &#x2F;&#x2F; &#125;                    &#x2F;&#x2F; else&#123;                    &#x2F;*                    double tmp1 &#x3D; vv.cpu * 1.0 &#x2F; vv.Memory * 1000;                    double maxn &#x3D; 999999;                    for (int ii &#x3D; 0; ii &lt; model_pair_size; ii++)                    &#123; &#x2F;&#x2F;找到一个最合适服务器的                                                double tmp2 &#x3D; model_pair[ii].first.cpu * 1.0 &#x2F; model_pair[ii].first.Memory * 1000;                                                                        if (vv.cpu &lt; model_pair[ii].first.cpu &#x2F; 2 &amp;&amp; vv.Memory &lt; model_pair[ii].first.Memory &#x2F; 2 &amp;&amp; !vv.Is_Double_node)                        &#123;                            if (abs(tmp1 - tmp2) &lt; maxn)                             &#123;                                iii &#x3D; ii;                                maxn &#x3D; abs(tmp1 - tmp2);                            &#125;                        &#125;                        if (vv.cpu &lt; model_pair[ii].first.cpu &amp;&amp; vv.Memory &lt; model_pair[ii].first.Memory &amp;&amp; vv.Is_Double_node)                        &#123;                            if (abs(tmp1 - tmp2) &lt; maxn)                             &#123;                                iii &#x3D; ii;                                maxn &#x3D; abs(tmp1 - tmp2);                            &#125;                        &#125;                    &#125;                    *&#x2F;                    &#x2F;&#x2F; &#125;                    server ss &#x3D; model_pair[ii].first;                    cost +&#x3D; ss.Hardware_cost;                    server_myself tt;                    tt.A_cpu &#x3D; ss.cpu &#x2F; 2;                    tt.A_Memory &#x3D; ss.Memory &#x2F; 2;                    tt.B_cpu &#x3D; ss.cpu &#x2F; 2;                    tt.B_Memory &#x3D; ss.Memory &#x2F; 2;                    tt.model &#x3D; ss.model;                    tt.Energy_cost_day &#x3D; ss.Energy_cost_day;                    tt.flag &#x3D; 1;                    int tt_id &#x3D; 0;                    int tt_index &#x3D; 0;                    if (purchase[ss.model] &#x3D;&#x3D; 0)                    &#123;                        purchase[ss.model] &#x3D; purchase_num.size();                        purchase_num.push_back(make_pair(ss.model, 1));                        tt_id &#x3D; server_myselfs.size();                        tt_index &#x3D; ids.size();                        server_myselfs.push_back(tt);                        ids.push_back(&#123;ops.id&#125;);                    &#125;                    else                    &#123;                        if (purchase[ss.model] &#x3D;&#x3D; (int)purchase_num.size())                        &#123;                            tt_id &#x3D; server_myselfs.size();                            tt_index &#x3D; ids.size();                            server_myselfs.push_back(tt);                            ids.push_back(&#123;ops.id&#125;);                        &#125;                        else                        &#123;                            int sum &#x3D; 0;                            for (int i &#x3D; 1; i &lt;&#x3D; purchase[ss.model]; i++)                            &#123;                                sum +&#x3D; purchase_num[i].second;                            &#125;                            tt_id &#x3D; len + sum;                            tt_index &#x3D; sum;                            server_myselfs.insert(server_myselfs.begin() + tt_id, tt);                            vector&lt;int&gt; temp &#x3D; &#123;ops.id&#125;;                            ids.insert(ids.begin() + sum, temp);                            for (int i &#x3D; sum + 1; i &lt; (int)ids.size(); i++)                            &#123;                                for (int j &#x3D; 0; j &lt; (int)ids[i].size(); j++)                                &#123;                                    if (adds.find(ids[i][j]) !&#x3D; adds.end())                                    &#123;                                        adds[ids[i][j]].server_id++;                                    &#125;                                &#125;                            &#125;                        &#125;                        purchase_num[purchase[ss.model]].second++;                    &#125;                    server_myselfs[tt_id].flag &#x3D; 1;                    server_myselfs[tt_id].VM_ids.push_back(make_pair(ops.id, 1));                    if (vv.Is_Double_node)                    &#123;                        add_tt.Is_Double_node &#x3D; 1;                        if (vv.cpu &#x2F; 2 &lt;&#x3D; server_myselfs[tt_id].A_cpu &amp;&amp; vv.Memory &#x2F; 2 &lt;&#x3D; server_myselfs[tt_id].A_Memory)                        &#123;                            server_myselfs[tt_id].A_cpu -&#x3D; vv.cpu &#x2F; 2;                            server_myselfs[tt_id].A_Memory -&#x3D; vv.Memory &#x2F; 2;                            server_myselfs[tt_id].B_cpu -&#x3D; vv.cpu &#x2F; 2;                            server_myselfs[tt_id].B_Memory -&#x3D; vv.Memory &#x2F; 2;                            add_tt.server_id &#x3D; tt_id;                        &#125;                        else                        &#123;                            cout &lt;&lt; &quot;----------CPU OR Memory 有问题的&quot; &lt;&lt; endl;                            return 0;                        &#125;                    &#125;                    else                    &#123;                        add_tt.A_or_B &#x3D; 1;                        if (vv.cpu &lt;&#x3D; server_myselfs[tt_id].A_cpu &amp;&amp; vv.Memory &lt;&#x3D; server_myselfs[tt_id].A_Memory)                        &#123;                            server_myselfs[tt_id].A_cpu -&#x3D; vv.cpu;                            server_myselfs[tt_id].A_Memory -&#x3D; vv.Memory;                            add_tt.server_id &#x3D; tt_id;                        &#125;                        else                        &#123;                            cout &lt;&lt; &quot;----------CPU OR Memory 有问题的&quot; &lt;&lt; endl;                            return 0;                        &#125;                    &#125;                &#125;                add_tt.index &#x3D; (int)ids_pair.size();                ids_pair.push_back(make_pair(ops.id, 1));                adds[ops.id] &#x3D; add_tt;            &#125;            else            &#123;                &#x2F;&#x2F;回收部分                add_VM del &#x3D; adds[ops.id];                ids_pair[del.index].second &#x3D; 0;                sum_vm--;                if (del.Is_Double_node)                &#123;                    server_myselfs[del.server_id].A_cpu +&#x3D; VM_map[del.model].cpu &#x2F; 2;                    server_myselfs[del.server_id].A_Memory +&#x3D; VM_map[del.model].Memory &#x2F; 2;                    server_myselfs[del.server_id].B_cpu +&#x3D; VM_map[del.model].cpu &#x2F; 2;                    server_myselfs[del.server_id].B_Memory +&#x3D; VM_map[del.model].Memory &#x2F; 2;                &#125;                else                &#123;                    if (del.A_or_B)                    &#123;                        server_myselfs[del.server_id].A_cpu +&#x3D; VM_map[del.model].cpu;                        server_myselfs[del.server_id].A_Memory +&#x3D; VM_map[del.model].Memory;                    &#125;                    else                    &#123;                        server_myselfs[del.server_id].B_cpu +&#x3D; VM_map[del.model].cpu;                        server_myselfs[del.server_id].B_Memory +&#x3D; VM_map[del.model].Memory;                    &#125;                &#125;                for (int i &#x3D; 0; i &lt; (int)server_myselfs[del.server_id].VM_ids.size(); i++)                &#123;                    if (server_myselfs[del.server_id].VM_ids[i].first &#x3D;&#x3D; ops.id)                    &#123;                        server_myselfs[del.server_id].VM_ids[i].second &#x3D; 0;                    &#125;                &#125;                if ((server_myselfs[del.server_id].A_cpu + server_myselfs[del.server_id].B_cpu) &#x3D;&#x3D; server_map[server_myselfs[del.server_id].model].cpu)                &#123;                    if ((server_myselfs[del.server_id].A_Memory + server_myselfs[del.server_id].B_Memory) &#x3D;&#x3D; server_map[server_myselfs[del.server_id].model].Memory)                    &#123;                        server_myselfs[del.server_id].flag &#x3D; 0;                    &#125;                &#125;                &#x2F;&#x2F;adds.erase(id);            &#125;        &#125;        &#x2F;*        for (int i &#x3D; 0; i &lt; (int)server_myselfs.size(); i++)        &#123;            if (server_myselfs[i].flag)            &#123;                cost +&#x3D; server_myselfs[i].Energy_cost_day;            &#125;        &#125;        *&#x2F;        for (int i &#x3D; 0; i &lt; (int)dis_id.size(); i++)        &#123;            if (adds[dis_id[i]].Is_Double_node)            &#123;                dis.push_back(&quot;(&quot; + to_string(adds[dis_id[i]].server_id) + &quot;)&quot;);            &#125;            else            &#123;                if (adds[dis_id[i]].A_or_B)                &#123;                    dis.push_back(&quot;(&quot; + to_string(adds[dis_id[i]].server_id) + &quot;,&quot; + &quot;A)&quot;);                &#125;                else                &#123;                    dis.push_back(&quot;(&quot; + to_string(adds[dis_id[i]].server_id) + &quot;,&quot; + &quot;B)&quot;);                &#125;            &#125;        &#125;        res.push_back(&quot;(purchase,&quot; + to_string(purchase_num.size() - 1) + &quot;)&quot;);        for (int i &#x3D; 1; i &lt; (int)purchase_num.size(); i++)        &#123;            res.push_back(&quot;(&quot; + purchase_num[i].first + &quot;,&quot; + to_string(purchase_num[i].second) + &quot;)&quot;);        &#125;        res.push_back(&quot;(migration,&quot; + to_string(migrations.size()) + &quot;)&quot;); &#x2F;&#x2F;一个简单的调度算法的        for (int i &#x3D; 0; i &lt; (int)migrations.size(); i++)        &#123;            res.push_back(migrations[i]);        &#125;        for (int i &#x3D; 0; i &lt; (int)dis.size(); i++)        &#123;            res.push_back(dis[i]);        &#125;    &#125;    for (int i &#x3D; 0; i &lt; (int)res.size(); i++)    &#123;        cout &lt;&lt; res[i] &lt;&lt; endl;        &#x2F;&#x2F;outfile &lt;&lt; res[i] &lt;&lt; endl;    &#125;    &#x2F;&#x2F; cout &lt;&lt; cost_min &lt;&lt; endl;    &#x2F;&#x2F;cout &lt;&lt; cost &lt;&lt; endl;    &#x2F;&#x2F;endTime &#x3D; clock();    &#x2F;&#x2F; cout &lt;&lt; &quot;The run time is:&quot; &lt;&lt;(double)(endTime - startTime) &#x2F; CLOCKS_PER_SEC &lt;&lt; &quot;s&quot; &lt;&lt; endl;    return 0;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>    复赛的题目应该是在初赛上加一些约束或者其他的数据，这里面的优化思路还是有一定的指引性的，仅供参考。如果在我的博客中有什么写的不妥的，或者错误的地方，欢迎大家留言批评指正。<br><strong>凡不能摧毁我者，必将使我更强大！！！</strong></p>]]></content>
      
      
      <categories>
          
          <category> 比赛总结 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 比赛算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>进程管理（二）</title>
      <link href="/2021/03/27/jin-cheng-guan-li-er/"/>
      <url>/2021/03/27/jin-cheng-guan-li-er/</url>
      
        <content type="html"><![CDATA[<h1>处理机调度</h1><h2 id="调度概念"><a class="header-anchor" href="#调度概念">¶</a>调度概念</h2><h3 id="调度的基本概念"><a class="header-anchor" href="#调度的基本概念">¶</a>调度的基本概念</h3><p>  因为在我们平时使用的多道程序系统中，进程的数量会多于处理机的个数，因此会经常出现进程争用处理机的情况。而处理机的调度就是<strong>对处理机进行分配，从就绪队列中按照一定的算法（公平、高效）选择一个进程并将处理机分配给它允许，以实现进程并发地执行。</strong></p><h3 id="调度层次"><a class="header-anchor" href="#调度层次">¶</a>调度层次</h3><p>  一个作业从提交开始直到完成，往往要经历以下的三级调度：<br>  （1）<strong>作业调度</strong>：主要任务是按一定的原则，从外存上处于后备状态的作业中挑选一个（或多个）作业，给它（们）分配内存、输入/输出设备等必要的资源，并建立相应的进程，以使它（们）获得竞争处理机的权利。<strong>多道批处理系统中大多数配有作业调度，而其他系统中通常不需要配置作业调度，并且作业调度的执行频率较低，通常为几分钟一次</strong>。<br>  （2）<strong>中级调度</strong>：为了提高内存利用率和系统吞吐量，应将那些暂时不能运行的进程调至外存等待，把此时的进程状态称为<strong>挂起态</strong>。当这些进程已经具备运行条件时且内存有空闲时，就由中级调度来决定把外存上的那些已经具备运行条件的就绪进程重新调入内存，并且修改其状态为就绪态，挂在就绪队列上等待。<br>  （3）<strong>进程调度</strong>：也被称为低级调度，按照某种方法和策略从就绪队列中选取一个进程，将处理机分配给它。<strong>进程调度是操作系统中最基本的一种调度</strong>，在一般的操作系统中都必须配置进程调度。<br><img src="/2021/03/27/jin-cheng-guan-li-er/1.png" alt="处理机的三级调度"><br>  因为在这里涉及到了作业和进程的调度，所以我在这里按照我的理解以及我参考其他的人博客中的理解来进行一定的解释（有误请大家私聊告诉我）。<br>  <strong>作业与进程的区别</strong>：一个进程是一个程序对某个数据集的执行过程，是资源的基本单位。作业是用户需要计算机完成的某项任务，是要求计算机所做工作的集合。一个作业的完成要经过作业提交、作业收容、作业执行和作业完成4个阶段。而进程是对已提交完毕的程序所执行过程的描述，是资源分配的基本单位。主要区别如下：<br>  （1）作业是用户向计算机提交任务的任务实体，在用户向计算机提交作业后，系统将它放入外存中的作业等待队列中等待执行。而进程则是完成用户任务的执行实体，是向系统申请分配资源的基本单位，任一进程，只要它被创建，总有相应的部分存在于内存中。<br>  （2）一个作业可由多个进程组成，且必须至少由一个进程组成，反过来不成立。<br>  （3）<strong>作业的概念主要用在批处理系统中</strong>，像分时系统中就没有作业的概念，而<strong>进程的概念则用在几乎所有的多道程序系统中</strong>。</p><h3 id="三级调度的联系"><a class="header-anchor" href="#三级调度的联系">¶</a>三级调度的联系</h3><p>  （1）作业调度为进程活动做准备，进程调度使进程正常活动起来，中级调度将暂时不能运行的进程挂起，中级调度处于作业调度和进程调度之间。<br>  （2）作业调度次数较少，中级调度次数略多，进程调度频率最高。<br>  （3）进程调度是最基本的，不可或缺的。</p><h2 id="调度的时机、切换与过程"><a class="header-anchor" href="#调度的时机、切换与过程">¶</a>调度的时机、切换与过程</h2><p>  进程调度和切换程序是操作系统内核程序。一般情况下，在请求调度的事件发生后，才可能运行进程调度程序，调度了新的就绪进程后，才会进行进程间的切换。但是在实际中可能会发送以下一些情况导致不能进行进程的调度与切换。<br>  （1）<strong>在处理中断的过程中</strong><br>  （2）<strong>进程在操作系统内核程序临界区中</strong>：进入临界区后，需要独占式的访问共享数据，理论上要加锁来防止其他程序进入，在解锁前不应切换到其他进程，以加快共享数据的释放。<br>  （3）<strong>其他需要完全屏蔽中断的原子操作过程中</strong>：如加锁、解锁、中断现场保护，即使中断也要进行相应的屏蔽。<br>  进行进程调度切换的情况如下:<br>  （1）发送引起调度条件且当前进程无法继续马上运行下去时，进行调度切换（非剥夺式调度）<br>  （2）中断处理结束或自陷处理结束后，返回被中断进程的用户态程序执行现场前，若置上请求调度标志，马上进行进程调度与切换（剥夺式调度）</p><h2 id="进程调度方式"><a class="header-anchor" href="#进程调度方式">¶</a>进程调度方式</h2><p>  （1）非剥夺调度方式：当一个进程在处理机上执行时，即使有更重要的进程进入就绪队列，处理机上的进程依然可以执行直到变为阻塞状态后，让出处理机。优点是<strong>实现简单，系统开销小适用于大多数的批处理系统，但是不适用于分时系统和大多数的实时系统</strong>。<br>  （2）剥夺调度方式：当一个在处理机上运行的进程在遇到另一个更为重要的进程进入就绪队列后，立即暂停，将处理机让出给更为重要的进程。<strong>对提高系统吞吐率和相应效率都有明显的好处</strong>。</p><h2 id="调度的基本准则"><a class="header-anchor" href="#调度的基本准则">¶</a>调度的基本准则</h2><p>  （1）<strong>CPU利用率</strong><br>  （2）<strong>系统吞吐量</strong>：表示单位时间内CPU完成作业的数量。<br>  （3）<strong>周转时间</strong>：从作业提交到作业完成所经历的时间，是作业等待、在就绪队列中排队、在处理机上运行以及进行输入/输出操作所花费时间的总和。<br>  作业的周转时间可用公式表示如下：<br>$$周转时间 = 作业完成时间 - 作业提交时间$$<br>  平均周转时间是指多个作业周转时间的平均值：<br>$$平均周转时间 = (作业1的周转时间 + … + 作业 n 的周转时间) / n$$<br>  带权周转时间是指作业周转时间与作业实际运行时间的比值。<br>  平均带权周转时间是指多个作业带权周转时间的平均值：<br>$$平均带权周转时间 = (作业1的带权周转时间 + … + 作业 n 的带权周转时间) / n$$<br>  （4）<strong>等待时间</strong>：指进程处于等处理机状态时间之和。因为处理机调度算法在实际上并不影响作业执行或输入/输出操作，只影响作业在就绪队列中等待所花的时间，所以衡量一个调度算法优劣常常只需简单地考察等待时间。<br>  （5）<strong>响应时间</strong>：是指从用户提交请求到系统首次产生响应所用的时间。</p><h2 id="典型的调度算法"><a class="header-anchor" href="#典型的调度算法">¶</a>典型的调度算法</h2><h3 id="先来先服务（FCFS）调度算法"><a class="header-anchor" href="#先来先服务（FCFS）调度算法">¶</a>先来先服务（FCFS）调度算法</h3><p>  在作业调度中，每次从后备队列中选择最先进入该队列的一个或几个作业，将它们调入内存，分配必要的资源，创建进程并放入就绪队列。进程调度类似。算法实例如下图所示：<br><img src="/2021/03/27/jin-cheng-guan-li-er/2.png" alt="FCFS调度算法性能"><br>  从上图中可以看出，该算法的特点是：算法简单，但是效率低；对长作业比较有利，对短作业不利；有利于CPU繁忙型作业，而不利于I/O繁忙型作业。</p><h3 id="短作业优先（SJF）调度算法"><a class="header-anchor" href="#短作业优先（SJF）调度算法">¶</a>短作业优先（SJF）调度算法</h3><p>  从队列中选出一个估计运行时间最短的作业优先调度，既可用于作业调度，也可用于进程调度。算法实例如下图所示：<br><img src="/2021/03/27/jin-cheng-guan-li-er/3.png" alt="SJF调度算法性能"><br>  SJF调度算法也存在不容忽视的缺点<br>  （1）<strong>对长作业不利</strong>。严重的是，若一长作业（进程）进入系统的后备队列（就绪队列），由于调度程序总是优先调度那些（即使是后进来的）短作业（进程），将导致长作业（进程）长期不被调度——饥饿<br>  （2）<strong>完全未考虑作业（进程）的紧迫程度，因而不能保证紧迫性作业（进程）会被及时处理</strong>。<br>  （3）由于作业（进程）的长短只是根据用户所提供的估计执行时间而定的，而用户又可能会有意或无意地缩短其作业的估计运行时间，致使该算法不一定能真正做到短作业优先调度。<br>  <strong>SJF调度算法的平均等待时间、平均周转时间最少</strong>。</p><h3 id="优先级调度算法"><a class="header-anchor" href="#优先级调度算法">¶</a>优先级调度算法</h3><p>  既可用于作业调度，又可用于进程调度。每次从后备作业队列中选择优先级最高的一个或几个作业（进程）进行执行。根据新的更高优先级进程能否抢占正在执行的进程，将调度算法分为两种（1）<strong>非剥夺式优先级调度算法</strong>、（2）<strong>剥夺式优先级调度算法</strong>。（在本文上面以及有讲解，此处省略。）<br>  根据进程创建后其优先级是否可以改变，可以将进程优先级分为以下两种。<br>  （1）<strong>静态优先权</strong>：静态优先权在创建进程时确定，且在进程的整个运行期间保持不变。确定进程优先权的依据有进程类型、进程对资源的需求、用户要求。<br>  （2）<strong>动态优先权</strong>：在创建进程时赋予的优先权是随进程的推进或随其等待时间的增加而改变，以获得更好的调度性能。<br>  在一般情况下，进程优先级的设置可以参照以下的原则：<br>  （1）<strong>系统进程 &gt; 用户进程</strong><br>  （2）交互型进程 &gt; 非交互型进程<br>  （3）I/O型进程 &gt; 计算型进程，因为I/O设备的处理速度要比CPU慢很多，所以需要让I/O设备尽早开始工作。</p><h3 id="高响应比优先调度算法"><a class="header-anchor" href="#高响应比优先调度算法">¶</a>高响应比优先调度算法</h3><p>  主要用于作业调度，既考虑作业估计的运行时间也考虑作业的等待时间，综合了先来先服务和最短作业优先两种算法的特点。该算法中的响应比是指作业等待时间与运行比值，响应比公式定义如下：<br>$$响应比R_{p} =（等待时间+要求服务时间）/ 要求服务时间$$<br>  优点有：（1）等待时间相同的作业，则要求服务的时间愈短，其优先权愈高，——对短作业有利；（2）要求服务的时间相同的作业，则等待时间愈长，其优先权愈高，——是先来先服务；（3）对于长作业，优先权随等待时间的增加而提高，其等待时间足够长时，其优先权便可升到很高， 从而也可获得处理机——对长作业有利。<br>  缺点：要进行响应比计算，增加了系统开销。</p><h3 id="时间片轮转调度算法"><a class="header-anchor" href="#时间片轮转调度算法">¶</a>时间片轮转调度算法</h3><p>  系统将所有的就绪进程按先来先服务的原则排成一个队列，每次调度时，把CPU分配给队首进程，并令其执行一个时间片；当执行的时间片用完时，由一个计时器发出时钟中断请求，调度程序便停止该进程的执行，并将其放就绪队列尾；然后，再把处理机分配给就绪队列中新的队首。<br>  <strong>时间片大小的选取很重要</strong>，若时间片足够大，以至于所有进程都能在一个时间片内执行完毕，则算法退化为先来先服务调度算法。若时间片很小，则处理机将在进程间过于频繁地切换，使得处理机的开销增大，而真正用于进程处理的时间很少。<br>  时间片的长短通常由：系统的响应时间、就绪队列中的进程数目和系统的处理能力来决定。</p><h3 id="多级反馈队列调度算法"><a class="header-anchor" href="#多级反馈队列调度算法">¶</a>多级反馈队列调度算法</h3><p>  是时间片轮转调度算法和优先级调度算法的综合。其具体思路如下：<br>  （1）先将它放入第一个队列的末尾，按FCFS原则排队等待调度。<br>  （2）如果时间片内完成，便可准备撤离系统。<br>  （3）如果时间片内未能完成，调度程序便将该进程转入第二队列的末尾等待再次被调度执行。<br>  （4）当第一队列中的进程都执行完，系统再按FCFS原则调度第二队列。在第二队列的稍放长些的时间片内仍未完成，再依次将它放入第三队列。<br>  （5）依次降到第n队列后，在第n队列中便采取按时间片轮转的方式运行。<br><img src="/2021/03/27/jin-cheng-guan-li-er/4.png" alt="多级反馈队列调度算法"><br>  需要注意的是以下几个方面：<br>  （1）设置多个就绪队列，各队列有不同的优先级,优先级从第一个队列依次降低。<br>  （2）赋予各队列进程执行时间片大小不同, 优先权越高，时间片越短。<br>  （3）仅当优先权高的队列（如第一队列）空闲时，调度程序才调度第二队列中的进程运行。<br>  （4）高优先级抢占时，被抢占的进程放回原就绪队列末尾。<br>  优点：（1）终端型作业用户：短作业优先。（2）短批处理作业用户：周转时间较短。（3）长批处理作业用户：经过前面几个队列得到部分执行，不会长期得不到处理。</p>]]></content>
      
      
      <categories>
          
          <category> 课本学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 操作系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>进程管理（一）</title>
      <link href="/2021/03/23/jin-cheng-guan-li-yi/"/>
      <url>/2021/03/23/jin-cheng-guan-li-yi/</url>
      
        <content type="html"><![CDATA[<h1>进程与线程</h1><h2 id="进程的概念与特征"><a class="header-anchor" href="#进程的概念与特征">¶</a>进程的概念与特征</h2><h3 id="进程的概念"><a class="header-anchor" href="#进程的概念">¶</a>进程的概念</h3><p>  <strong>进程概念</strong>：<strong>进程是进程实体的运行过程</strong>，<strong>是系统进行资源分配和调度的一个独立单位</strong>。<br>  在上述定义中，我们应该如何去理解进程实体？在最初的单道程序环境下，当我们的程序被载入到内存之后，它会被划分为程序段和数据段。如下图所示：<br><img src="/2021/03/23/jin-cheng-guan-li-yi/1.png" alt="程序在内存存储图"><br>  但是在早期，由于计算机内存只支持一道应用程序，所以我们把该进程的程序段和数据段放在固定的位置。但是随之计算机的发展，计算机可以支持多道程序并发运行，操作系统为了去记录这些进程的程序段和数据段的位置，构建了一个叫<strong>程序控制块</strong>（<strong>PBC</strong>）的数据结构来存放这些信息。如下图所示：<br><img src="/2021/03/23/jin-cheng-guan-li-yi/2.png" alt="PBC存储信息"><br>  至此，可以使参与并发执行的程序（包括数据）能够独立地运行，因此<strong>进程实体</strong>=<strong>PCB</strong>+<strong>程序段</strong>+<strong>数据段</strong>。（进程实体也可以称为进程映像）所以<strong>进程创建的实质就是创建进程映像中的PCB</strong>，反之如此。在这里可以看出<strong>PCB是进程存在的唯一标志</strong>。在一般情况下，我们把进程实体就称为进程，但是严格来说，<strong>进程实体和进程并不一样，进程实体是静态的，而进程是动态的</strong>。<br>  同时在进程的定义中，要准确的理解其系统资源，在定义中的系统资源实际上是指处理机、存储器和其他设备服务于某个进程的“时间”。因为进程在多道程序中并发执行时，通常由处理机的时间片为其分配运行时间，这也决定了进程一定是一个动态的概念。</p><h3 id="进程的特征"><a class="header-anchor" href="#进程的特征">¶</a>进程的特征</h3><p>  因为在多道程序环境下，允许多个程序并发执行，在这个过程中，这些程序就失去了封闭性，因此引出进程，所以进程的基本特征也是对进程管理提出的基本要求。<br>（1）<strong>动态性</strong>：进程是程序的一次执行，从创建到活动、暂停、终止等过程，具有自己的生命周期，是动态地产生、变化和消亡的。该特性是进程最基本的特性。<br>（2）<strong>并发性</strong>：顾名思义，多个进程实体可以同时存在于内存中，进程能够在同一时间段内同时运行，该特性是操作系统的重要特征，使程序与其他进程的程序并发执行，提高了资源利用率。<br>（3）<strong>独立性</strong>：指进程实体是一个能独立运行、独立获得资源和独立接受调度的基本单位。<strong>注意</strong>：必须是进程实体，也就是说，必须要创建PCB！！！。<br>（4）<strong>异步性</strong>：由于进程的相互制约，使得进程具有执行的间断性，即进程按各自独立的、不可预知的速度向前推进，比如，当正在执行的进程提出某种资源请求时，如打印请求，而此时打印机正在为其他某进程打印，由于打印机属于临界资源，因此正在执行的进程必须等待，且放弃处理机，直到打印机空闲，并再次把处理机分配给该进程时，该进程方能继续执行。可见，由于资源等因素的限制，进程的执行通常都不是“一气呵成”，而是以“停停走走”的方式运行。异步性就是描述进程这种以不可预知的速度走走停停、何时开始何时暂停何时结束不可预知的性质。异步性会导致执行结果的不可再现性，为此操作系统中必须配置响应的进程同步机制。<br>（5）<strong>结构性</strong>：每个进程都配置一个PCB对其进行描述，其结构为<strong>PCB</strong>+<strong>程序段</strong>+<strong>数据段</strong>。</p><h2 id="进程的状态与转换"><a class="header-anchor" href="#进程的状态与转换">¶</a>进程的状态与转换</h2><p>  进程在其生命周期内，由于进程之间的相互制约以及系统的运行环境的变化，导致其状态也在不断地发生变化。在一般情况下存在以下五种状态：<br>  （1）<strong>运行态</strong>：进程在处理及上运行，并且在单机环境下，每个时刻最多只有一个进程在运行。<br>  （2）<strong>就绪态</strong>：进程获得了除处理机外的一切所需资源，一旦得到处理机，便可立即运行。系统中处于就绪状态的进程可能有多个，通常将它们排成一个队列，称为就绪队列。<br>  （3）<strong>阻塞态</strong>：又称<strong>等待态</strong>，进程正在等待某一事件而暂停运行，如等待某资源为可用（<strong>不包括处理机，这点与就绪态有明显的差别</strong>）或等待输入/输出完成，即使处理机空闲，该程序也不能运行。<br>  （4）<strong>创建态</strong>：进程正在被创建，尚未转到就绪态。创建进程通常需要多个步骤：首先申请一个空白的PCB，并向PCB中填写一些控制和管理进程的信息；然后由系统为该该进程分配运行时所必须的资源；最后把该进程转入就绪态。<br>  （5）<strong>结束态</strong>：进程正从系统中消失，可能是进程正常结束或其他原因中断推出运行。进程需要结束运行时，系统首先必须将该进程置为结束态，然后进一步处理资源释放和回收等工作。<br>  <strong>注意</strong>，就绪态和等待态是不同的，因为就绪态是指进程仅缺少处理机，只要获得处理机资源就立即运行；而等待态是指进程需要其他资源（除了处理机）或等待某一事件。五种进程状态的转换情况如下图所示：<br><img src="/2021/03/23/jin-cheng-guan-li-yi/3.png" alt="5种进程状态的转换"><br>  （1）<strong>就绪态</strong>$\rightarrow$<strong>运行态</strong>：处于就绪态的进程被调度后，获得处理机资源（分派处理机时间片），于是进程由就绪态转换为运行态。<br>  （2）<strong>运行态</strong>$\rightarrow$<strong>就绪态</strong>：当处于运行态的进程在时间片用完之后，会让出处理机，转化为就绪态，或者在可剥夺的操作系统种，当有更高级的进程就绪时，调度程序将正在执行的进程转化为就绪态，让更高级的进程执行。<br>  （2）<strong>运行态</strong>$\rightarrow$<strong>阻塞态</strong>：进程请求某一资源的使用和分配或等待某一事件的发生（例如I/O操作的完成）时，就会从运行态转换为阻塞态。<strong>进程以系统调用的形式请求操作系统提供服务，这是一种特殊的、由运行用户态程序调用操作系统内核过程的形式</strong>。<br>  需要注意的是，一个进程从运行态变成阻塞态是主动行为，而从阻塞态变成就绪态是被动的行为，需要其他相关进程协助。</p><h2 id="进程控制"><a class="header-anchor" href="#进程控制">¶</a>进程控制</h2><p>  进程控制主要是对系统中的所有进程实施有效的管理，其具有创建新进程、撤销已有进程、实现进程状态转换等功能。通常，我们把进程控制用的程序段称为<strong>原语</strong>。它是一个不可分割的基本单位。</p><h3 id="进程的创建"><a class="header-anchor" href="#进程的创建">¶</a>进程的创建</h3><p>  一个进程可以创建另一个进程，创建者为父进程，被创建的进程称为子进程。子进程可以继承父进程所拥有的资源。并且在其被撤销时，要归还所有从父进程那里得到的资源。当父进程被撤销时，必须撤销其所有的子进程。创建进程的过程如下：<br>  （1）为新进程分配一个唯一的标识号，并且申请一个空白的PCB，<strong>若PCB申请失败，则创建失败</strong>，这与在上文中（进程的概念）我解释的进程创建的实质相对应。<br>  （2）为进程分配资源，例如为程序和数据以及用户栈分配必要的内存空间。当资源不足时，进程会进入阻塞态。<br>  （3）初始化PCB，设置进程优先级等。<br>  （4）当进程就绪队列可以接纳新进程后，就将新进程插入队列中，等待被调度运行。</p><h3 id="进程的终止"><a class="header-anchor" href="#进程的终止">¶</a>进程的终止</h3><p>  在进程被执行的过程中，通常会因为一些事件而引起进程终止。主要由以下的几种情况：<br>  （1）正常结束。<br>  （2）异常结束，如存储区越界，非法指令、I/O故障等使程序无法继续运行。<br>  （3）外界干预：程应外界的请求而终止运行，例如：操作员和操作系统的干预，父进程请求和父进程终止。<br>  操作系统终止进程的过程如下：<br>  （1）根据被终止进程的标识符，检索PCB，从中读出该进程的状态。<br>  （2）若被终止进程处于执行状态，立即终止该进程的执行，将处理机资源分配给其他进程。<br>  （3）若该进程还有子孙进程，则应将其所有的子孙进程终止。<br>  （4）将该进程所有的资源全部归还与父进程或者操作系统。<br>  （5）将PCB从所在队列（链表中）删除。</p><h3 id="进程的阻塞和唤醒"><a class="header-anchor" href="#进程的阻塞和唤醒">¶</a>进程的阻塞和唤醒</h3><p>  正在执行的进程由于期待的某些事件未发生，由系统自动执行阻塞原语（Block，也就是执行阻塞程序），使自己由运行态变为阻塞态。对此可以看出，<strong>进程的阻塞是进程自身的一种主动行为，同时，也只有处于阻塞态的进程（获得了CPU）才可能将其转为阻塞态</strong>。阻塞原语的执行过程如下：<br>  （1）找到将要被阻塞进程的标识号对应的PCB。<br>  （2）若该进程为运行态，则保护其现场，将其状态转为阻塞态，停止运行。<br>  （3）把该PCB插入相应时间的等待队列，将处理机资源调度给其他就绪进程。<br>  当阻塞进程所期待的事件出现时，由有关进程调用唤醒原语，将该进程唤醒。唤醒原语（Wakeup）的执行过程如下：<br>  （1）把该事件的等待队列种找到相应进程的PCB。<br>  （2）将其从等待队列中移除，并置其状态为就绪态。<br>  （3）把该PCB插入就绪队列，等待调度程序调度。<br>  需要注意的是，这一对原语作用恰好相反，必须成对使用，<strong>其中阻塞原语是被阻塞进程自我调用实现的，而唤醒原语则是有一个被唤醒进程合作或被其他相关进程调用实现的。</strong></p><h3 id="进程切换"><a class="header-anchor" href="#进程切换">¶</a>进程切换</h3><p>  通常情况下，进程的创建、撤销等操作都是利用系统调用进入内核，在内核中由相应处理程序完成的。而进程的切换是指处理机从一个进程的运行转到另一个进程上的运行，同样需要内核的支持，所以<strong>任何进程都是在操作系统内核的支持下运行的</strong>，其切换过程如下：<br>  （1）保存处理机上下文，包括程序计数器和其他寄存器。<br>  （2）更新PCB信息<br>  （3）把进程的PCB移入到相应的队列，如就绪、在某事件阻塞等队列。<br>  （4）选择另一个进程执行，并更新其PCB。<br>  （5）更新内存管理的数据结构。<br>  （6）恢复处理机上下文。<br>  需要注意一点的是，<strong>调度和切换是两种不同的情况，调度是指决定资源分配给哪个进程的行为，是一种决策行为，而切换则是指实际分配的行为，是执行行为。</strong></p><h2 id="进程的组织"><a class="header-anchor" href="#进程的组织">¶</a>进程的组织</h2><p>  **进程是一个独立的运行单位，也是操作系统进程资源分配和调度的基本单位。**由PCB + 数据段 + 程序段组成。其中最为核心的部分是PCB。</p><h3 id="进程控制块（PCB）"><a class="header-anchor" href="#进程控制块（PCB）">¶</a>进程控制块（PCB）</h3><p>  操作系统通过PCB表来管理和控制进程。在进程创建时，操作系统为进程新建一个PCB，该结构之后可以存储在内存中，并且在任意时刻都可以存取，在进程的执行过程中，系统可以通过PCB来了解进程的先行状态信息，以便对其进行管理和控制，在进程结束时，系统收回其PCB，该进程也随之消亡。并且在PCB中还保存了进程状态及优先级，处理机状态信息，数据和程序的内存初始地址。发生断点的处理机环境。<br>  为了方便进程的调度和管理，需要将各进程的PCB用适当的方法组织起来，目前常用的方法有链式法和索引法。链式方式就是将同一状态的PCB链接成队列的。索引方式是将同一状态的进程组织在一个索引表中，索引表的表项指向相应的PCB。</p><h3 id="程序段"><a class="header-anchor" href="#程序段">¶</a>程序段</h3><p>  程序段就是能被进程调度程序调度到CPU执行的程序代码段。<strong>程序可被多个进程共享，即多个进程可有运行同一个程序</strong>。</p><h3 id="数据段"><a class="header-anchor" href="#数据段">¶</a>数据段</h3><p>  一个进程的数据段，可以是进程对应的程序加工处理的原始数据，也可以是程序执行时产生的中间或最终结果。</p><h2 id="进程的通信"><a class="header-anchor" href="#进程的通信">¶</a>进程的通信</h2><p>  进程通信是指进程之间的信息交换。其中PV操作属于低级通信方式，而高级通信是指以较高的效率传输大量数据的通信方式。高级通信主要有以下三种方式：</p><h3 id="共享存储"><a class="header-anchor" href="#共享存储">¶</a>共享存储</h3><p>  在通信的进程之间存在一块可直接访问的共享空间，通过对这片共享空间进行读/写操作，实现进程之间的信息交换。操作系统只负责为通信进程提供可共享使用的存储空间和同步互斥工具（P/V原语），而其中的数据交换则由用户自己安排读/写指令完成。共享存储又分为两种：（1）低级方式的基于数据结构的共享。（2）高级方式的基于存储区的共享。<br>  <strong>用户进程空间一般都是独立的，进程运行期间一般不能访问其他进程空间，必须通过特殊的系统调用才能实现。进程内的线程是自然共享进程空间的</strong>。<br><img src="/2021/03/23/jin-cheng-guan-li-yi/4.png" alt="共享存储"></p><h3 id="消息传递"><a class="header-anchor" href="#消息传递">¶</a>消息传递</h3><p>  在消息传递系统中，进程间的数据交换是以格式化的消息为单位的。<strong>如果通信的进程之间不存在可直接访问的共享空间，则必须利用操作系统提供的消息传递方法实现进程通信</strong>。操作系统为进程提供了发送消息和接收消息两个原语来进行数据交换。消息传递的通信方式分为两种。<br>  （1）直接通信方式：发送进程把消息发送给接收进程，把消息挂在接收进程的消息缓冲队列上，接收进程从消息缓冲队列中得到消息。该过程可以看作两个人之间写信进行交流的过程。<br><img src="/2021/03/23/jin-cheng-guan-li-yi/5.png" alt="直接通信方式"><br>  （2）间接通信方式：即发送在某个实体，接收进程从该实体中获取消息。该实体类似于一个邮差的功能。</p><h3 id="管道通信"><a class="header-anchor" href="#管道通信">¶</a>管道通信</h3><p>  管道通信时消息传递的一种特殊方式。这里的“管道”是指用于连接一个读进程和一个写进程，以实现它们之间的通信的一个共享文件。其中向管道输入和接收数据都是由进程实现的。为了协调读写进程的通信，管道机制必须提供<strong>互斥</strong>、<strong>同步和确定对方的存在</strong>的三方面能力。<br>  <strong>从管道读数据是一次性操作，数据一旦被读取，它就从管道中被抛弃，释放空间以便写入更多的数据。并且管道在某一时刻只能单向传输，要实现父子进程双方互动通信，需要定义两个管道</strong>。</p><h2 id="线程的概念和多线程模型"><a class="header-anchor" href="#线程的概念和多线程模型">¶</a>线程的概念和多线程模型</h2><h3 id="线程的基本概念"><a class="header-anchor" href="#线程的基本概念">¶</a>线程的基本概念</h3><p>  <strong>引入进程的目的是更好地使多道程序并发执行，提高资源利用率和系统吞吐量；引入线程的目的则是减小程序在并发执行时所付出的时空开销，提高操作系统的并发性能。</strong><br>  <strong>线程是一个基本的CPU执行单元，也是程序执行流的最小单元。线程是进程中的一个实体，是被系统独立调度和分配的基本单位（与进程要进行区分，进程是系统进行资源分配和调度的一个独立单位）</strong><br>  <strong>线程自己不拥有系统资源，只拥有一点在运行中必不可少的资源。但是它可与同属一个进程的其他线程共享进程所拥有的全部资源。</strong><br>  <strong>一个线程可以创建和撤销另一个线程，同一个进程中的多个线程之间可以并发执行。</strong><br>  由于线程之间的相互制约，致使线程在运行中呈现出间断性。并且线程也有就绪、阻塞和运行三种状态。</p><h3 id="进程与线程的比较（理解重点）"><a class="header-anchor" href="#进程与线程的比较（理解重点）">¶</a>进程与线程的比较（理解重点）</h3><p>  （1）调度：<strong>线程是独立调度的基本单位，进程是拥有资源的基本单位</strong>，在同一进程中，线程的切换不会引起进程的切换，。在不同进程中进行线程切换，会引起进程切换。<br>  （2）拥有资源：进程是拥有资源的基本单位，而线程不拥有系统资源。但线程可以访问其隶属进程的系统资源。<br>  （3）并发性：不仅进程之间可以并发执行，而且多个线程之间也可以并发执行，从而使操作系统具有更好的并发性，提高系统的吞吐量。<br>  （4）系统开销：由于创建或撤销进程时，系统都要为之分配或回收资源，因此操作系统所付出的开销远大于创建或撤销线程时的开销。因为同一进程内的多个线程共享进程的地址空间，所以这些线程之间的通信非常容易实现，甚至无需操作系统的干预。<br>  （5）地址空间和其他资源：进程的地址空间之间相互独立，同一进程的各线程间共享进程的资源，某进程内的线程对于其他进程不可见。<br>  （6）通信方面：进程间通信需要进程同步和互斥手段的辅助，以保证数据的一致性，而线程间可以直接读/写进程数据段（如全局变量）来进行通信。</p><h3 id="线程的属性"><a class="header-anchor" href="#线程的属性">¶</a>线程的属性</h3><p>  在多线程操作系统把线程作为独立运行（或调度）的基本单位之后，进程就已经不再是一个基本的可执行实体。因此所谓进程处于“执行状态”，实际上是指该进程中的某线程正在执行。线程的主要属性如下：<br>  （1）线程不拥有系统资源，但每个线程有一个唯一的标识符和一个线程控制块，其记录了线程执行的寄存器和栈等现场状态。<br>  （2）不同的线程可以执行相同的程序。<br>  （3）同一个进程中的各个线程共享该进程所拥有的资源。<br>  （4）线程是处理机的地理调度单位，多个线程是可以并发执行的。<br>  （5）一个线程被创建后，便开始了它的生命周期，直至终止。</p><h3 id="线程的实现方式"><a class="header-anchor" href="#线程的实现方式">¶</a>线程的实现方式</h3><p>  分为用户级线程和内核级线程。</p><h3 id="多线程模型"><a class="header-anchor" href="#多线程模型">¶</a>多线程模型</h3><p>  有些系统支持用户线程和内核线程，由此产生了不同的多线程模型，即实现用户级线程和内核级线程的连接方式。主要有（1）多对一模型、（2）一对一模型、（3）多对多模型。</p>]]></content>
      
      
      <categories>
          
          <category> 课本学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 操作系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计算机系统概述（三）</title>
      <link href="/2021/03/22/ji-suan-ji-xi-tong-gai-shu-san/"/>
      <url>/2021/03/22/ji-suan-ji-xi-tong-gai-shu-san/</url>
      
        <content type="html"><![CDATA[<h1>操作系统的运行环境</h1><h2 id="操作系统的运行机制"><a class="header-anchor" href="#操作系统的运行机制">¶</a>操作系统的运行机制</h2><p>  在计算机系统中，CPU通常会执行两种不同性质的程序，（1）<strong>操作系统的内核程序即管理程序</strong>，（2）<strong>用户自编程序即应用程序</strong>。<br>  <strong>管理程序</strong>：执行一些特权指令，这些指令不允许用户直接使用，例如I/O指令、置中断指令、存取用于内存保护的寄存器等。<br>  <strong>用户自编程序</strong>：出于安全考虑不能执行这些指令。<br>  用户自编程序运行在用户态，操作系统内核程序运行在核心态。并且现在操作系统几乎都是层次式的结构。操作系统的各项功能分别被设置在不同的层次上。一些与硬件关联较紧密的模块，如时钟管理、中断处理、设备驱动等处于最底层；其次是一些运行频率较高的程序，如进程管理、存储器管理和设备管理等。并且上面的这两部分构成了操作系统的<strong>内核</strong>，内核的指令操作工作在<strong>核心态</strong>。内核主要包括以下四部分内容。</p><h3 id="时钟管理"><a class="header-anchor" href="#时钟管理">¶</a>时钟管理</h3><p>  时钟管理的主要作用如下几点：<br>  （1）计时，即向用户提供标准的系统时间。<br>  （2）<strong>通过时钟中断的管理，切换进程</strong>。在分时操作系统中就有很好的体现（采用时间片轮转调度）。<br>  （3）衡量作业的运行程度（在批处理系统中，无论是多道批处理系统还是单道批处理系统，在微观上都是属于串行，因此可以用作业的执行时间来衡量作业的运行程度）。</p><h3 id="中断机制"><a class="header-anchor" href="#中断机制">¶</a>中断机制</h3><p>  在中断机制中，只有一小部分功能属于内核，它们保护和恢复中断现场的信息，转移控制权到相关的处理程序。提高系统的并行处理能力。并且可以提高多道程序运行环境中CPU的利用率。例如：<strong>进程的管理和调度</strong>，<strong>系统功能的调用</strong>，<strong>设备驱动</strong>……</p><h3 id="原语"><a class="header-anchor" href="#原语">¶</a>原语</h3><p>  按照上述所说的，操作系统是层次式的结构，那么在其底层一定是一些可被调用的具有特定功能的公用程序，例如：CPU切换、设备驱动等，因此将这些称为<strong>原语</strong>。其具有以下的特征：<br>  （1）处于操作系统的最底层，最接近硬件的部分。<br>  （2）其运行具有原子性，其操作必须一次性完成。<br>  （3）被频繁调用，且运行时间较短。</p><h3 id="系统控制的数据结构及处理"><a class="header-anchor" href="#系统控制的数据结构及处理">¶</a>系统控制的数据结构及处理</h3><p>  用来等级状态信息的数据结构，如作业控制块、进程控制块、消息队列、链表、内存分配表等。其常见操作有以下3种：<br>  （1）<strong>进程管理</strong>：进程状态管理、进程调度和分派、创建与撤销进程控制块等。<br>  （2）<strong>存储器管理</strong>存储器的空间分配和回收、内存信息保护程序、代码对换程序等。<br>  （3）<strong>设备管理</strong>：缓冲区管理、设备分配和回收。</p><h2 id="中断和异常"><a class="header-anchor" href="#中断和异常">¶</a>中断和异常</h2><h3 id="定义"><a class="header-anchor" href="#定义">¶</a>定义</h3><p>  <strong>CPU运行上层程序时，唯一可以实现从用户态进入核心态的方式就是中断或异常</strong>。并且中断可以在程序并未使用某种资源时，把它对那种资源的占有权释放，提高资源利用率。<br>  <strong>中断</strong>：指计算机运行过程中，出现某些意外情况需主机干预时，机器能自动停止正在运行的程序并转入处理新情况的程序，处理完毕后又返回原被暂停的程序继续运行。<br>  <strong>异常</strong>：指的是在程序运行过程中发生的异常事件，通常是由外部问题（如硬件错误、输入错误）所导致的。</p><h3 id="中断处理过程"><a class="header-anchor" href="#中断处理过程">¶</a>中断处理过程</h3><p>  中断处理流程图如下图所示：<br><img src="/2021/03/22/ji-suan-ji-xi-tong-gai-shu-san/1.png" alt="中断处理的流程"><br>  （1）<strong>关中断</strong>：CPU响应中断后，首先要保护程序的现场状态，不应响应更高级中断源的中断请求。否则现场会保存不完整。<br>  （2）<strong>保存断点</strong>：将原来的程序断点保存起来，在中断服务程序执行完毕后能正确地返回到原来的程序。<br>  （3）<strong>中断服务程序寻址</strong>：取出中断服务程序的入口地址送入程序计数器PC。<br>  （4）<strong>保存现场和屏蔽字</strong>：现场信息一般是指程序状态字寄存器PSWR和某些通用寄存器的内容。<br>  （5）<strong>开中断</strong>：允许更高级中断请求得到响应。<br>  （6）<strong>关中断</strong>：保证在恢复现场和屏蔽字时不被中断。<br>  （7）<strong>开中断、中断返回</strong>：中断服务程序的最后一条指令通常是一条中断返回指令，使其返回到原程序的断点处，以便继续执行原程序。</p><h3 id="系统调用"><a class="header-anchor" href="#系统调用">¶</a>系统调用</h3><p>  系统中的各种共享资源都由操作系统统一掌管，因此在用户程序种，凡是与资源有关的操作（如存储分配、进行I/O传输及管理文件等），都必须通过系统调用方式向操作系统提出服务请求，并由操作系统代为完成。系统调用功能大致可分为如下几类：<br>  （1）<strong>设备管理</strong>：完成设备的请求或释放，以及设备启动等功能。<br>  （2）<strong>文件管理</strong>：完成文件的读、写、创建即删除等功能。<br>  （3）<strong>进程控制</strong>：完成进程的创建、撤销、阻塞及唤醒等功能。<br>  （4）<strong>进程通信</strong>：完成进程之间的消息传递或信号传递等功能。<br>  （5）<strong>内存管理</strong>：完成内存的分配、回收以及获取作业占用内存区大小及实址等功能。<br>  这样做的好处是<strong>保证系统的稳定性和安全性，防止用户程序随意更改或访问重要的资源系统，影响其他进程的运行</strong>。</p><p>  操作系统的运行环境可以理解为：用户通过操作系统运行上层程序（如用户自编程序），而上层程序的运行需要操作系统的底层管程序提供服务支持。当需要管理程序服务时，系统通过硬件中断机制进入核心态，运行管理程序，或者在出现异常时，被动提供管理程序服务。实现了从用户态转入核心态，在管理服务程序结束后，保存程序现场退出中断处理程序或异常处理程序，返回断点处继续执行用户自编程序。具体流程图如下所示：<br><img src="/2021/03/22/ji-suan-ji-xi-tong-gai-shu-san/2.png" alt="系统调用执行过程"></p>]]></content>
      
      
      <categories>
          
          <category> 课本学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 操作系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计算机系统概述（二）</title>
      <link href="/2021/03/22/ji-suan-ji-xi-tong-gai-shu-er/"/>
      <url>/2021/03/22/ji-suan-ji-xi-tong-gai-shu-er/</url>
      
        <content type="html"><![CDATA[<h1>操作系统的发展与分类</h1><h2 id="手工操作阶段"><a class="header-anchor" href="#手工操作阶段">¶</a>手工操作阶段</h2><p>  所有的工作都需要人工干预，缺点如下：<br>  （1）用户独占全机，虽然不会出现因资源已被其他用户占用而等待的现象，但资源利用低。<br>  （2）CPU等待手工操作，CPU的利用不充分。</p><h2 id="批处理阶段（操作系统开始出现）"><a class="header-anchor" href="#批处理阶段（操作系统开始出现）">¶</a>批处理阶段（操作系统开始出现）</h2><p>  解决人机矛盾及CPU和I/O设备之间速度不匹配的矛盾，出现了单道批处理系统和多道批处理系统。</p><h3 id="单道批处理系统"><a class="header-anchor" href="#单道批处理系统">¶</a>单道批处理系统</h3><p>  主要特征：<br>  （1）<strong>自动性</strong>：在顺利的情况下，磁带上的一批作业能自动地逐个运行，而且无须人工干预。<br>  （2）<strong>顺序性</strong>：磁带上的各道作业顺序地进入内存，先调入内存的作业先完成。<br>  （3）<strong>单道性</strong>：内存中仅有一道程序运行，当该程序完成或发生异常情况时，才换入其后继程序进入内存运行。<br>  缺点：内存中作业运行期间发出输入/输出请求后，高速的CPU要等待低速的I/O完成，资源利用率和系统的吞吐量较低。</p><h3 id="多道批处理系统"><a class="header-anchor" href="#多道批处理系统">¶</a>多道批处理系统</h3><p>  多道批处理系统允许多个程序同时进入内存并允许它们在CPU中交替地运行，这些程序共享系统中的各种硬/软件资源，当一道程序因I/O请求而暂停运行时，CPU便立即转去运行另一道程序。<br>  主要特征如下：<br>  （1）<strong>多道</strong>：计算机内存中同时存放多道相互独立的程序。<br>  （2）<strong>宏观上并行</strong>：同时进入系统的多道程序都处于运行过程中，即各自运行，但都未运行完毕。<br>  （3）<strong>微观上串行</strong>：内存中的多道程序轮流占有CPU，交替执行。<br>  多道程序设计技术的实现需要解决以下问题：<br>  （1）如何分配处理器。<br>  （2）多道程序的内存分配问题。<br>  （3）I/O设备如何分配。<br>  （4）如何组织和存放大量的程序和数据，以方便用户使用并保证其安全性与一致性。<br>  <strong>优点</strong>：（1）资源利用率高。（2）系统吞吐量大，CPU和其他资源保持“忙碌”状态。<br>  <strong>缺点</strong>：（1）用户响应的时间较长。（2）不提供人机交互能力，用户既不了解自己程序的运行情况，又不能控制计算机。</p><h2 id="分时操作系统"><a class="header-anchor" href="#分时操作系统">¶</a>分时操作系统</h2><p>  <strong>分时技术</strong>：把处理及的运行时间分成很短的时间片，按时间片把处理器分配给各联机作业使用。若某个作业在分配给它的时间片内不能完成其计算，则该作业暂时停止运行，把处理器让给其他的作业使用，等待下一次继续使用。<br>  <strong>分是操作系统</strong>：用户通过终端同时共享一台主机，这些终端连接在主机上，用户可以同时与主机进行交互操作而互不干扰。分时系统特征如下：<br>  （1）<strong>同时性</strong>：允许多个终端用户同时使用一台计算机。<br>  （2）<strong>交互性</strong>：用户可以方便地与系统进行人机对话。<br>  （3）<strong>独立性</strong>：多个用户可以彼此独立操作，互不干扰。<br>  （4）<strong>及时性</strong>：用户在请求计算机时可以很快得到响应。<br><strong>分时操作系统也是支持多道程序设计的，但是与多道批处理系统还是存在差别的</strong>，具体差别如下：<br>  多道程序系统是在计算机内存中同时存放几道相互独立的程序，使它们在管理程序控制之下，相互穿插的运行。 两个或两个以上程序在计算机系统中同处于开始和结束之间的状态。这就称为多道程序技术运行的特征：多道、宏观上并行、微观上串行。<br>  分时操作系统是使一台计算机同时为几个、几十个甚至几百个用户服务的一种操作系统。把计算机与许多终端用户连接起来，分时操作系统将系统处理机时间与内存空间按一定的时间间隔，轮流地切换给各终端用户的程序使用。由于时间间隔很短，每个用户的感觉就像他独占计算机一样。<br>  总之，分时操作系统主要是针对于多用户来说的，而多道程序系统主要是针对于多程序来说的，注意用户和程序之间的区别。</p><h2 id="实时操作系统"><a class="header-anchor" href="#实时操作系统">¶</a>实时操作系统</h2><p>  可以在某个时间限制内完成某些紧急任务而不需要时间片排队。其分为两种情况：<br>  （1）<strong>硬实时系统</strong>：某个动作必须要在规定的时刻或时间段内完成，如飞行自动控制系统。<br>  （2）<strong>软实时系统</strong>：偶尔违反时间规定且不会引起任何永久性的损害。如飞机订票系统。</p><h2 id="网络操作系统"><a class="header-anchor" href="#网络操作系统">¶</a>网络操作系统</h2><p>  通过计算机网络把各台计算机联合在一起，实现各台计算机之间数据的互相传送。<br>  <strong>特点</strong>：网络中各种资源的共享及计算机之间的通信。</p><h2 id="分布式计算机系统"><a class="header-anchor" href="#分布式计算机系统">¶</a>分布式计算机系统</h2><p>  属于分布式计算机系统需要满足以下条件：<br>  （1）系统中任意两台计算机通过通信方式交换信息。<br>  （2）系统中的每台计算机具有相同的地位。<br>  （3）每台计算机的资源为所有用户共享。<br>  （4）任意台计算机都可以构成子系统，并且可以重构。<br>  （5）任何工作都可以分布在几台计算机上，由他们协同完成。<br>  主要特点如下：<strong>分布性</strong>和<strong>并行性</strong>。</p><h2 id="个人操作系统"><a class="header-anchor" href="#个人操作系统">¶</a>个人操作系统</h2><p>  有常见的Windows、Linux、Macintosh等，应用最为广泛。</p><p>  还有嵌入式操作系统、服务器操作系统等。</p>]]></content>
      
      
      <categories>
          
          <category> 课本学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 操作系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计算机系统概述（一）</title>
      <link href="/2021/03/20/ji-suan-ji-xi-tong-gai-shu-yi/"/>
      <url>/2021/03/20/ji-suan-ji-xi-tong-gai-shu-yi/</url>
      
        <content type="html"><![CDATA[<h1>操作系统的基本概念</h1><h2 id="什么是操作系统？"><a class="header-anchor" href="#什么是操作系统？">¶</a>什么是操作系统？</h2><p>  操作系统（Operating System， OS）是指：控制和管理整个计算机系统的硬件与软件资源，合理地组织、调度计算机的工作与资源的分配，进而为用户和其他软件提供方便的接口和环境的程序集合。<strong>操作系统是计算机系统中最基本的系统软件</strong>。<br>  其作用简单来说：<br>（1）控制和管理整个计算机系统的硬件与软件资源。<br>（2）组织和调度计算机工作和资源的分配。<br>（3）提供给用户和其他软件方便的接口和环境。</p><h2 id="操作系统的特征"><a class="header-anchor" href="#操作系统的特征">¶</a>操作系统的特征</h2><p>  操作系统是一种系统软件，其基本特征包括<strong>并发、共享、虚拟和异步</strong>。</p><h3 id="（1）并发（Concurrence）"><a class="header-anchor" href="#（1）并发（Concurrence）">¶</a>（1）并发（Concurrence）</h3><p>  并发是指两个或多个事件在同一时间间隔内发生。操作系统的并发性是指计算机系统中同时存在多个运行的程序。因此我们可以认为它有上述的作用（2）.同时在整个操作系统中，我们引入进程的目的，也是为了使程序能并发执行。<br>  在上面我们需要注意的是，并发和并行的区别，通俗来说，并发是指事情同一时间段内发生，例如在我写这篇博客的整个时间段内，我顺便去偷看了旁边几个漂亮的妹纸，在宏观上来说，这些事情都是在这个时间段上是同时发生的，但是在微观上的其中几分钟，几秒钟来说，这些事情其实是交替发生的，整个过程大致就是“写博客-看妹纸-写博客-看妹纸-看妹纸-写博客”（不好意思，其实我只看了一次😇 😇 😇）而并行是指在同一时刻发生的，例如在我偷看妹纸的时候，发现我对面的哥们（经典无中生友😂 😂 😂）其实也在和我一样，不过他在偷看旁边的男生😳 😳 😳，那么我们两个人在相同的时刻做的这件事情，这就叫做并行。<br>  在我们进行提到的多线程中，如果你的电脑为单核CPU，那么即使你加再多的线程，也是并发执行，因为一个核心，只能处理一个任务。一个核心处理多任务的方法，（1）排队，一个一个执行。（2）一个执行一小段时间，在多个任务间切换，没有被服务的任务只能等待，表现就是你的电脑会有些卡顿。如果你的CPU有两个核心，那么它的每个核心，在此时此刻，可以分别服务一个任务，这样就可以实现并行。</p><h3 id="（2）共享（Sharing）"><a class="header-anchor" href="#（2）共享（Sharing）">¶</a>（2）共享（Sharing）</h3><p>  即资源共享，是指操作系统中的资源可供内存中多个并发执行的进程共同使用。共享主要分为<strong>互斥共享方式</strong>和<strong>同时访问方式</strong>。</p><h4 id="互斥共享方式"><a class="header-anchor" href="#互斥共享方式">¶</a>互斥共享方式</h4><p>  操作系统中的资源虽然可以同时提供给多个进程使用，但一个时间段内只允许一个进程访问该资源。<br>  举一个通俗的例子来解释，如果有一个妹纸问我有没有时间陪她出去玩，但是同时我的平时一个很讨厌的人也在问我能否陪他出去，这两个进程同时请求使用我嘴的资源，这时我不可能同时回答他们两个人的问题，是或者不是都会让其中一个人误会我的意思（当然是想和妹纸出去，拒绝另外一个人）。这就是互斥共享。<br>  我们把上述的资源共享方式称为互斥共享，把一段时间内只允许一个进程访问的资源称为<strong>临界资源</strong>或者<strong>独占资源</strong>，例如：打印机、磁带机等。</p><h4 id="同时访问方式"><a class="header-anchor" href="#同时访问方式">¶</a>同时访问方式</h4><p>  允许一个时间段内由多个进程“同时”对他们进行访问<br>  “同时”通常上是宏观的，而在微观上，这些进程可能是交替地对该资源进行访问即“分时共享”的。比如说：今天在图书馆的这一个下午，看妹纸和写博客这两件事情都可以向我的眼睛和大脑来发送请求，使用这两个资源，在这段时间内，我可以看一眼妹子，然后写几行博客，交替进行这两个进程。在计算机中可供多个进程“同时”访问的典型资源是磁盘设备。<br>  互斥共享要求一种资源在一段时间内（哪怕是一段很小的时间）只能，满足一个请求，否则就会出现严重的问题（例如打字机一行打印A文档内容，一行打印B文档内容）而同时访问共享通常要求一个请求分几个时间片段间隔地完成。<br>  并发和共享之间互为存在的条件：<strong>（1）资源共享是以程序的并发为条件的，若系统不允许程序并发执行则不存在资源共享的问题。（2）若系统不能对资源共享实施有效的管理，则影响到程序的并发执行，甚至根本无法存在并发执行</strong>。</p><h3 id="（3）虚拟（Virtual）"><a class="header-anchor" href="#（3）虚拟（Virtual）">¶</a>（3）虚拟（Virtual）</h3><p>  虚拟是指把一个物理上的实体转变为若干逻辑上的对应物。操作系统的虚拟技术可归纳为：<strong>（1）时分复用技术：处理器的分时共享</strong>。<strong>（2）空分复用技术：虚拟存储器</strong>。</p><h3 id="（4）异步（Asynchronism）"><a class="header-anchor" href="#（4）异步（Asynchronism）">¶</a>（4）异步（Asynchronism）</h3><p>  在多道程序环境中，允许多个程序并发执行，但由于资源优先，进程的执行不是一贯到底，而是走走停停，以不可预知的速度向前推进。</p><h2 id="操作系统的目标和功能"><a class="header-anchor" href="#操作系统的目标和功能">¶</a>操作系统的目标和功能</h2><p>  （1）为了给多道程序提供良好的运行环境，操作系统应具有以下几方面的功能：<strong>处理机管理、存储器管理、设备管理和文件管理</strong>。<br>  （2）为了方便用户使用操作系统，还必须向用户提供接口。<br>  （3）操作系统可用来扩充机器，以提供更方便的服务、更高的资源利用率。</p><h3 id="操作系统作为计算机系统资源的管理者"><a class="header-anchor" href="#操作系统作为计算机系统资源的管理者">¶</a>操作系统作为计算机系统资源的管理者</h3><h4 id="处理机管理"><a class="header-anchor" href="#处理机管理">¶</a>处理机管理</h4><p>  在多道程序环境下，<strong>处理机的分配和运行都以进程、线程为基本单位</strong>，因而对处理机的管理可归结为对进程的管理。因此进程何时创建、何时撒销、如何管理、如何避免冲突、合理共享就是进程管理的最主要的任务。进程管理的主要功能包括<strong>进程控制、进程同步、进程通信、死锁处理、处理机调度等。</strong></p><h4 id="存储器管理"><a class="header-anchor" href="#存储器管理">¶</a>存储器管理</h4><p>  存储器管理是为了给多道程序的运行提供良好的环境，方便用户用及提高内存的利用率，主要包括<strong>内存分配与回收、地址映射、内存保护与共享和内存扩充等功能</strong>。</p><h4 id="文件管理"><a class="header-anchor" href="#文件管理">¶</a>文件管理</h4><p>  计算机中的信息都是以文件的形式存在的，操作系统中负责文件管理的部分称为文件系统，文件管理包括<strong>文件存储空间的管理、目录管理及文件读写管理和保护等</strong>。</p><h4 id="设备管理"><a class="header-anchor" href="#设备管理">¶</a>设备管理</h4><p>  设备管理的主要任务是完成用户的I/O请求，方便用户使用各种设备，并提高设备的利用率，主要包括<strong>缓冲管理、设备分配、设备处理和虚拟设备等功能</strong>。</p><h3 id="操作系统作为用户与计算机硬件系统之间的接口"><a class="header-anchor" href="#操作系统作为用户与计算机硬件系统之间的接口">¶</a>操作系统作为用户与计算机硬件系统之间的接口</h3><p>  为了方便用户对于计算机硬件的操作以及运行自己计算机上的程序，操作系统为用户提供了接口，接口分为两类，<strong>（1）命令接口，（2）程序接口</strong>。</p><h4 id="命令接口"><a class="header-anchor" href="#命令接口">¶</a>命令接口</h4><p>  命令接口的目的是，用户利用这些命令来组织和控制作业的执行。其分为<strong>联机命令接口</strong>和<strong>脱机命令接口</strong>。<br>  <strong>联机命令接口</strong>又称交互式命令接口，适用于分时或实时系统的接口，通常是用户在键盘通过控制台或者终端输入操作命令，操作系统的命令解释程序解释执行输入的命令后，完成功能后，将指挥权返回终端。<br>  <strong>脱机命令接口</strong>又称批处理命令接口，适用于批处理系统。用户不能直接干预作业的运行，而是事先用相应的作业控制命令以作业操作说明书的形式提交给操作系统，等待系统中命令解释器对作业进行逐条处理。</p><h4 id="程序接口（系统调用）"><a class="header-anchor" href="#程序接口（系统调用）">¶</a>程序接口（系统调用）</h4><p>  程序接口由一组系统调用命令(也称广义指令)组成。用户通过在程序中使用这些系统调用来请求操作系统为其提供服务。如使用各种外部设备、申请分配和回收内内存及其他用程序接口实现的，当前最为流行的是图形用户界面(GUT),即图形接口。</p><h3 id="操作系统用作扩充机器"><a class="header-anchor" href="#操作系统用作扩充机器">¶</a>操作系统用作扩充机器</h3><p>  裸机没有任何软件支持，而我们实际中的计算机系统是若干层软件改造之后的，在裸机的外层，就是操作系统，这也不难理解为什么我们称其为硬件与用户之间的中介，因为其提供了大量的资源管理功能和方便用户的各种服务功能。</p>]]></content>
      
      
      <categories>
          
          <category> 课本学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 操作系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>xbwcj的失败史</title>
      <link href="/2021/03/19/xbwcj-de-shi-bai-shi/"/>
      <url>/2021/03/19/xbwcj-de-shi-bai-shi/</url>
      
        <content type="html"><![CDATA[<h2 id="分享一句话"><a class="header-anchor" href="#分享一句话">¶</a>分享一句话</h2><p><font face="微软雅黑" size="4">你我都是内卷背景下不起眼的尘埃，被时代的洪流裹挟向前。</font></p><h2 id="个人失败历史"><a class="header-anchor" href="#个人失败历史">¶</a>个人失败历史</h2><p>入学以来大一参加计算机设计大赛失败。😟<br>入学以后第一场考试以及后面无数考试失利。😩<br>大一参加校内数学建模新生杯惨败。😞<br>大一参加华中赛数学建模无功而返。😑<br>大一参加互联网+因特殊原因退出。😔<br>……<br>大二开始接触DataFountain竞赛，一直徘徊在复赛圈，与决赛无缘。<br>开始学习acm算法，在各种比赛中被吊打。<br>开始学习一些简单的开发，但是没有完整做出一款属于自己的开发的应用。<br>大二参加华为软件精英挑战赛，被数据漏洞坑害（参赛经验不足，获取比赛信息时效性低），赛区64强止步。<br>大二参加全国k-code程序设计大赛，止步21名，倒在决赛圈（前二十名）门口。<br>参加MathorCup成功参赛。<br>大二暑期建模培训最终选拔全校第七名，特殊原因被淘汰。<br>……<br>大三参加天池Redis数据库中间件挑战赛止步决赛。<br>……<br>还有很多自己以及以往的失败历史。</p><h2 id="未来准备参加的比赛"><a class="header-anchor" href="#未来准备参加的比赛">¶</a>未来准备参加的比赛</h2><p>美赛成绩未出<br>继续准备参加计算机设计大赛、华为软件精英挑战赛、等之类的其他比赛。</p><h2 id="xbwcj的数学建模比赛的准备"><a class="header-anchor" href="#xbwcj的数学建模比赛的准备">¶</a>xbwcj的数学建模比赛的准备</h2><p>1、提高自己的编程能力，编程能力的提升是在平时就要锻炼的，平时写代码的时候不要马虎应付，多看博客等其他网站上的一些常用算法与伪代码，最重要的是了解算法的思维，严谨的思维+超强的编程能力才能轻松应对数模中的编程。<br>2、强烈推荐去看司守奎的《数学建模算法与应用》这本书，学习上面的一些比较常见的算法，自己一定要手动实现一次，自己不手动实现，就很难理解里面的编程思维。<br>3、多去准备一些比较新的智能优化算法，推荐公众号：数学算法实验室、智能优化算法。尝试自己改进一些算法，将这些算法做成接口的形式，在使用时只需要传参就可以。准备一些可以做出精美图片的数据分析的软件，例如Oracle提供的Data Visualization Desktop的软件，也可以使用Office的PPT功能。熟练使用可以在比赛过程中省时省力。或者准备一些Matlab或者Python的作图代码，例如简单的条形图、折线图、雷达图等，或者高级点的词云之类的，也以接口的形式封装。<br>4、如何上手？一定一定要自己独自去完成一次数模的全部流程，了解每个步骤应该做什么如何去做。只有全部接触才能知道自己的优势以及劣势，了解自己应该找什么样的队友来取长补短。<br>5、暑期培训前的准备：2020年由于疫情的原因，选拔赛是以组队的形式直接做题来选拔。在暑期培训前无论是校赛还是校外的数模比赛中，都可以自己去找队友，因此最好在暑期选拔培训前就确定好自己的队友，尽早开始磨合，利用其他的数模比赛找到队伍的不足，这样可以在选拔赛中发挥的更好一些。校外的数模比赛建议参加：华中赛、泰迪杯、数维杯、深圳杯、亚太赛。（挑选其中几个即可）</p><h2 id="xbwcj的校外比赛经验"><a class="header-anchor" href="#xbwcj的校外比赛经验">¶</a>xbwcj的校外比赛经验</h2><p>推荐几个我经常浪荡的比赛网站：<br><a href="https://tianchi.aliyun.com/competition/gameList/activeList">天池</a>、<a href="https://competition.huaweicloud.com/competitions">华为云</a>、<br><a href="https://www.datafountain.cn/competitions">DataFountain</a>、<a href="https://www.kaggle.com/competitions">kaggle</a>、<br>这些比赛有奖金，并且你会学习到很多平时在课堂里面学不到的知识技能。刚开始得奖会比较难，因为这些比赛中参加的不只是本科生，一般是面向所有在校学生，而且硕士生所占比例不低，所以开始大家可以去涨经验，后面能到何种地步就看大家自己的发挥了。🐶🐶🐶<br>如果想要提高自己的编程能力：<br><a href="https://ac.nowcoder.com/acm/problem/list">牛客</a>、<a href="https://www.luogu.com.cn/problem/list">洛谷</a>、<a href="http://acm.hdu.edu.cn/">hduOJ</a>、<a href="https://codeforces.com/problemset">CodeForces</a>、<a href="https://nanti.jisuanke.com/acm">计蒜客</a>。<br>去刷里面的题目，如果不是专门去训练acm，不需要去做太难的，达到中等就可以应付绝大多数公司的绝大多数笔试题了。也可以帮助你了解比较重要的基础算法。</p><h2 id="xbwcj个人大学总结经验（其实是自己的不足与后悔之处）"><a class="header-anchor" href="#xbwcj个人大学总结经验（其实是自己的不足与后悔之处）">¶</a>xbwcj个人大学总结经验（其实是自己的不足与后悔之处）</h2><p>1、一定要尽早规划，自己以后是找工作还是要读研，读研的话，是准备考研，还是A、B保，如果保研自己还欠缺什么，尽早做打算。<br>2、精心，静心去做一件事，贪多嚼不烂。<br>3、无论做什么，基础一定要扎实。</p>]]></content>
      
      
      <categories>
          
          <category> 个人分享 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 个人分享 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>xbwcj的失败史</title>
      <link href="/2021/03/19/xbwcj-de-shi-bai-shi-he-ccr-de-guang-hui-sui-yue/"/>
      <url>/2021/03/19/xbwcj-de-shi-bai-shi-he-ccr-de-guang-hui-sui-yue/</url>
      
        <content type="html"><![CDATA[<h1>XBW</h1><h2 id="分享一句话"><a class="header-anchor" href="#分享一句话">¶</a>分享一句话</h2><p><font face="微软雅黑" size="4">你我都是内卷背景下不起眼的尘埃，被时代的洪流裹挟向前。</font></p><h2 id="个人失败历史"><a class="header-anchor" href="#个人失败历史">¶</a>个人失败历史</h2><p>入学以来大一参加计算机设计大赛失败。😟<br>入学以后第一场考试以及后面无数考试失利。😩<br>大一参加校内数学建模新生杯惨败。😞<br>大一参加华中赛数学建模无功而返。😑<br>大一参加互联网+因特殊原因退出。😔<br>……<br>大二开始接触DataFountain竞赛，一直徘徊在复赛圈，与决赛无缘。<br>开始学习acm算法，在各种比赛中被吊打。<br>开始学习一些简单的开发，但是没有完整做出一款属于自己的开发的应用。<br>大二参加华为软件精英挑战赛，被数据漏洞坑害（参赛经验不足，获取比赛信息时效性低），赛区64强止步。<br>大二参加全国k-code程序设计大赛，止步21名，倒在决赛圈（前二十名）门口。<br>参加MathorCup成功参赛。<br>大二暑期建模培训最终选拔全校第七名，特殊原因被淘汰。<br>……<br>大三参加天池Redis数据库中间件挑战赛止步决赛。<br>……<br>还有很多自己以及以往的失败历史。</p><h2 id="未来准备参加的比赛"><a class="header-anchor" href="#未来准备参加的比赛">¶</a>未来准备参加的比赛</h2><p>美赛成绩未出<br>继续准备参加计算机设计大赛、华为软件精英挑战赛、等之类的其他比赛。</p><h2 id="xbwcj的数学建模比赛的准备"><a class="header-anchor" href="#xbwcj的数学建模比赛的准备">¶</a>xbwcj的数学建模比赛的准备</h2><p>1、提高自己的编程能力，编程能力的提升是在平时就要锻炼的，平时写代码的时候不要马虎应付，多看博客等其他网站上的一些常用算法与伪代码，最重要的是了解算法的思维，严谨的思维+超强的编程能力才能轻松应对数模中的编程。<br>2、强烈推荐去看司守奎的《数学建模算法与应用》这本书，学习上面的一些比较常见的算法，自己一定要手动实现一次，自己不手动实现，就很难理解里面的编程思维。<br>3、多去准备一些比较新的智能优化算法，推荐公众号：数学算法实验室、智能优化算法。尝试自己改进一些算法，将这些算法做成接口的形式，在使用时只需要传参就可以。准备一些可以做出精美图片的数据分析的软件，例如Oracle提供的Data Visualization Desktop的软件，也可以使用Office的PPT功能。熟练使用可以在比赛过程中省时省力。或者准备一些Matlab或者Python的作图代码，例如简单的条形图、折线图、雷达图等，或者高级点的词云之类的，也以接口的形式封装。<br>4、如何上手？一定一定要自己独自去完成一次数模的全部流程，了解每个步骤应该做什么如何去做。只有全部接触才能知道自己的优势以及劣势，了解自己应该找什么样的队友来取长补短。<br>5、暑期培训前的准备：2020年由于疫情的原因，选拔赛是以组队的形式直接做题来选拔。在暑期培训前无论是校赛还是校外的数模比赛中，都可以自己去找队友，因此最好在暑期选拔培训前就确定好自己的队友，尽早开始磨合，利用其他的数模比赛找到队伍的不足，这样可以在选拔赛中发挥的更好一些。校外的数模比赛建议参加：华中赛、泰迪杯、数维杯、深圳杯、亚太赛。（挑选其中几个即可）</p><h2 id="xbwcj的校外比赛经验"><a class="header-anchor" href="#xbwcj的校外比赛经验">¶</a>xbwcj的校外比赛经验</h2><p>推荐几个我经常浪荡的比赛网站：<br><a href="https://tianchi.aliyun.com/competition/gameList/activeList">天池</a>、<a href="https://competition.huaweicloud.com/competitions">华为云</a>、<br><a href="https://www.datafountain.cn/competitions">DataFountain</a>、<a href="https://www.kaggle.com/competitions">kaggle</a>、<br>这些比赛有奖金，并且你会学习到很多平时在课堂里面学不到的知识技能。刚开始得奖会比较难，因为这些比赛中参加的不只是本科生，一般是面向所有在校学生，而且硕士生所占比例不低，所以开始大家可以去涨经验，后面能到何种地步就看大家自己的发挥了。🐶🐶🐶<br>如果想要提高自己的编程能力：<br><a href="https://ac.nowcoder.com/acm/problem/list">牛客</a>、<a href="https://www.luogu.com.cn/problem/list">洛谷</a>、<a href="http://acm.hdu.edu.cn/">hduOJ</a>、<a href="https://codeforces.com/problemset">CodeForces</a>、<a href="https://nanti.jisuanke.com/acm">计蒜客</a>。<br>去刷里面的题目，如果不是专门去训练acm，不需要去做太难的，达到中等就可以应付绝大多数公司的绝大多数笔试题了。也可以帮助你了解比较重要的基础算法。</p><h2 id="xbwcj个人大学总结经验（其实是自己的不足与后悔之处）"><a class="header-anchor" href="#xbwcj个人大学总结经验（其实是自己的不足与后悔之处）">¶</a>xbwcj个人大学总结经验（其实是自己的不足与后悔之处）</h2><p>1、一定要尽早规划，自己以后是找工作还是要读研，读研的话，是准备考研，还是A、B保，如果保研自己还欠缺什么，尽早做打算。<br>2、精心，静心去做一件事，贪多嚼不烂。<br>3、无论做什么，基础一定要扎实。</p><h1>Terence</h1><h2 id="最近做的事"><a class="header-anchor" href="#最近做的事">¶</a>最近做的事</h2><ul><li><p>和好朋友一起参加  <code>DataWhale</code> 三月份的组队学习（推荐系统和区块链方面）</p></li><li><p>学习英语和编程</p></li><li><p>准备了解一下多模态这个领域，也顺便考虑一下自己以后的研究方向，准备读研也不得不面对这个问题，以后要做什么？</p></li></ul><p>就以这个 <code>以后要做什么？</code> 题简单跟大家分享下</p><h2 id="以后要做什么？"><a class="header-anchor" href="#以后要做什么？">¶</a>以后要做什么？</h2><p>留给我们的选择其实不多，读研 or 就业</p><p>读研</p><ul><li>绩点要稳住（大数据专业绝大部分专业必修都在前两年）走 A 保</li><li>比赛拿奖项走 B 保</li></ul><p>科研</p><ul><li>理论研究</li><li>数据挖掘</li><li>机器学习</li><li>NLP（自然语言处理）</li><li>CV（计算机视觉）</li><li>多模态</li></ul><p>职业</p><ul><li><p>数据科学家</p></li><li><p>数据分析师</p></li><li><p>算法工程师</p></li></ul><h2 id="参加的比赛"><a class="header-anchor" href="#参加的比赛">¶</a>参加的比赛</h2><ul><li>华中地区大学生数学建模邀请赛省赛</li><li>华为大学生ICT大赛湖北区域省赛</li><li>全国大学生数学建模省赛</li><li>美国大学生数学建模大赛国赛</li><li>全国大学生节能减排国赛</li><li>中国大学生计算机设计大赛国赛</li><li>中国大学生服务外包创新创业大赛国赛</li><li>Kaggle、天池、腾讯广告…</li></ul><h2 id="数学建模"><a class="header-anchor" href="#数学建模">¶</a>数学建模</h2><p>讲下数学建模，其实刚才雯雯也说了很多，也非常详细，跟我观点也蛮吻合的。有一个观点，就是在咱们学校成功进入校队，参加国赛和美赛，不是一件容易的事情。确实它收益很大，每一年都有很多同学通过数学建模成功保研。并不是很推荐大家去很功利地做一件事情，数模带给我们的不仅仅是一个保研的资格或者说门票，更多的是带来一种能力。</p><ul><li>分析问题，将实际问题建立数学模型的能力</li><li>解决问题，运用自己所学去求解模型的能力</li><li>撰写科技论文的能力</li><li>团队配合</li></ul><p>2019年数学建模选拔形式（具体细节可以在教务处官网查询）</p><ul><li><p>编程：开卷、不限语言（主要是 Matlab ）对 8 个题目进行求解，求解问题大多是线性方程、0-1背包、最优化、智能算法以及开放题。最终按成绩排名。</p></li><li><p>建模：这个我就不太清楚了</p></li></ul><h2 id="其他比赛"><a class="header-anchor" href="#其他比赛">¶</a>其他比赛</h2><ul><li><p>ACM</p></li><li><p><a href="http://i.whut.edu.cn/xxtg/znbm/jwc/202103/t20210317_484335.shtml">【教务处】关于组织参加 “2021 年（第14届）中国大学生计算机设计大赛”的通知</a></p></li><li><p><a href="http://i.whut.edu.cn/xxtg/znbm/jwc/202103/t20210304_483136.shtml">【教务处】关于组织参加第十二届中国大学生服务外包创新创业大赛的通知</a></p></li><li><p><a href="http://i.whut.edu.cn/xxtg/znbm/jwc/202103/t20210304_483133.shtml">【教务处】关于举办“2021年中国高校计算机大赛-团体程序设计天梯赛”校内选拔赛的通知</a></p></li></ul><p>怎么说，不断去接触去尝试才会有更多可能。你说比赛它难不难，要想拿到好名次确实很难，没有一帆风顺的路，当你觉得自己真的真的真的快撑不下去的时候，那就别撑了，我们又不是把伞，老撑着干嘛:happy:</p><h2 id="小结"><a class="header-anchor" href="#小结">¶</a>小结</h2><p>找到自己喜欢的事情，然后坚持下去就好了。如果有一件事（限学业方面），能够让你忘记时间地投入进去，那就是足够热爱的事情啦！</p>]]></content>
      
      
      <categories>
          
          <category> 个人分享 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 个人分享 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据结构--线性表</title>
      <link href="/2021/03/08/shu-ju-jie-gou-xian-xing-biao/"/>
      <url>/2021/03/08/shu-ju-jie-gou-xian-xing-biao/</url>
      
        <content type="html"><![CDATA[<h2 id="什么是线性表？"><a class="header-anchor" href="#什么是线性表？">¶</a>什么是线性表？</h2><p>线性表（linear_list）是最常用且最简单的一种数据结构，一个线性表相当于是n个数据元素的有限序列，其中每个数据元素表示的内容在不同的情况下并不相同，有可能是一个数字、一个符号之类的。若将线性表用集合表示为:<br>$$<br>(a_{1}, …, a_{i-1}, a_{i}, a_{i+1}, …, a_{n})<br>$$</p><p>由集合中可以看出，除第一个外，集合中的每个数据元素均只有一个前驱，除最后一个外，集合中的每个数据元素均只有一个后继。</p><h2 id="线性表的两种表示形式"><a class="header-anchor" href="#线性表的两种表示形式">¶</a>线性表的两种表示形式</h2><p>（1）顺序表示：用一组地址连续的存储单元依次存储线性表的数据元素，称为线性表的顺序存储结构，可随机存取表中任一元素（其实就是数组）<br>（2）链式表示：用一组任意的存储单元存储线性表中的数据元素，称为线性表的链式存储结构。它的存储单元可以是连续的，也可以是不连续的。在表示数据元素之间的逻辑关系时，除了存储其本身的信息之外，还需存储一个指示其直接后继的信息（即直接后继的存储位置），这两部分信息组成数据元素的存储映像，称为结点（node）。它包括两个域；存储数据元素信息的域称为数据域；存储直接后继存储位置的域称为指针域。指针域中存储的信息称为指针或链。<br>可以用下图来更加直观的表示顺序结构和链式结构</p><h2 id="线性表的一般定义"><a class="header-anchor" href="#线性表的一般定义">¶</a>线性表的一般定义</h2><p>线性表的抽象数据类型定义如下：<br>数据对象：$$D , = , {a_{i} , | , a_{i} , \in , ElemSet, ,i = 1,2,\cdots,n, , n \geq 0}$$<br>数据关系：$$R1 , = , {&lt; a_{i-1},a_{i} &gt; |a_{i-1},a{i} \in D,,i=2,\cdots,n}$$</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">ADT List &#123;    &#x2F;&#x2F;基本操作    InitList(&amp;L) &#x2F;&#x2F;构造空线性表L    DestoryList(&amp;L) &#x2F;&#x2F;销毁线性表L    ClearList(&amp;L) &#x2F;&#x2F;将线性表L变为空    ListEmpty(L) &#x2F;&#x2F;若线性表L为空表，返回TRUE，否则返回FASLSE    ListLength(L) &#x2F;&#x2F;返回线性表中的数据元素个数    GetElem(L, i, &amp;e) &#x2F;&#x2F;用e返回L中第i个数据元素的值    PriorElem(L, cur_e, &amp;pre_e) &#x2F;&#x2F; 如果cur_e是线性表中的元素，而且不是第一个，那么我们就可以返回该元素前一个元素的值    NextElem(L, cur_e, &amp;next_e) &#x2F;&#x2F; &#x2F;&#x2F;如果cur_e是线性表中的元素，而且不是最后一个，就返回它下一个元素的值    Listinsert(&amp;L, i, e)&#x2F;&#x2F;如果线性表存在了，而且i符合条件，则在i位置插入一个元素    ListDelete(&amp;L, i)&#x2F;&#x2F;删除i位置上的元素    ListDelete_data(&amp;L, e, order)&#x2F;&#x2F;删除指定的元素e，order决定是删除一个，还是全部。    Connect_two_List(L_a,L_b,&amp; L_c)&#x2F;&#x2F;连接两个线性表，除去重复的内容    print(L)&#x2F;&#x2F;打印线性表    &#x2F;*        此处省略部分其他常见的操作    *&#x2F;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在上述的函数中需要注意，如果要改变原本线性表的内容，则需要传入线性表的地址，如果只是对线性表进行查询等不改变原本的线性表内容的操作，则不需要以地址的形式传入。（这部分其实就是C/C++的对传入函数参数值改变的原理，在此做一个小的提醒）。</p><h2 id="顺序存储结构常见的结构体实现"><a class="header-anchor" href="#顺序存储结构常见的结构体实现">¶</a>顺序存储结构常见的结构体实现</h2><p>我们通过线性表顺序结构来实现线性表的一些基础操作。</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">#include&lt;bits&#x2F;stdc++.h&gt;#define SIZE 100#define SIZE_T 150using namespace std;typedef int ElemType;struct List &#123;    ElemType *data; &#x2F;&#x2F;数据    int length; &#x2F;&#x2F;长度    int size; &#x2F;&#x2F;线性表初始容量&#125;;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="顺序存储结构InitList-函数的实现"><a class="header-anchor" href="#顺序存储结构InitList-函数的实现">¶</a>顺序存储结构InitList()函数的实现</h2><p>线性表的顺序表示可以看作对数组进行一些操作，初始化函数就是将表的长度变为0，对data进行堆内存的分配和初始容量的初始化。</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">&#x2F;&#x2F;创建一个空的线性表void InitList(List &amp;newList) &#123;    &#x2F;&#x2F;初始容量为startsize    newList.size &#x3D; SIZE_T;    &#x2F;&#x2F;首先开辟空间    newList.data &#x3D; (int *)malloc(SIZE * sizeof(ElemType));    if(!newList.data)    &#123;        exit(OVERFLOW); &#x2F;&#x2F; 存储分配失败    &#125;    &#x2F;&#x2F;空表，长度是0    newList.length &#x3D; 0;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="顺序存储结构DestoryList-函数的实现"><a class="header-anchor" href="#顺序存储结构DestoryList-函数的实现">¶</a>顺序存储结构DestoryList()函数的实现</h2><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">&#x2F;&#x2F;前提是线性表已经存在void Destory (List &amp;newList)&#123;if (newList &#x3D;&#x3D; NULL)    &#123;        exit(OVERFLOW);&#x2F;&#x2F; 线性表不存在    &#125;    &#x2F;&#x2F;首先释放堆内存free(newList.data);    &#x2F;&#x2F;每次释放堆内存后，应将对应的指针指向NULL，这是一个比较好的编程习惯    newList.data &#x3D; NULL;    newList.length &#x3D; 0;    newList.size &#x3D; 0;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="顺序存储结构ClearList-函数的实现"><a class="header-anchor" href="#顺序存储结构ClearList-函数的实现">¶</a>顺序存储结构ClearList()函数的实现</h2><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">&#x2F;&#x2F;前提是线性表已经存在void ClearList(List &amp;newList) &#123;    if (newList &#x3D;&#x3D; NULL)    &#123;        exit(OVERFLOW);&#x2F;&#x2F; 线性表不存在    &#125;    newList.length &#x3D; 0;free(newList.data);    newList.data &#x3D; NULL;    &#x2F;&#x2F;重新开辟空间    newList.data &#x3D; (int *)malloc(SIZE * sizeof(ElemType));&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="顺序存储结构ListEmpty-函数的实现"><a class="header-anchor" href="#顺序存储结构ListEmpty-函数的实现">¶</a>顺序存储结构ListEmpty()函数的实现</h2><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">&#x2F;&#x2F; 判断线性表是否为空bool ListEmpty(List newList) &#123;    if(newList.length &#x3D;&#x3D; 0)    &#123;        return 1;    &#125;    else    &#123;        return 0;    &#125;    return 0;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="顺序存储结构ListLength-函数的实现"><a class="header-anchor" href="#顺序存储结构ListLength-函数的实现">¶</a>顺序存储结构ListLength()函数的实现</h2><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">&#x2F;&#x2F; 返回线性表的长度int ListEmpty(List newList) &#123;       return newList.length;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 课本学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2021/02/13/hello-world/"/>
      <url>/2021/02/13/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a class="header-anchor" href="#Quick-Start">¶</a>Quick Start</h2><h3 id="Create-a-new-post"><a class="header-anchor" href="#Create-a-new-post">¶</a>Create a new post</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo new &quot;My New Post&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a class="header-anchor" href="#Run-server">¶</a>Run server</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo server<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a class="header-anchor" href="#Generate-static-files">¶</a>Generate static files</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo generate<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a class="header-anchor" href="#Deploy-to-remote-sites">¶</a>Deploy to remote sites</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo deploy<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      <categories>
          
          <category> hexo </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo blog </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BAS算法</title>
      <link href="/2021/01/29/bas-suan-fa/"/>
      <url>/2021/01/29/bas-suan-fa/</url>
      
        <content type="html"><![CDATA[<h2 id="天牛须搜索-Beetle-Antennae-Search-BAS"><a class="header-anchor" href="#天牛须搜索-Beetle-Antennae-Search-BAS">¶</a>天牛须搜索(Beetle Antennae Search-BAS)</h2><p>又称甲壳虫须搜索，类似于遗传算法、粒子群算法、模拟退火等智能优化算法，天牛须搜索不需要知道函数的具体形式，不需要梯度信息，就可以实现高效寻优。<br><strong>优点</strong>：相比于粒子群算法，天牛须搜索只需要一个个体，即一只天牛，运算量大大降低。</p><h2 id="仿生学原理"><a class="header-anchor" href="#仿生学原理">¶</a>仿生学原理</h2><p>天牛须搜索算法模仿自然界中天牛觅食行为。在天牛觅食过程中，其并不知道食物在哪里，但食物会产生特殊气味，吸引天牛向着食物前进。天牛通过其两只触角对空气中的食物气味进行感知，且根据食物距离两只触角的距离远近不同，两只触角所感知的气味浓度也有所差异。当食物处于天牛左侧时，左侧触角感知的气味浓度强于右侧触角感知的气味浓度，天牛根据两只触角所感知的浓度差，向着浓度强的一侧随机前进。通过一次次迭代，最终找到食物的位置。</p><h2 id="行为启发"><a class="header-anchor" href="#行为启发">¶</a>行为启发</h2><p>食物的气味就相当于一个函数,这个函数在三维空间每个点值都不同,天牛两个须可以采集自身附近两点的气味值,天牛的目的是找到仝局气味值最大的点仿照天牛的行为,我们就可以高效的进行函数寻优。</p><h2 id="算法模型"><a class="header-anchor" href="#算法模型">¶</a>算法模型</h2><p>BAS算法主要是通过在不停的左右触角气味浓度比对中前进，同其他算法相比，原理十分简单。<br>在进行两只触角气味浓度计算之前，需要对其进行一系列准备工作，在$D$维空间中天牛的位置为$X = (x_{1}, x_{2}, … , x_{n})$,天牛左右两只触角的位置被定义为如下公式所示模型：</p><p>$$<br>\left{ \begin{array}{l}<br>{X_r} = X + l * \mathop d\limits^ \to  \<br>{X_l} = X - l * \mathop d\limits^ \to<br>\end{array} \right.<br>$$</p>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 智能优化算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>前缀和、二维前缀和与差分个人理解</title>
      <link href="/2020/05/28/qian-zhui-he-er-wei-qian-zhui-he-yu-chai-fen-ge-ren-li-jie/"/>
      <url>/2020/05/28/qian-zhui-he-er-wei-qian-zhui-he-yu-chai-fen-ge-ren-li-jie/</url>
      
        <content type="html"><![CDATA[<h1>前缀和</h1><h2 id="什么是前缀和"><a class="header-anchor" href="#什么是前缀和">¶</a>什么是前缀和</h2><p>  前缀和顾名思义就是指一个数组的某一个下标的（包括该下标）之前的所有数组元素的和。现在我们假设有某一数组a = [1, 2, 3, 4, 5, 6, 7, 8, 9]。其前缀和数组为sum，那么sum数组与a数组对应的关系如下图所示。<br><img src="/2020/05/28/qian-zhui-he-er-wei-qian-zhui-he-yu-chai-fen-ge-ren-li-jie/1.png" alt="在这里插入图片描述"><br>  由上面的对应关系我们可以得到他们满足如下的公式。</p><p><img src="/2020/05/28/qian-zhui-he-er-wei-qian-zhui-he-yu-chai-fen-ge-ren-li-jie/2.png" alt="在这里插入图片描述"><br>  以上的公式即为<strong>一维前缀和</strong>一维前缀和的代码模板如下所示。</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">&#x2F;**     * 一维前缀和     *     * @a 表示原数组     * @sum 表示a数组的一维前缀和     *&#x2F;     const int maxn &#x3D; 1e5 + 10;     int a[9] &#x3D; &#123;1, 2, 3, 4, 5, 6, 7, 8, 9&#125;;      int sum[maxn];    void oneDimen(int num) &#123;&#x2F;&#x2F;num表示数组a的长度        sum[0] &#x3D; a[0];        for (int i &#x3D; 1; i &lt; num; i++) &#123;            sum[i] &#x3D; sum[i - 1] + a[i];        &#125;    &#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="前缀和使用情况"><a class="header-anchor" href="#前缀和使用情况">¶</a>前缀和使用情况</h2><p>  我们在做题的时候经常会遇到查询问题，例如给出一个数组a，再给出m次查询，每次查询都会给出两个数L，R，分表表示查询区间的左右范围。如果我们只是使用最简单的朴素查询的方法，每次遍历区间，进行m次的查询，这样在题目所给数据范围较小的情况下可以进行，但是当查询次数很大时，其时间复杂度为<strong>O（n*m）<strong>会使运行TLE，所以我们使用上述的前缀和可以使时间复杂度降低为</strong>O(m+n)</strong></p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">int query(int L, int R)&#123;retrun sum[R] - sum[L - 1];&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h1>差分</h1><h2 id="什么是差分"><a class="header-anchor" href="#什么是差分">¶</a>什么是差分</h2><p>  差分就是指相邻两个数的差，我们假设存在一个数组，如下图所示<br><img src="/2020/05/28/qian-zhui-he-er-wei-qian-zhui-he-yu-chai-fen-ge-ren-li-jie/3.png" alt="在这里插入图片描述"><br>  具体代码模板如下：</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">const int maxn &#x3D; 1e5 + 10;int a[9] &#x3D; &#123;1, 2, 3, 4, 5, 6, 7, 8, 9&#125;; int diff[maxn];&#x2F;&#x2F;求出差分数组void chafen(int num)&#123;&#x2F;&#x2F;num表示原数组的长度diff[0] &#x3D; a[0];for(int i &#x3D; 1; i &lt; num; i++)&#123;diff[i] &#x3D; a[i] - a[i - 1];&#125;&#125;&#x2F;&#x2F;对区间进行加操作void addarray(int L, int R, int k)&#123;&#x2F;&#x2F;L和R分别代表对加区间的左右范围，k表示在区间里每个元素加的数字diff[L] +&#x3D; k;diff[R + 1] -&#x3D; k;&#x2F;&#x2F;这里特别要注意，因为在前面进行区间加后，后面一个数与前面这个数的差变小了，所以要在后面这个数的差分数组减去前面区间所增加的数字。&#125;&#x2F;&#x2F;通过差分数组和原数组a推理得到进行区间加后数组中某一个元素的值void get_a()&#123;for(int i &#x3D; 1; i &lt;&#x3D; n; i++)&#123;a[i] &#x3D; doff[i] + a[i - 1];&#125; &#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="差分使用情况"><a class="header-anchor" href="#差分使用情况">¶</a>差分使用情况</h2><p>  区间加：把数组a[l]到a[r]都加上k，这种操作称为区间加。在进行区间加的操作后得到的数组b，我们对数组b进行查询，但可以发现如果是L——-R非常大的情况下，通过朴素的区间范围内主次累加求和这个操作执行的次数又很多，那时间复杂度会很高。所以可以使用差分的思想来降低复杂度。</p><h1>二维前缀和</h1><h2 id="什么是二维前缀和"><a class="header-anchor" href="#什么是二维前缀和">¶</a>什么是二维前缀和</h2><p><img src="/2020/05/28/qian-zhui-he-er-wei-qian-zhui-he-yu-chai-fen-ge-ren-li-jie/4.png" alt="在这里插入图片描述"><br>  在上图中深蓝色的部分代表的是二维数组的索引，浅蓝色的部分代表的是二维数组的每个元素的值。其二维前缀和如下图所示<br><img src="/2020/05/28/qian-zhui-he-er-wei-qian-zhui-he-yu-chai-fen-ge-ren-li-jie/5.png" alt="在这里插入图片描述"><br>  前缀和数组里每一个位置都表示原数组当前索引左上方的数字的和。<br>如上表中的而为前缀和数组：prefixSum[3, 3] = src[0~2, 0~2]的和;<br>二维前缀和数组的计算步骤如下所示。<br>可以分为四种情况</p><ol><li>i == 0 &amp;&amp; j ==0，只有一个直接赋值即可：prefixSum[0, 0] = a[0, 0]。</li><li>i == 0，最左边的一列，二维前缀和为元素上一行相同列的元素加该数字，公式为prefixSum[0, j] = prefixSum[0, j-1] + a[0, j]；</li><li>j == 0，最上面一排，与i == 0类似prefixSum[i, o] = prefixSum[i-1, 0] + a[i, 0];</li><li>i!=0 || j!=0，其公式为 prefixSum[i][j] = prefixSum[i - 1][j] + prefixSum[i][j - 1] + a[i][j] - prefixSum[i - 1][j - 1];<br>其代码模板如下所示</li></ol><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">&#x2F;** * 二维前缀和 * * @param src 原数组 * @return 二维前缀和 *&#x2F; const int maxn &#x3D; 100; int prefixSum[maxn][maxn];void twoDimen(int a[][], int n, int m) &#123;&#x2F;&#x2F;n和m分别代表二维原始数组的行列长度    for (int i &#x3D; 0; i &lt; n; i++) &#123;        for (int j &#x3D; 0; j &lt; m; j++) &#123;            if (i &#x3D;&#x3D; 0 &amp;&amp; j &#x3D;&#x3D; 0) &#123;&#x2F;&#x2F;第0个，最左上角                prefixSum[i][j] &#x3D; a[i][j];            &#125; else if (i &#x3D;&#x3D; 0) &#123;&#x2F;&#x2F;第一行，最顶部一行                prefixSum[i][j] &#x3D; prefixSum[i][j - 1] + a[i][j];            &#125; else if (j &#x3D;&#x3D; 0) &#123;&#x2F;&#x2F;第一列，最左边一列                prefixSum[i][j] &#x3D; prefixSum[i - 1][j] + a[i][j];            &#125; else &#123;&#x2F;&#x2F;其他                prefixSum[i][j] &#x3D; prefixSum[i - 1][j] + prefixSum[i][j - 1] + a[i][j] - prefixSum[i - 1][j - 1];            &#125;        &#125;    &#125;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="二维前缀和的使用情况"><a class="header-anchor" href="#二维前缀和的使用情况">¶</a>二维前缀和的使用情况</h2><p>  一般使用二维前缀和可以求子矩阵的最大值。通过求解出整个矩阵的二维前缀和数组，然后对二位前缀和数组中的元素进行查询，找到其和最大的子矩阵。</p><h2 id="二维前缀和的差分"><a class="header-anchor" href="#二维前缀和的差分">¶</a>二维前缀和的差分</h2><p>  二维前缀和也可以使用差分的形式。方法是和一维类似的，我们也是需要另开一个数组记录修改操作，最后求前缀和时统计修改操作，只是二维每一次操作需要记录4个位置，一维只需要记录2个位置。具体模板代码如下所示。</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">void chafen()&#123;for(int i&#x3D;0;i&lt;m;i++)&#123;&#x2F;&#x2F;m是修改操作次数 int x1,y1,x2,y2,p;cin&gt;&gt;x1&gt;&gt;y1&gt;&gt;x2&gt;&gt;y2&gt;&gt;p;b[x1][y1]+&#x3D;p;b[x2+1][y2+1]+&#x3D;p;b[x2+1][y1]-&#x3D;p;b[x1][y2+1]-&#x3D;p;&#125;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>  以上部分来自个人理解以及从其他大佬的博客中领悟到的，有些内容可能与其他大佬相似，如有侵权，请及时指出，立马进行修正。有写的不好地方也请及时指出，本人菜鸡，勿喷。</p><p><font face="微软雅黑" size="4">你我都是内卷背景下不起眼的尘埃，被时代的洪流裹挟向前。</font></p>]]></content>
      
      
      <categories>
          
          <category> ACM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ACM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>线段树个人理解</title>
      <link href="/2020/05/27/xian-duan-shu-ge-ren-li-jie/"/>
      <url>/2020/05/27/xian-duan-shu-ge-ren-li-jie/</url>
      
        <content type="html"><![CDATA[<h1>线段树</h1><p><img src="/2020/05/27/xian-duan-shu-ge-ren-li-jie/1.png" alt="在这里插入图片描述"></p><h2 id="定义："><a class="header-anchor" href="#定义：">¶</a>定义：</h2><p>  线段树是一种二叉搜索树，与区间树相似，它将一个区间划分成一些单元区间，每个单元区间对应线段树中的一个叶结点。使用线段树可以快速的查找某一个节点在若干条线段中出现的次数，时间复杂度为O(logN)。而未优化的空间复杂度为2N，实际应用时一般还要开4N的数组以免越界，因此有时需要离散化让空间压缩。对于线段树中的每一个非叶子节点[a,b]，它的左儿子表示的区间为[a,(a+b)/2]，右儿子表示的区间为[(a+b)/2+1,b]。因此线段树是平衡二叉树，最后的子节点数目为N，即整个线段区间的长度。</p><h2 id="作用范围："><a class="header-anchor" href="#作用范围：">¶</a>作用范围：</h2><p>  线段树的适用范围很广，可以在线维护修改以及查询区间上的最值，求和。更可以扩充到二维线段树（矩阵树）和三维线段树（空间树）。对于一维线段树来说，每次更新以及查询的时间复杂度为O(logN)。还支持区间修改，单点修改等操作。</p><h2 id="实现原理："><a class="header-anchor" href="#实现原理：">¶</a>实现原理：</h2><p>  线段树主要是把一段大区间平均地划分成两段小区间进行维护，再用小区间的值来更新大区间。这样既能保证正确性，又能使时间保持在log级别（因为这棵线段树是平衡的）。也就是说，一个[L…R]的区间会被划分成[L…(L+R)/2]和[(L+R)/2+1…R]这两个小区间进行维护，直到L=R。但是在上述的过程中我们会遇到以下几个问题，就是我们该如何建树，建树的过程中每一个下标我们该如何去分配，分派到的每一个空间我们应该用来存放哪些数据。</p><p><img src="/2020/05/27/xian-duan-shu-ge-ren-li-jie/2.png" alt="在这幅图片中"><br>  在这里我们仅对线段树中常见的区间最大值问题进行解释讨论。假设所给的区间为F[1:6] = {1, 9, 7, 8, 2, 3}。那么其对应的线段树的结构就如上图所示。其中红色的圆圈就代表线段树对应的每一个结点的下标。蓝色方框中的Max就是我们每一个结点所存放的内容，即每一个区间存放的最大值。Max下面的内容是对这个区间范围的一个说明，并不需要存放在数组中。<br>  仔细看这幅图我们会发现，其中结点的下标并不连续（在图中结点的标号并没有10，11）。这是因为我们在用数组对线段树进行模拟的时候，必须要提前对整个树的空间进行提前的开辟，所开辟的空间虽然并没有使用到，但是其仍然真是存在，这也是为什么我们在对数组进行开辟空间时一般会选择4<em>n的大小以避免出现RE。<br>  通过观察上面的线段树结点标号我们可以发现，对于一个区间[L,R]来说，最重要的数据当然就是区间的左右端点L和R，但是大部分的情况我们并不会去存储这两个数值，而是通过递归的传参方式进行传递。这种方式用指针好实现，定义两个左右子树递归即可，按时指针表示过于繁琐，而且不方便各种操作，大部分的线段树都是使用数组进行表示，那这里怎么快速使用下标找到左右子树呢。这就会涉及到每个结点下表数字的规律。我们发现在线段树中每个非叶子结点的度都为2，且父亲节点的左右两个孩子分别存储父亲一半的区间，而每个父亲结点存放的欧式孩子的最大值，而且左孩子的下标都为偶数，右孩子的下标都是奇数且左孩子下标数+1，即：<br><strong><em><em>L = Father</em>2 （左子树下标为父亲下标的两倍）<br>R = Father</em>2+1（右子树下标为父亲下标的两倍+1）</strong></em>*<br>或<br><strong>k&lt;&lt;1（结点k的左子树下标）<br>k&lt;&lt;1|1（结点k的右子树下标）</strong><br>所以建树的操作可用如下代码实现</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">const int maxn &#x3D; 1e5+5;const int INF &#x3D; 0x3f3f3f3f;int tree[maxn&lt;&lt;2],temp[maxn];&#x2F;&#x2F;tree[]数组表示线段树数组，temp[]表示存放原始数据的数组void Build(int l,int r,int rt)&#123; &#x2F;&#x2F;l,r表示当前节点区间，rt表示当前节点编号      if(l&#x3D;&#x3D;r) &#123;&#x2F;&#x2F;若到达叶节点，即区间的左右值相等           tree[rt]&#x3D;temp[l];&#x2F;&#x2F;储存数组值           return;      &#125;      int mid &#x3D; (l+r)&gt;&gt;1;  &#x2F;&#x2F;mid表示中间点    &#x2F;&#x2F;左右递归       Build(l,mid,rt&lt;&lt;1);      Build(mid+1,r,rt&lt;&lt;1|1);      tree[rt] &#x3D; max(tree[rt&lt;&lt;1],tree[rt&lt;&lt;1|1];&#x2F;&#x2F;更新信息&#125;  <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="线段树的基本操作："><a class="header-anchor" href="#线段树的基本操作：">¶</a>线段树的基本操作：</h2><h3 id="一、点更新"><a class="header-anchor" href="#一、点更新">¶</a>一、点更新</h3><p><img src="/2020/05/27/xian-duan-shu-ge-ren-li-jie/3.png" alt="在这里插入图片描述"><br>  假设我们将上述的区间F[1:6] = {1, 9, 7, 8, 2, 3}中的F[3] = 7通过对其+3更改为10。那么我们应当对线段树进行如下的几个操作。</p><ol><li>我们通过线段树的根结点向下遍历，通过叶子结点所在的区间进行查询，在每一处根结点与我们改变的值相比较，如果F[3] = 10大于当前根结点中存储的Max值，那么将Max = 10，否则不变且继续向下遍历。</li><li>直至到L=R时，即为我们改变的叶子结点，将其中存储的值变为我们上述的F[3] = 10，退出。<br>  具体代码实现如下：</li></ol><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">&#x2F;&#x2F;递归方式更新 updata(p,v,1,n,1);void updata(int p,int v,int l,int r,int rt)&#123;    &#x2F;&#x2F;p为下标，v为要加上的值，l，r为结点区间，rt为结点下标    if(l &#x3D;&#x3D; r)&#123;    &#x2F;&#x2F;左端点等于右端点，即为叶子结点，直接加上v即可        temp[rt] +&#x3D; v;        tree[rt] +&#x3D; v;    &#x2F;&#x2F;原数组和线段树数组都得到更新        return ;    &#125;    int m &#x3D; l + ((r-l)&gt;&gt;1);    &#x2F;&#x2F;m则为中间点，左儿子的结点区间为[l,m],右儿子的结点区间为[m+1,r]    if(p &lt;&#x3D; m)    &#x2F;&#x2F;如果需要更新的结点在左子树区间        updata(p,v,l,m,rt&lt;&lt;1);    else    &#x2F;&#x2F;如果需要更新的结点在右子树区间        updata(p,v,m+1,r,rt&lt;&lt;1|1);    tree[rt] &#x3D; max(tree[rt&lt;&lt;1],tree[rt&lt;&lt;1|1];    &#x2F;&#x2F;更新父节点的值&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="二、区间查询"><a class="header-anchor" href="#二、区间查询">¶</a>二、区间查询</h3><p>  线段树的每个结点存储的都是一段区间的信息 ，这就意味着如果我们刚好要查询这个区间，那么则直接返回这个结点的信息即可，比如对于上面线段树，如果我直接查询[1,6]这个区间的最值，那么直接返回根节点信息10即可，查询[1,2]直接返回9。但是有时题目中为了设置难度并不会轻易让我们查询每个结点所表示的区间。比如现在我要查询[2,5]区间的最值，这时候我们会发现并不存在某个节点的区间是[2,5]，那么这时我们应该采取一些什么方法来进行区间信息的查询呢？<br><img src="/2020/05/27/xian-duan-shu-ge-ren-li-jie/4.png" alt="在这里插入图片描述"></p><ol><li>首先我们发现区间[2,5]在线段树中包括的节点有[2,2]，[3,3]，[4,4]，[5,5]，[4,5]。但是[4,4]，[5,5]这两个信息的区间已经被[4,5]区间所包含，所以我们真正需要查询的结点为[2,2]，[3,3]，[4,5]这三个区间所在的结点。</li><li>其次从根节点开始往下递归，如果当前结点是要查询的区间的真子集，则返回这个结点的信息且不需要再往下递归。<br>  具体代码如下</li></ol><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">&#x2F;&#x2F;递归方式区间查询 query(Ld,Rd,1,n,1);int query(int Ld,int Rd,int l,int r,int rt)&#123;    &#x2F;&#x2F;[Ld,Rd]即为要查询的区间，l，r为结点区间，rt为结点下标    if(Ld &lt;&#x3D; l &amp;&amp; r &lt;&#x3D; Rd)    &#x2F;&#x2F;如果当前结点的区间真包含于要查询的区间内，则返回结点信息且不需要往下递归        return tree[rt];    int ans &#x3D; -INF;    &#x2F;&#x2F;返回值变量，根据具体线段树查询的什么而自定义    int mid &#x3D; (l+r)&gt;&gt;1;    &#x2F;&#x2F;m则为中间点，左儿子的结点区间为[l,m],右儿子的结点区间为[m+1,r]    if(Ld &lt;&#x3D; m)    &#x2F;&#x2F;如果左子树和需要查询的区间交集非空        ans &#x3D; max(ans, query(L,R,l,m,k&lt;&lt;1));    if(Rd &gt; m)    &#x2F;&#x2F;如果右子树和需要查询的区间交集非空，注意这里不是else if，因为查询区间可能同时和左右区间都有交集        ans &#x3D; max(ans, query(L,R,m+1,r,k&lt;&lt;1|1));    return ans;    &#x2F;&#x2F;返回当前结点得到的信息    &#125;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="三、区间更新"><a class="header-anchor" href="#三、区间更新">¶</a>三、区间更新</h3><p>  在线段树的区间更新中我们引进了一个新的思想，Lazy_tag，字面意思就是懒惰标记的意思，实际上它的功能也就是偷懒= =，因为对于一个区间[L,R]来说，我们每次都更新区间中的每一个值，那样的话更新的复杂度将会是O(NlogN)，这太高了，所以引进了Lazy_tag，这个标记一般用于处理线段树的区间更新。<br>　　线段树在进行区间更新的时候，为了提高更新的效率，所以每次更新只更新到更新区间完全覆盖线段树结点区间为止，这样就会导致被更新结点的子孙结点的区间得不到需要更新的信息，所以在被更新结点上打上一个标记，称为lazy-tag，等到下次访问这个结点的子结点时再将这个标记传递给子结点，所以也可以叫延迟标记。<br>　　也就是说递归更新的过程，更新到结点区间为需要更新的区间的真子集不再往下更新，下次若是遇到需要用这下面的结点的信息，再去更新这些结点，所以这样的话使得区间更新的操作和区间查询类似，复杂度为O(logN)。</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">void Pushdown(int rt)&#123;    &#x2F;&#x2F;更新子树的lazy值，这里是RMQ的函数，要实现区间和等则需要修改函数内容    if(lazy[rt])&#123;    &#x2F;&#x2F;如果有lazy标记        lazy[rt&lt;&lt;1] +&#x3D; lazy[rt];    &#x2F;&#x2F;更新左子树的lazy值        lazy[rt&lt;&lt;1|1] +&#x3D; lazy[rt];    &#x2F;&#x2F;更新右子树的lazy值        t[rt&lt;&lt;1] +&#x3D; lazy[rt];        &#x2F;&#x2F;左子树的最值加上lazy值        t[rt&lt;&lt;1|1] +&#x3D; lazy[rt];    &#x2F;&#x2F;右子树的最值加上lazy值        lazy[rt] &#x3D; 0;    &#x2F;&#x2F;lazy值归0    &#125;&#125;&#x2F;&#x2F;递归更新区间 updata(L,R,v,1,n,1);void updata(int Ld,int Rd,int v,int l,int r,int rt)&#123;    &#x2F;&#x2F;[Ld,Rd]即为要更新的区间，l，r为结点区间，k为结点下标    if(Ld &lt;&#x3D; l &amp;&amp; r &lt;&#x3D; Rd)&#123;    &#x2F;&#x2F;如果当前结点的区间真包含于要更新的区间内        lazy[rt] +&#x3D; v;    &#x2F;&#x2F;懒惰标记        t[rt] +&#x3D; v;    &#x2F;&#x2F;最大值加上v之后，此区间的最大值也肯定是加v    &#125;    else&#123;        Pushdown(k);    &#x2F;&#x2F;重难点，查询lazy标记，更新子树        int m &#x3D; l + ((r-l)&gt;&gt;1);        if(Ld &lt;&#x3D; m)    &#x2F;&#x2F;如果左子树和需要更新的区间交集非空            update(Ld,Rd,v,l,m,rt&lt;&lt;1);        if(m &lt; Rd)    &#x2F;&#x2F;如果右子树和需要更新的区间交集非空            update(Ld,Rd,v,m+1,r,rt&lt;&lt;1|1);        Pushup(rt);    &#x2F;&#x2F;更新父节点    &#125;&#125;&#x2F;&#x2F;递归方式区间查询 query(Ld,Rd,1,n,1);int query(int Ld,int Rd,int l,int r,int rt)&#123;    &#x2F;&#x2F;[L,R]即为要查询的区间，l，r为结点区间，k为结点下标    if(Ld &lt;&#x3D; l &amp;&amp; r &lt;&#x3D; Rd)    &#x2F;&#x2F;如果当前结点的区间真包含于要查询的区间内，则返回结点信息且不需要往下递归        return t[rt];    else&#123;        Pushdown(rt);    &#x2F;**每次都需要更新子树的Lazy标记*&#x2F;        int res &#x3D; -INF;    &#x2F;&#x2F;返回值变量，根据具体线段树查询的什么而自定义        int mid &#x3D; l + ((r-l)&gt;&gt;1);    &#x2F;&#x2F;m则为中间点，左儿子的结点区间为[l,m],右儿子的结点区间为[m+1,r]        if(Ld &lt;&#x3D; m)    &#x2F;&#x2F;如果左子树和需要查询的区间交集非空            res &#x3D; max(res, query(Ld,Rd,l,m,rt&lt;&lt;1));        if(Rd &gt; m)    &#x2F;&#x2F;如果右子树和需要查询的区间交集非空，注意这里不是else if，因为查询区间可能同时和左右区间都有交集            res &#x3D; max(res, query(Ld,Rd,m+1,r,rt&lt;&lt;1|1));        return res;    &#x2F;&#x2F;返回当前结点得到的信息    &#125;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><font face="微软雅黑" size="4">你我都是内卷背景下不起眼的尘埃，被时代的洪流裹挟向前。</font></p>]]></content>
      
      
      <categories>
          
          <category> ACM </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ACM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>武汉理工大学《软件工程》复习总括三</title>
      <link href="/2019/11/05/wu-han-li-gong-da-xue-ruan-jian-gong-cheng-fu-xi-zong-gua-san/"/>
      <url>/2019/11/05/wu-han-li-gong-da-xue-ruan-jian-gong-cheng-fu-xi-zong-gua-san/</url>
      
        <content type="html"><![CDATA[<h1>第六章软件结构体系</h1><h2 id="软件结构体系的内容："><a class="header-anchor" href="#软件结构体系的内容：">¶</a><strong>软件结构体系的内容：</strong></h2><p><strong>1、构件</strong>：代表着一组基本的构成要素<br><strong>2、连接件</strong>：也就是构件之间的连接关系<br><strong>3、约束</strong>：是作用于构件或者连接关系上的一些限制条件<br><strong>4、质量</strong>：是系统的质量属性，如性能、可扩展性、可修改性、可重用性、安全性等。<br><strong>5、物理分布</strong>：代表着构件连接之后形成的拓扑结构，描述了软件到硬件之间的影射。</p><h2 id="软件结构体系发展的阶段："><a class="header-anchor" href="#软件结构体系发展的阶段：">¶</a>软件结构体系发展的阶段：</h2><p><img src="/2019/11/05/wu-han-li-gong-da-xue-ruan-jian-gong-cheng-fu-xi-zong-gua-san/1.png" alt="在这里插入图片描述"></p><h2 id="体系结构、软件框架、设计模式三者的联系和区别："><a class="header-anchor" href="#体系结构、软件框架、设计模式三者的联系和区别：">¶</a>体系结构、软件框架、设计模式三者的联系和区别：</h2><p><strong>体系结构</strong>：描述某一特定应用领域中系统组织的惯用模式，反映领域中众多系统所共有的结构和语义特性，例如：MVC<br><strong>软件框架</strong>：由开发人员定制的应用系统骨架，整个或部分系统的可重用设计，由一组抽象构件和构件实例之间的交互方式组成。例如Django就是一个开放源代码的应运框架，由Python写成。<br><strong>设计模式</strong>：描述软件系统设计过程中常见问题的一些解决方案，从大量的成功实践中总结出来的，且被广泛公认的实践和知识。<br><strong>软件框架和体系结构的区别及关系：</strong><br><img src="/2019/11/05/wu-han-li-gong-da-xue-ruan-jian-gong-cheng-fu-xi-zong-gua-san/2.png" alt="在这里插入图片描述"><br><strong>软件框架和实际模式的区别及关系：</strong><br><img src="/2019/11/05/wu-han-li-gong-da-xue-ruan-jian-gong-cheng-fu-xi-zong-gua-san/3.png" alt="在这里插入图片描述"></p><h2 id="软件工程问题中的关键的角色："><a class="header-anchor" href="#软件工程问题中的关键的角色：">¶</a>软件工程问题中的关键的角色：</h2><p><strong>用户</strong>：使用系统实现某种目标<br><strong>软件系统</strong>：待开发的系统<br><strong>环境</strong>：软件系统以外的任何事物</p><h2 id="软件设计的原则（高内聚低耦合）："><a class="header-anchor" href="#软件设计的原则（高内聚低耦合）：">¶</a>软件设计的原则（高内聚低耦合）：</h2><p><strong>内聚性</strong>：是一个模块或子系统内部的依赖程度。分为七种：功能内聚、信息内聚、通信内聚、过程内聚、时间内聚、逻辑内聚、巧合内聚。<br><img src="/2019/11/05/wu-han-li-gong-da-xue-ruan-jian-gong-cheng-fu-xi-zong-gua-san/4.png" alt="在这里插入图片描述"><br><strong>耦合性</strong>：是两个模块或者子系统之间依赖关系的强度，程序结构各个模块之间相互关联的度量。模块之间的联系方式一般有7中：非直接耦合、数据耦合、标记耦合、控制耦合、外部耦合、公共耦合、内容耦合。<br><img src="/2019/11/05/wu-han-li-gong-da-xue-ruan-jian-gong-cheng-fu-xi-zong-gua-san/5.png" alt="在这里插入图片描述"></p><h2 id="软件体系结构常见的风格："><a class="header-anchor" href="#软件体系结构常见的风格：">¶</a>软件体系结构常见的风格：</h2><p>可以根据文字描述判断出风格的种类即可。<br>**<img src="/2019/11/05/wu-han-li-gong-da-xue-ruan-jian-gong-cheng-fu-xi-zong-gua-san/6.png" alt="在这里插入图片描述"><br><strong>管道/过滤器风格</strong>：把系统任务分成若干连续的处理步骤，这些步骤由通过系统的数据流连接，一个步骤的输出是下一个步骤的输入。<br><strong><img src="/2019/11/05/wu-han-li-gong-da-xue-ruan-jian-gong-cheng-fu-xi-zong-gua-san/7.png" alt="在这里插入图片描述"><br>主程序—子程序风格</strong>：结构化程序设计的一种典型风格，从功能的观点设计系统，逐步分解和细化，形成整个系统的体系结构。<br><strong><img src="/2019/11/05/wu-han-li-gong-da-xue-ruan-jian-gong-cheng-fu-xi-zong-gua-san/8.png" alt="在这里插入图片描述"><br>面向对象风格</strong>：系统被看作是对象的集合，每个对象都有一个它自己的功能集合，数据及作用在数据上的操作被封装成抽象数据类型，只通过接口与外界交互，内部的设计决策则被封装起来。<br>**<img src="/2019/11/05/wu-han-li-gong-da-xue-ruan-jian-gong-cheng-fu-xi-zong-gua-san/9.png" alt="在这里插入图片描述"><br><strong>层次结构风格----客户机／服务器体系结构</strong>：一种分布式系统模型<br><strong>服务器</strong>：为客户机提供服务<br><strong>客户机</strong>：负责与用户的交互       类似于网络编程交互的情景。<br><strong><img src="/2019/11/05/wu-han-li-gong-da-xue-ruan-jian-gong-cheng-fu-xi-zong-gua-san/10.png" alt="在这里插入图片描述"><br>层次结构----浏览器/服务器结构</strong>：<br><img src="/2019/11/05/wu-han-li-gong-da-xue-ruan-jian-gong-cheng-fu-xi-zong-gua-san/11.png" alt="在这里插入图片描述"><br><strong>层次结构----模型/视图/控制器：（MVC）</strong><br>**<img src="/2019/11/05/wu-han-li-gong-da-xue-ruan-jian-gong-cheng-fu-xi-zong-gua-san/12.png" alt="在这里插入图片描述"><br><strong>基于事件的隐式调用风格</strong>：将应用看成是一个构件集合，每个构件直至发生对它有影响的事件时才有所动作<br>**<img src="/2019/11/05/wu-han-li-gong-da-xue-ruan-jian-gong-cheng-fu-xi-zong-gua-san/13.png" alt="在这里插入图片描述"><br><strong>仓库风格</strong>：以数据为中心，适合于数据由一个模块产生而由其他模块使用的情形<br><img src="/2019/11/05/wu-han-li-gong-da-xue-ruan-jian-gong-cheng-fu-xi-zong-gua-san/14.png" alt="在这里插入图片描述"></p><h1>第七章面向对象设计</h1><h2 id="面向对象的设计和分析中的三种类："><a class="header-anchor" href="#面向对象的设计和分析中的三种类：">¶</a>面向对象的设计和分析中的三种类：</h2><p><strong>1、实体类</strong>：对应系统需求中的每个实体，它们通常需要保存在永久的存储体中，一般使用数据库表和文件来记录，实体类包括存储和传递数据的类，也包括操作数据的类<br><strong>2、控制类</strong>：用于体现应用程序的执行逻辑，提供相应的业务操作，将控制类抽象出来可以降低界面和数据库之间的耦合度；<br><strong>3、边界类</strong>：用于对外部用户与系统之间的交互对象进行抽象。主要包括界面类。</p><h2 id="什么是领域模型："><a class="header-anchor" href="#什么是领域模型：">¶</a>什么是领域模型：</h2><p>在面向对象分析和设计的初级阶段，通常先识别出实体类，绘制初始类图，此时的类图称为领域模型，包括实体类和它们之间的相互关系。</p><h1>第八章编写高质量代码</h1><h2 id="程序复杂度怎么计算（重点是第二种，第二种有三种小方法）："><a class="header-anchor" href="#程序复杂度怎么计算（重点是第二种，第二种有三种小方法）：">¶</a>程序复杂度怎么计算（重点是第二种，第二种有三种小方法）：</h2><p><strong>基本思想</strong>：程序复杂性主要取决于程序控制流的复杂性，单一的顺序结构最简单，选择和循环结构构成的环路越多，程序越复杂。<br><strong>实质</strong>：度量程序拓扑结构的复杂性程序图：把程序看成是有一个入口、一个出口的有向图程序图的<br><strong>节点</strong>：每个语句、一个顺序流程的程序代码段、程序流程图中的每个处理符号程序图的<br><strong>有向弧</strong>：程序中的流程控制、程序流程图中连接不同处理符号的、带箭头的线段<br><strong>强连通图(Strongly Connected Graph)</strong>：是指一个有向图（Directed Graph）中任意两点v1、v2间存在v1到v2的路径（path）及v2到v1的路径的图。<br><strong>三种方法</strong>：如果程序图中每个节点都可以由入口节点到达，则<strong>图中环的个数 = 环路复杂度</strong><br>如果程序图是强连通图，则计算环路数V(G)的方法 <strong>方法一：V(G) = e–n + p（e: 弧数，n: 节点数，p: 分离部分的数目,V(G)有向图G中的环数）</strong> <strong>方法二：包括强连通域在内的环路数</strong> <strong>方法三：判定节点数 +  1</strong><br>V(G)与程序复杂性呈正比关系 一般一个模块V(G) ≤ 10</p><h1>第九章测试驱动的实现</h1><h2 id="软件测试的类型："><a class="header-anchor" href="#软件测试的类型：">¶</a><strong>软件测试的类型</strong>：</h2><p>1）从测试对象角度①单元测试 ②集成测试③功能测试 ④性能测试 ⑤安装测试2）测试技术角度①黑盒测试（功能测试）②白盒测试（结构测试）<br>3）是否运行程序角度①静态测试 ②动态测试<br>4）执行测试的方式①手工测试 ②自动化测试</p><h2 id="白盒测试："><a class="header-anchor" href="#白盒测试：">¶</a>白盒测试：</h2><p>在下一次更新中详写。</p><h2 id="自己会设计测试用例：路径覆盖："><a class="header-anchor" href="#自己会设计测试用例：路径覆盖：">¶</a>自己会设计测试用例：路径覆盖：</h2><p>在下一次更新中详写</p><h2 id="软件测试的几个阶段：-每个阶段的名称作用测试的对象"><a class="header-anchor" href="#软件测试的几个阶段：-每个阶段的名称作用测试的对象">¶</a>软件测试的几个阶段：(每个阶段的名称作用测试的对象)</h2><p><strong>1、单元测试</strong>：对软件中的最小可测试单元进行检查和验证 对象是单元。<br><strong>2、集成测试</strong>：在单元测试的基础上，将所有模块按照总体设计的要求组装成为子系统或系统进行的测试 对象是系统或者子系统<br><strong>3、确认测试</strong>：在开发过程中或结束时评估系统或组成部分的过程，目的是判断系统是否满足规定的要求。对象是系统<br><strong>4、系统测试</strong>：检测软件系统运行时与其他相关要素的协调工作情况是否满足要求。对象是系统。</p>]]></content>
      
      
      <categories>
          
          <category> 课本学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件工程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>武汉理工大学《软件工程》复习总括二</title>
      <link href="/2019/11/03/wu-han-li-gong-da-xue-ruan-jian-gong-cheng-fu-xi-zong-gua-er/"/>
      <url>/2019/11/03/wu-han-li-gong-da-xue-ruan-jian-gong-cheng-fu-xi-zong-gua-er/</url>
      
        <content type="html"><![CDATA[<h1>第四章需求获取</h1><p><strong>需求分析的实质</strong>：是对系统的理解与表达的过程，是一种软件工程的活动。</p><p><strong>需求分析之后建立模型的名称</strong>：分析模型或需求模型需求分析的过程：<br><strong>需求分析的过程</strong>：<img src="/2019/11/03/wu-han-li-gong-da-xue-ruan-jian-gong-cheng-fu-xi-zong-gua-er/1.png" alt="在这里插入图片描述"><br><strong>常用的需求分析的方法</strong>：<br>1：面向数据流的结构化分析方法（简称SA）<br>2：面向数据结构的Jackson方法（简称JSD）<br>3：面向对象的分析方法<br>4：建立动态模型的迁移图或Petri网等。<br><strong>软件需求的分类，根据分类的标准不同，结果也不同</strong>：<br><strong>1：按修饰对象的不同</strong>：<br><strong>Ø 产品需求</strong>：<br><strong>l 功能性需求</strong>：软件产品的功能特性<br><strong>l 非功能性需求</strong>：软件产品的质量属性，是在功能性需求满足情况下的进一步要求<br><strong>“FURPS“模型</strong>：<br><strong>功能性</strong>：需要考虑的额外的功能需求，如安全性；<br><strong>可用性</strong>：易用性、美观性、一致性和文档化；<br><strong>可靠性</strong>：指的是在特定操作环境下预期的系统故障频率、可恢复性、可预测性准确性以及平均故障时间；<br><strong>性能</strong>：响应时间、效率、资源利用率和吞吐量（在一个指定时间内系统可完成的工作量）<br><strong>可支持性</strong>：可测试性、适应性、可维护性、兼容性、可配置性、可扩展性和本地化<br><strong>Ø 过程需求</strong>——修饰或限制软件开发过程的要求<br><strong>2：按抽象层次详细程度</strong>：<br><strong>Ø 业务需求</strong><br><strong>Ø 用户需求</strong><br><strong>Ø 系统需求</strong><br><strong>Ø 软件设计规约</strong></p><p><strong>需求优先级的等级：</strong><br><strong>1、基本的</strong>：使得客户能够黑手系统并且必须实现的要求<br><strong>2：可取的</strong>：非常可取但却不是必须的那些需求<br><strong>3：可选的</strong>：在时间和资源允许的情况下，可能会实现的需求<br><strong>4：未来的</strong>：不会在系统当前版本中实现，但考虑到系统后续的版本应该记录下来的需求</p><p><strong>需求获取的技术有哪些</strong>：<br>1：面谈<br>2：问卷调查<br>3：群体诱导技术<br>4：头脑风暴<br>5：参与观察法<br>6：亲身实践<br>7：原型<br>8：情景分析<br>9：概念建模<br>10：A/B测试</p><p><strong>结构化分析的主要工具</strong>：<br>1：数据流图(DFD)<br>2:数据字典(DD)<br>3：结构化语言<br>4：判定树<br>5：判定表</p><p><strong>传统的软件建模中分析模型的核心及围绕核心的三个子模型</strong>：<br>分析模型的核心是数据字典，围绕数据字典3个层次的子模型有数据模型、功能模型和行为模型。<br><strong>数据字典</strong>：用于描述系统软件中使用或者产生的每一个数据元素，是系统数据信息定义的集合。<br><strong>数据模型</strong>：用于描述数据对象之间的关系。其应包含3种相关的信息，即数据对象、属性和关系<br><strong>功能模型</strong>：可以用数据流图描述（数据流图是一种图形化技术，可以表达软件系统必须完成的功能），所以又称数据流模型。<br><strong>行为模型</strong>：常用状态转化图（即状态图）来描述，又称状态机模型，可以理解为，在任一个时刻，系统处于有限可能的状态中的一个状态，当某一个激励条件到达时，它激发系统从一个状态转换到另一新状态。</p><h1>第五章</h1><p><strong>用例建模UML的九种图的画法，以及每种图的作用，在分析和设计的过程中怎么使用：</strong><br><img src="/2019/11/03/wu-han-li-gong-da-xue-ruan-jian-gong-cheng-fu-xi-zong-gua-er/2.png" alt="在这里插入图片描述"><br><strong>1、用例图：</strong><br><strong>作用</strong>：表示角色和用例之间的关系，其中用例代表的是一个系统或分类器的功能，外部交互者与这一分类器来进行交互呈现。<br><strong>组成/使用</strong>：由一些角色、一组用例，还可能有一些接口以及这些组成元素之间的关系构成的图，其中关系是指角色和用例之间的联系。用例通常用矩形框起来以表示系统或分类器的边界。<br><img src="/2019/11/03/wu-han-li-gong-da-xue-ruan-jian-gong-cheng-fu-xi-zong-gua-er/3.png" alt="在这里插入图片描述"><br><strong>2、类图：</strong><br><strong>作用</strong>：静态描述性模型元素相互连接的集合图，可以表示不同实体（人，事务和数据）的内部构成<br><strong>组成/使用</strong>：名称，属性和方法，他们之间的关系。#表示受保护成员，+表示公有成员，“-”表示私有成员。<br><strong><img src="/2019/11/03/wu-han-li-gong-da-xue-ruan-jian-gong-cheng-fu-xi-zong-gua-er/4.png" alt="在这里插入图片描述"><br>3、交互图</strong> ：包括顺序图和协作图，两种图在内容上是等效的，可以相互转换。<br><strong>顺序图</strong>：强调消息的时间排序<br><strong>作用</strong>：表示交互，指为得到一个期望的结果而在多个分类器角色之间进行的交互序列。<br><strong>组成/使用</strong>：顺序图有两维，垂直维代表时间，水平维代表对象。通常，垂直维自上至下代表时间向前推进。<br><strong>协作图</strong>：强调发送消息和接收消息的对象的结构组织<br><strong>作用</strong>：描述相互联系的对象之间的关系，或者分类器角色和关联角色之间的关系以下是同一个例子分别用两种图的表示<br><img src="/2019/11/03/wu-han-li-gong-da-xue-ruan-jian-gong-cheng-fu-xi-zong-gua-er/5.png" alt="在这里插入图片描述"> 顺序图<br><img src="/2019/11/03/wu-han-li-gong-da-xue-ruan-jian-gong-cheng-fu-xi-zong-gua-er/6.png" alt="在这里插入图片描述"><br>协作图<br><strong>4、状态图</strong>：描述模型元素在接收到事件后的动态行为。<br><strong>作用</strong>：描述一个类的对象在生命周期里如何从一个状态转移到另外一个状态，类的迁移由事件触发。<br><strong>组成/使用</strong>：图形中的状态和各种其他类型的顶点（伪状态）用适当的状态或者伪状态符号表示，状态之间的转换则用有向弧连接表示。<img src="/2019/11/03/wu-han-li-gong-da-xue-ruan-jian-gong-cheng-fu-xi-zong-gua-er/7.png" alt="在这里插入图片描述"></p><p><strong>5、活动图</strong>：是状态图的一种特殊的情况，其中绝大部分状态是动作或子活动状态，并且绝大部分甚至所有的转换是通过动作或者子活动的完成所触发的。<br><strong>作用</strong>：描述绝大多数甚至是所有的事件是由内部动作的完成所引起的情况。<br><strong>组成</strong>：由一条路径组成。包含并发和分叉，并发：两个活动同时发生。  分叉：选择性活动的发生<br><img src="/2019/11/03/wu-han-li-gong-da-xue-ruan-jian-gong-cheng-fu-xi-zong-gua-er/8.png" alt="在这里插入图片描述"><br><strong>6、构件图：</strong><br><strong>作用</strong>：表示构建之间的依赖关系组成：软件构建包括源代码构建、二进制代码构建和可执行构建，一些构建存在于编译时刻，一些存在于链接时刻，一些存在于运行时刻，还有一些可能存在于不止一个时刻。<br><strong>组成/使用</strong>：使用箭头表示依赖关系<br><img src="/2019/11/03/wu-han-li-gong-da-xue-ruan-jian-gong-cheng-fu-xi-zong-gua-er/9.png" alt="在这里插入图片描述"><br><strong>7、配置图：</strong><br><strong>作用</strong>：表示系统运行时的处理元素、软件构件以及基于它们的进程和对象的配置情况<br><strong>组成/使用</strong>：不处于运行状态的实体的软件构件不出现（在构件图中表示），结点可能包含构件实例，构件可能包含对象，构件与构件之间的依赖关系用箭线表示<br><strong><img src="/2019/11/03/wu-han-li-gong-da-xue-ruan-jian-gong-cheng-fu-xi-zong-gua-er/10.png" alt="在这里插入图片描述"><br>用例之间的关系</strong>：泛化、包含、扩展</p><p><strong>用例的场景：</strong><br>1：某个用例的一个实例，只描述完成给定的用例行为的若干可能途径中的一种  2：一个用例可能存在多个场景<br>3：系统会根据参与者提供的不同信息进入不同的场景<br>4：场景可以表达：正面行为需求，反面行为需求，不希望发生的交互，并行机制</p><p><strong>类与类之间的关系</strong>：<br>1：关联关系：包含自返关联、二元关联、N元关联<br>2：泛化关系<br>3：依赖关系<br>4：实现关系</p>]]></content>
      
      
      <categories>
          
          <category> 课本学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件工程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>武汉理工大学《软件工程》复习总括一</title>
      <link href="/2019/11/02/wu-han-li-gong-da-xue-ruan-jian-gong-cheng-fu-xi-zong-gua-yi/"/>
      <url>/2019/11/02/wu-han-li-gong-da-xue-ruan-jian-gong-cheng-fu-xi-zong-gua-yi/</url>
      
        <content type="html"><![CDATA[<h1>第一章软件工程概述</h1><p><strong>软件的本质特征：</strong><br>复杂性+一致性+可变性+不可见性<br><strong>软件危机的概念：</strong><br>软件危机是指在计算机软件的开发和维护过程中所遇到的一系列问题。<br><strong>软件工程的概念：</strong><br>1：将系统化的、规范的、可度量的方法应运与软件的开发、运行和维护的过程，即将工程化应运与软件中<br>2：对1中所述的方法的研究<br><strong>软件工程的关键元素</strong>：方法+工具+过程<br><strong>软件工程的开发策略</strong>：软件复用+分而治之+逐步演进+折中优化<br><strong>软件工程的基本原理：</strong><br>1：用分阶段的生命周期计划严格管理<br>2：坚持进行评审阶段<br>3：实行严格的产品控制<br>4：采用现代化程序设计技术<br>5：结果应能清楚的审查<br>6：开发小组人员应少而精<br>7：承认不断改进软件工程的必要性</p><h1>第二章软件过程</h1><p><strong>软件过程的定义及包含的活动：</strong><br>软件过程是指软件生成周期中的一系列相关过程，是为了获得高质量软件而实施的一系列活动。它包括问题定义、需求开发、软件设计、软件构造、软件测试等一系列软件开发的实现活动，而每一项都会产生相应的中间制品。<br><strong>软件过程常见的模型及其关系</strong>：<br>Ø <strong>瀑布模型</strong>——无法适应需求变化，计划驱动<br>特点：①. 阶段间具有顺序性和依赖性，便于分工合作；<br>②. 强调软件文档的重要性，要求每个阶段都进行仔细的验证；<br>③. 文档便于修改，并有复审质量保证。<br>缺陷：①. 划分固定，产生大量文档，增加了开发的工作量；<br>②. 开发是线性的，用户只有在整个程结束时才能看到开发成果；<br>③. 难以响应开发过程中用户的变更需求；<br>④. 早期错误难以发现适用于在软件需求明确，开发技术比较成熟，工程管理较严格的场合下使用（基本不会单独使用瀑布模型作为软件过程模型）<br>Ø <strong>原型化模型</strong>——需求不明确时选用<br>从用户需求出发快速建立一个原型，使用户通过这个原型初步表达出自己的需求，并通过反复修改完善逐渐靠近用户的全部需求，最终形成一个完全满足用户需求的新体系。<br>例：3D打印机<br>Ø <strong>迭代式开发</strong>——适应需求变化<br>开发被组织成一系列固定的短期小项目，称为一次迭代，每次迭代都包括完整的需求分析、设计、实现和测试活动。（理解：发布一系列版本）<br>增量开发：逐渐增加新的功能（缺点：增加功能的过程中可能破坏原有系统）<br>迭代开发：一次性开发出所有功能，后期再逐步完善各个功能<br>优点：①. 快速交付产品；<br>②. 快速响应需求变更；<br>③. 关注用户行为，很快得到用户反馈例：网上视频学习网站<br>Ø <strong>可转换模型</strong>——数学方法（安全、可靠、保密）<br>特点：需要一个精确表述的形式化的规格说明<br>例：汽车防抱系统，嵌入式控制系统<br><strong>关系</strong>：这些模型相互并不排斥，而且经常一起使用，尤其是对一些大型系统的开发。<br><strong>敏捷软件开发的核心价值</strong>：<br>1：“个体和交互”胜过“过程和工具”<br>2：“可以工作的软件”胜过“面面俱到的文档”<br>3：“客户合作”胜过“合同谈判”<br>4：“响应变化”胜过“遵循计划”</p><h1>第三章对象模型</h1><p><strong>面向对象方法的精华</strong>：面向对象=对象+分类+继承+消息通信<br><strong>1：对象</strong>：<br>客观世界都是由各种对象组成，任何事物都是对象，复杂的对象可以由比较简单的对象组合起来<br><strong>2：分类</strong>：<br>把所有的对象都划分为各种类，每个类都定义了一组数据和一组方法<br><strong>3：继承</strong>：<br>按照子类和父类的关系分类组成一个层次结构的系统，下层的子类与上层的父类有相同的特性<br><strong>4：消息通信</strong>：对象与对象之间只能通过传递消息进行通信。<br><strong>接口的概念</strong>：方法声明的集合<br><strong>对象属性和方法的三种访问权限</strong>：<br><strong>1：公有的（public）</strong>：其他对象可以直接访问<br><strong>2：私有的  (private)</strong>：只有特定的对象可以访问<br><strong>3：保护的(protected)</strong>：表示允许相关对象的访问<br><strong>对象的职责</strong>：即一个对象对其他对象的职责<br>1：“知道”型职责:知道各类数据和引用变量<br>2：“做”型职责：执行计算完成某项任务<br>3：“交流”型职责：和其他对象进行交流</p><p>此部分仅为第一到三章的内容，后续部分会依次更新，请您关注我的博客，在我的博客中寻找其他几章内容！！</p>]]></content>
      
      
      <categories>
          
          <category> 课本学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件工程 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
