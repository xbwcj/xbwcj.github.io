<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="《Advances and Open Problems in Federated Learning》阅读笔记, Live My Life">
    <meta name="description" content="">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>《Advances and Open Problems in Federated Learning》阅读笔记 | Live My Life</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">

    <script src="/libs/jquery/jquery.min.js"></script>

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.3.0"><link rel="alternate" href="/atom.xml" title="Live My Life" type="application/atom+xml">
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>




<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Live My Life</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>留言板</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Live My Life</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			留言板
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/xbwcj/xbwcj.github.io" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/xbwcj/xbwcj.github.io" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/4.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">《Advances and Open Problems in Federated Learning》阅读笔记</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        padding: 35px 0 15px 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        padding-bottom: 30px;
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/">
                                <span class="chip bg-color">联邦学习</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/%E7%A7%91%E7%A0%94%E5%AD%A6%E4%B9%A0/" class="post-category">
                                科研学习
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2022-09-06
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2022-09-07
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    36.6k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    127 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="/libs/prism/prism.css">
        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="3-efficiency-and-effectiveness"><a href="#3-efficiency-and-effectiveness" class="headerlink" title="3 efficiency_and_effectiveness"></a>3 efficiency_and_effectiveness</h1><p>&emsp;&emsp;在本节中，我们会探索各种技术和开放性的问题，以解决使联邦学习更加高效和有效的挑战。其中包含了无数种可能的方法，包括：探索更好的优化算法；提供不同的模型给不同的客户端；让机器学习任务，例如：参数搜索、结构搜索和调试在联邦学习场景中更加容易；提高通信效率等等。<br>&emsp;&emsp;解决这些目标的一个基本挑战就是non-IID（非独立同分布）数据的存在，因此，我们首先分析这个问题，并强调潜在的解决方案。</p>
<h2 id="3-1联邦学习中的Non-IID数据"><a href="#3-1联邦学习中的Non-IID数据" class="headerlink" title="3.1联邦学习中的Non-IID数据"></a>3.1联邦学习中的Non-IID数据</h2><p>&emsp;&emsp;虽然通常情况下IID的含义很清楚，但是数据non-IID则有很多种可能。在本节中，我们提供了一种对于non-IID数据的分类方法，对任何客户端分区的数据集可能出现的数据non-IID情况进行分类。最常见的独立但是非同分布的来源是每个客户端对应着一类特定的用户，一片地理区域，或者一段特定的时间。提出的分类法与数据漂移的概念有密切的关系[304, 327]，它研究训练集分布和测试集分布之间的差异。这里，我们仅考虑每个客户端上数据分布的差异。<br>&emsp;&emsp;对于以下内容，我们假设一个监督任务有特征$x$和其对应的标签$y$。联邦学习的统计模型涉及到两个层面的采样： 第一层是对客户端 $i \sim Q$ 进行采样（在可用客户端上的数据分布），第二层是对客户端本地数据分布进行采样 $(x,y) \sim \mathcal{P}_i(x,y)$。<br>&emsp;&emsp;当在联邦学习中提到数据non-IID时，我们通常指的是客户端$i$和客户端$j$所对应的 $\mathcal{P}_i$ 与 $\mathcal{P}_j$ 不同。然而，有一点需要我们特别注意的是：$\mathcal{Q}$ 和 $\mathcal{P_i}$ 是可能随着时间的推移而改变，从而导致另一维度上的non-IID。<br>&emsp;&emsp;为了完整起见，我们注意到，即使对于单个设备上的数据，如果数据没有经过充分的随机打乱顺序，比如：按照时间排列，那么本地数据的独立性也无法保证。一个简单的例子：视频中连续的帧是高度相关的。客户端内部相关性的来源通常可以通过在本地随机打乱顺序来解决。<br><b>非同分布的客户端分布：</b> 根据Hsieh et al.[205]，我们首先研究了数据偏离同分布的一些常见方式，即对于不用的客户端 $i$ 和客户端 $j$ 的分布不同 $P_i \not= P_j$。我们将 $P_i(x,y)$ 重写为 $P_i(y|x)P_i(x)$ 和 $P_i(x|y)P_i(y)$ 让我们能够更加准确地描述他们的区别。</p>
<p><I>特征分布倾斜（协变量飘移）：</I>即使共享 $\mathcal{P}(y|x)$ ，不同客户端上的边缘分布 $\mathcal{P}_i(x)$ 也可能不同 $^4$ 。比如，在手写识别领域，用户在书写同一个单词时也可能有着不同的笔画宽度、斜度等。</p>
<p><I>标签分布倾斜（先验概率飘移）：</I>即使 $\mathcal{P}(x|y)$ 是相同的，对于不同客户端上的边缘分布 $\mathcal{P}_i(y)$ 也可能不同。比如，当客户端与特定的地理区域绑定时，标签的分布在不同的客户端上是不同的。比如：袋鼠只在澳大利亚或动物园里；一个人的脸只在出现在全球的几个地方；对于手机设备的键盘，某些特定人群使用某些表情，而其他人不使用。</p>
<p><I>标签相同，特征不同（概念飘移）：</I>即使共享 $\mathcal{P}(y)$ ，不同客户端上的条件分布 $P_i(x|y)$ 也可能是不同。由于文化差异，天气影响，生活水平等因素，对于相同的标签 $y$ ，对于不同的客户端可能对应着差异非常大的特征$x$。比如：世界各地的家庭图片千差万别，衣着也千差万别。即使在美国，冬季停放的被大雪覆盖汽车的图像只会出现在某些地区。同样的品牌在不同的时间和不同的时间尺度上看起来也会有很大的不同：白天和晚上、季节效应、自然灾害、时尚设计潮流等等。</p>
<p><I>特征相同，标签不同（概念飘移）：</I>即使 $\mathcal{P}(X)$ 是相同的，对于不同客户端上的条件分布 $P_i(y |x)$ 也可能不同。由于个人偏好，训练数据项中的相同特征向量可能具有不同的标签。例如，反映情绪或单词联想的标签有着个人和地区差异。</p>
<p><I>数量倾斜或者不平衡：</I>不同的客户可以拥有着样本数量差异很大的数据。</p>
<p>&emsp;&emsp;在现实世界中，联邦数据集可能同时包含多个上述影响，同时如何去刻画现实世界中的不同客户端之间的数据集的分布是一个重要的开放性问题。大多数关于合成的non-IID数据集的实证工作(例如[289])都集中在标签分布倾斜上，在这种情况下，non-IID数据集是通过基于标签划分现有数据集的“平面”而形成的。为了更好地理解真实世界的non-IID数据集的性质，我们允许构建受控的但真实的non-IID数据集，用于测试算法和评估它们对不同程度的客户端异构的恢复力。<br>&emsp;&emsp;此外，对于不同的non-IID分布可能需要制定不同的缓解策略。例如：在特征分布倾斜的情况下，因为 $\mathcal{P}(y|x)$ 被假设是共同的，这个问题至少在理论上是很清楚的，训练一个全局模型去学习 $\mathcal{P}(y|x)$ 将是合适的。当同一个特征在不同的客户端上被映射到不同的标签上时，某种形式的个性化（详见3.3）可能对学习真正的标签函数很重要。</p>
<p><b>违反独立性：</b> 在训练过程中，只要概率分布$\mathcal{Q}$发生变化，就会其导致违反独立性。举一个具有代表性的例子：在跨设备联邦学习中，设备通常需要满足特定的要求才能够参与训练（详见1.1.2）。设备通常在本地的夜间时间满足这些要求（当它们大概率在充电、使用免费wi-fi和空闲时），因此设备可用性可能存在明显的昼夜不同。更进一步的，因为当地的时间直接对应着经度，因此数据的来源就存在着非常大的地理偏见。Eichner等人[151]描述了这个问题和一些缓解策略，但是仍然有许多问题是待解决的。<br><b>数据集飘移：</b> 最后，我们注意到了分布 $\mathcal{Q}$ 和 $\mathcal{P}$ 对于时间的依赖性可能引入传统意义上的数据集偏移（训练集和测试集的分布不同）。此外，其他的条件可能会使有资格训练联合模型的客户端集合与模型被部署的客户端集合不同。例如，训练比推理可能要求设备拥有更大的内存。这些问题将在第6节被更深入的探讨。采取技术来解决数据集飘移对于联邦学习来说是另一个有趣的开放性问题。</p>
<h3 id="3-1-1处理Non-IID数据的策略"><a href="#3-1-1处理Non-IID数据的策略" class="headerlink" title="3.1.1处理Non-IID数据的策略"></a>3.1.1处理Non-IID数据的策略</h3><p>&emsp;&emsp;联邦学习的最初目标是在所有客户端数据集的并集上训练单个全局模型，而non-IID的数据则使其变得更加困难。一个自然的方法就是修改现有的算法（例如：通过不同的参数选取）或者探索一种新的方法更高效地达到这个目标。本节的3.2.2将讨论这方法。<br>&emsp;&emsp;对于某些应用程序，可能可以增加数据以使不同客户端的数据更加相似。一种方法是创建一个可以全局共享的小数据集。这个数据集可能来自一个公开可用的代表性数据源，一个不涉及隐私敏感的独立于客户数据的数据集，或者可能是原始数据的蒸馏结果（参考Wang等人[404]）。<br>&emsp;&emsp;客户目标函数的异构性使得如何构建目标函数的问题变得更加重要——现在已经不清楚平等地对待所有的样本是否是有意义的。替代方案包括：限制任何一个用户的数据贡献（这对隐私也很重要，见第4节），并在客户端之间引入其他公平概念；参见第6节中的讨论。<br>&emsp;&emsp;但是，如果我们能够在每个设备上的本地数据上运行训练（这对于全局模型的联合学习是必要的），那么训练单个全局模型是否是正确的目标呢？在许多情况下，使用单个模型是首选地，例如：为了向没有数据的客户端提供模型，或者在为了在部署之前允许进行人工验证和质量确认。然而，由于本地训练是可能的，因此每个客户都有一个定制的模型是可行的。这种方法可以把non-IID问题从一个bug变成一个特性，几乎是字面上的意思，即因为每个客户端都有自己的模型，客户端能够独立地参数化模型，看起来有些病态但缺让non-IID变得不那么重要。例如：对每一个 $i$，$\mathcal{P}_i(y)$ 只支持一个标签，那么找到一个高精度的全局模型可能是非常具有挑战性的（特别是当 $x$ 的信息相对不足时），但是训练一个高精度的局部模型是微不足道的（只需要一个持续的预测）。这种多模型方法将在第3.3节中深入讨论。除了解决非独立的客户端分布之外，使用多个模型还可以解决由于客户端可用性变化而导致的违背独立性的问题。例如，Eichner等人[151]的方法运行单个训练，但对不同的迭代进行平均，并基于时区/经度为客户端的推断提供不同的模型。</p>
<h2 id="3-2-联邦学习的优化算法"><a href="#3-2-联邦学习的优化算法" class="headerlink" title="3.2 联邦学习的优化算法"></a>3.2 联邦学习的优化算法</h2><p>&emsp;&emsp;在典型的联邦学习任务中，目标是学习单个全局模型，该模型最小化整个训练数据集上的经验风险函数，训练集数据为所有客户端数据的并集。联邦优化算法和标准分布式训练方法之间的主要区别是需要处理表格 1中的特征——对于优化需要特别关注：non-IID和不平衡的数据、有限的通信带宽、不可靠和有限的可用设备。<br>&emsp;&emsp;当联邦学习在设备的总数非常庞大时（如：跨移动设备），算法每轮只需要一些客户端参与（客户端采样）。此外，每个设备都可能多次参加训练给定的模型，因此算法应当是不状态依赖的。这就排除了直接应用在数据中心上下文中非常有效的各种方法，例如：ADMM之类的有状态优化算法，以及根据前几轮遗留的压缩错误修正更新的有状态压缩策略。<br>&emsp;&emsp;联邦学习算法的在现实中另一个重要考虑是与其他技术的可组合性。优化算法并非在生产部署中独立运行，而是需要与其他技术结合使用，如：第4.2.1节中的加密聚合协议、第4.2.2节的差分隐私(DP)和3.5节中的模型和更新压缩。如第1.1.2节所述，这些技术中有许多可以应用于基本类型，如“对选定的客户机求和”和“向选定的客户机广播”，以这些基本形式表达的优化算法提供了一个有价值的关注点分割，但也可能排除某些技术，例如：通过异步更新。<br>&emsp;&emsp;联邦学习最常用的优化方法之一是联邦平均算法[289]，它适用于本地更新或并行的SGD。在这里，每个客户机在本地运行一些SGD步骤，然后对更新后的本地模型求平均值，以在协同服务器上形成更新的全局模型。伪代码在算法1中给出。<br>&emsp;&emsp;执行本地更新并减少与中央服务器的通信频率，解决了在面对数据位置限制和移动设备客户机有限通信能力情况下的核心挑战。然而，从优化理论的角度来看，这类算法也带来了一些新的算法挑战。在第3.2节中，我们分别讨论了数据跨客户端分布IID和non-IID情况下，联邦优化算法的最新进展和面临的挑战。开发专门针对联邦学习场景特征的新算法仍然是一个重要的开放问题。<br><img src="/2022/09/06/advances-and-open-problems-in-federated-learning-yue-du-bi-ji/1.png" alt="联邦平均算法"></p>
<h3 id="3-2-1-优化算法和IID数据集的收敛率"><a href="#3-2-1-优化算法和IID数据集的收敛率" class="headerlink" title="3.2.1 优化算法和IID数据集的收敛率"></a>3.2.1 优化算法和IID数据集的收敛率</h3><p>&emsp;&emsp;虽然可以对正在优化的每个客户机函数作出各种不同的假设，但最基本的划分是假设IID和non-IID数据。在形式上，在客户端上具有IID数据意味着，用于客户端本地更新的每个mini-batch数据在统计上都与整个训练数据集（所有客户端上本地数据集的并集）的均匀抽取样本（有放回）相同。由于客户独立地收集他们自己的训练数据，这些数据在大小和分布上都有所不同，而且这些数据不与其他客户或中心节点共享，因此IID的假设在实践中几乎不可能成立。但是，这个假设极大地简化了联邦优化算法的理论收敛性分析，并给出了了一个基准线，可以用来理解non-IID数据对优化率的影响。因此，第一步自然是了解IID数据情况下的优化算法。<br>&emsp;&emsp;在形式上，IID的设定让我们能够标准定义随机优化问题</p>
<script type="math/tex; mode=display">
\min _{x \in \mathbb{R}} F(x):=\underset{z \sim P}{\mathbb{E}}[f(x ; z)]</script><p>&emsp;&emsp;我们假设一个间歇性的通信模型，如Woodworth等人[411，第4.4节]，其中$M$个无状态客户端参与每一轮T，在每一轮中，每个客户端可以计算 $K$ 个样本（如mini-batch）的梯度 $z_1,…,z_K$ 从 $\mathcal{P}$ 中IID采样得到（可能使用这些来进行连续的步骤）。在IID数据的假设中，客户端是可互换的，我们可以不失一般性地假设 $M=N$。表格4中，总结了本节中的符号。<br>&emsp;&emsp;对 $f$ 的不同假设会产生不同的保证。我们将首先讨论凸设置，然后观察非凸问题的结果。<br><b>凸问题的基准线和最高水准：</b> 本节中，我们总结了 $H$-平滑的收敛结果，凸（但不一定是强凸）函数的假设下的方差随机梯度的边界为 $\sigma^2$ 。更正式地说，$H$-平滑意味着对于所有 $z,f(\cdot;z)$ 都是可微的，并且具有H-Lipschitz梯度，也就是说，对于任意 $x,y$ 的</p>
<script type="math/tex; mode=display">
\|\nabla f(x, z)-\nabla f(y, z)\| \leq L\|x-y\|</script><p>我们还假设对于所有的 $x$，随机梯度 $\bigtriangledown_x f(x;z)$ 满足：</p>
<script type="math/tex; mode=display">
\underset{z \sim P}{\mathbb{E}}\|\nabla x f(x ; z)-\nabla F(x)\| \leq \sigma^{2}</script><p>当求算法在 $T$ 次迭代后输出 $x_T$ 的收敛率时，我们考虑公式：</p>
<script type="math/tex; mode=display">
\mathbb{E}\left[F\left(x_{T}\right)\right]-F\left(x^{*}\right)</script><p>其中 $x^*=min_xF(x)$ 。这里讨论的所有收敛速度都是这一项的上界。 表5给出了这些函数的收敛结果的汇总。<br>&emsp;&emsp;联邦平均法（又称并行SGD/本地SGD）自然地需要和两个基准线进行对比：首先，我们可以在每一轮本地更新中固定 $x$，并计算当前$x$总的 $KM$ 梯度，以加速的mini-batch数据SGD的运行。令 $\bar{x}$ 表示该算法 $T$ 次迭代的平均值。对于凸问题[256, 119, 132]，我们可以得到上界：</p>
<script type="math/tex; mode=display">
\mathcal{O}\left(\frac{H}{T^{2}}+\frac{\sigma}{\sqrt{T K M}}\right)</script><p>请注意，在训练过程中我们也需要将$z$的随机性考虑到第一项期望的计算中。<br>&emsp;&emsp;第二个自然的基准线是仅考虑所有 $M$ 个活动客户端中的1个客户端，这允许(加速的)SGD连续执行 $KT$ 步。结合上述相同的一般界限，此方法提供的上界为：</p>
<script type="math/tex; mode=display">
\mathcal{O}\left(\frac{H}{(T K)^{2}}+\frac{\sigma}{\sqrt{T K}}\right)</script><p>&emsp;&emsp;比较这两个结果，我们可以看到mini-batch数据SGD达到了最佳的“统计”项 $(\sigma / \sqrt{T K M})$ ，而对于单客户端SGD（忽略其他设备的更更新）获得了最佳的“优化”项 $(H/ \sqrt{(HK)^2})$ 。<br>&emsp;&emsp;局部更新梯度下降方法的收敛性分析是当前研究的一个非常活跃领域[370,271,428,399,334,318,233]。本地更新梯度下降的第一个收敛结果最早可以追溯到Stich[370]对于强凸目标函数和Yu等人[428]对于非凸目标函数的有界梯度范数假设。这些分析使用次优优化项从而达到目标的 $\sigma/ \sqrt{TKM}$ 的统计项（表5总结了凸函数的中间条件的结果）。<br><img src="/2022/09/06/advances-and-open-problems-in-federated-learning-yue-du-bi-ji/2.png" alt="凸函数的中间部分总结结果"></p>
<p>&emsp;&emsp;Wang和Joshi[399]、Stich和Karimireddy[371]去除了有界梯度的假设，进一步将优化项改进为 $HM/T$ 。结果表明，当局部步数 $K$ 小于 $T/M^3$ 时，最优统计项占主导地位。然而，对于一般的跨设备应用程序，我们可能有 $T=10^6$ 和 $M=100$ (表2)，这意味着 $K = 1$。<br>&emsp;&emsp;在文献中，收敛边界经常伴随着关于可以选择多大的 $K$ 以渐近地达到与mini-batch数据SGD收敛速度相同的统计项的讨论。对于强凸函数，Khaled等人[233]改进了这个边界，Stich和Karimireddy[371]进一步改进了这个边界。<br>&emsp;&emsp;对于非凸目标，Yu等[428]表明，局部更新 $K$ 小于 $T^{1/3}/M$ 时，局部梯度下降可以达到 $1/ \sqrt{TKM}$ 的渐近误差边界。Wang和Joshi [399]进一步改进了收敛性保证，他们删除了有界梯度范数假设，并表明本地更新的数量可以大到 $T/M^3$。[399]中的分析也可以应用于具有局部更新的其他算法，从而第一个为具有局部更新的去中心的SGD（或周期性分散SGD）和弹性平均SGD提供收敛保证[432]。Haddadpour等[191]改进了Wang和Joshi [399]中要求Polyak-Lojasiewicz（PL）的条件[226]的函数的界线，这是强凸性质的推广。Haddadpour等[191]研究表明，对于PL函数，每轮 $T^2/M$ 的局部更新可以达到  $\mathcal{O}(1/TKM)$ 收敛。<br>&emsp;&emsp;尽管以上工作着眼于随着迭代迭代错误率的收敛情况，然而从业者最关注时间上的收敛速度。评估时必须根据通信和本地计算的相对成本，考虑参数的设计对每次迭代所花费时间的影响。从这个角度来看，在保持统计速率的同时关注于可以使用的最大$K$可能不是联邦学习中的主要关注点，在联邦学习中，人们可能会假设几乎是无限的数据集（非常大的N）。增加 $M$ 的成本（至少在时间方面）很小，因此，适当地增加$M$以匹配优化项，然后调整 $K$ 来最大化时间性能可能更自然。那么如何选择 $K$ ？增加客户端在聚合之前的本地迭代的更新次数，本地模型被平均时的差异也会随之增加。这就会导致，在训练损失方面的误差收敛相比顺序SGD的$TK$步迭代更慢。然而，执行更多的本地更新可以节省大量的通信成本并减少每次迭代所花费的时间。最优的局部更新次数在这两种现象之间取得了平衡，实现了最快的误差和时钟时间的收敛。Wang和Joshi[400]提出了一种自适应的通信策略，该策略根据训练过程中的训练损失，在一定的时间间隔内对$K$进行调整。<br>&emsp;&emsp;联邦学习中的另一个重要设计参数是模型聚合方法，该方法用于使用选定客户端进行的更新来更新全局模型。在最初的联邦学习论文中，McMahan等人[289]建议对本地模型进行加权平均，与本地数据集的大小成比例。对于IID数据，假定每个客户端都有一个无限大的数据集，这可以简化为对本地模型进行简单的平均。但是，尚不清楚此聚合方法是否为最快的错误收敛方法。<br>&emsp;&emsp;即使在使用IID数据的情况下，联邦优化中还有许多悬而未决的问题。<br>&emsp;&emsp;Woodworth等人[411]强调了与联邦学习设置的优化上限和下限之间的一些差距，特别是对于“间隔通信图”，它包含了本地SGD方法，但是不清楚这种方法的收敛速率和对应的下限。在表5中，我们展示了对于凸设定下的收敛结果。虽然大多数方案都能够达到渐近显性统计项，但没有一个方案能够与加速mini-batch SGD的收敛速度相匹配。联邦平均算法是否能够拉近这个距离仍然是一个问题。<br>&emsp;&emsp;所有 $M$ 个客户端执行相同数量的本地更新的本地更新SGD方法可能会遇到一个常见的可伸缩性问题，即如果任何一个客户端意外地速度慢或失败，则它们就可能会成为瓶颈。可以使用多种方法来解决此问题，但尚不清楚哪种方法是最佳的，尤其是在考虑到潜在的偏差时（请参见第6节）。Bonawitz等[74]建议为客户提供过多的资源（例如，向130万个客户请求更新），然后接受收到的前$M$个更新，并拒绝后续掉队者的消息。稍微复杂一点的解决方案是固定一个时间窗口，并允许客户端在此期间尽可能多地进行本地更新$K_i$轮，然后由中央服务器平均其模型。解决客户端掉队者问题的另一种方法是在 $\tau$ 处固定本地更新的数量，但允许客户端以同步或无锁方式更新全局模型。尽管一些先前的工作[432，267，143]提出了类似的方法，但是误差收敛分析是一个开放且具有挑战性的问题。但是，联邦学习环境中的一个更大挑战是，从第3.2节开始讨论起，异步方法可能会变得难以与差异性隐私或安全聚合之类的互补技术结合起来。<br>&emsp;&emsp;除了本地更新的数量外，每次训练选择的客户群大小的选择与本地更新的数量存在类似的折中点。更新并平均更大数量的客户端可以让每个训练回合的模型产生更好的收敛性，但是由于与客户端进行的计算/通信中的不可预测的尾部延迟，使得训练速度容易受到下降。<br>&emsp;&emsp;在non-IID设定中对本地SGD/联邦平均计算的分析更具挑战性，在下一章中将讨论与其相关的结果和未解决的问题，以及直接解决non-IID问题的专用算法。</p>
<h3 id="3-2-2-优化算法和IID数据集的收敛率"><a href="#3-2-2-优化算法和IID数据集的收敛率" class="headerlink" title="3.2.2 优化算法和IID数据集的收敛率"></a>3.2.2 优化算法和IID数据集的收敛率</h3><p>&emsp;&emsp;相比中心学习中经过充分随机而得到的独立且同分布的（IID）样本，联邦学习的样本使用来自最终用户设备的本地数据，从而产生了多种non-IID数据（第3.1节）。<br>&emsp;&emsp;在这种假设下，对于 $N$ 个客户端都拥有自己的本地数据分布 $\mathcal{P}_i$ 和本地目标函数：</p>
<script type="math/tex; mode=display">
f_{i}(x)=\underset{z \sim \mathcal{P}_{i}}{\mathbb{E}}[f(x ; z)]</script><p>其中 $f(x;z)$ 为模型 $x$ 对于样本 $z$ 的损失。我们通常希望最小化：</p>
<script type="math/tex; mode=display">
F(x)=\frac{1}{N} \sum_{i=1}^{N} f_{i}(x)</script><p>请注意，当 $\mathcal{P}_i$ 是同分布的时候，这就沦落为IID的设定。我们定义 $F^$ 为 $F$ 的的最小值，此时观测值为 $x^$。类似的，我们使用 $f_i^*$ 代表 $f_i$ 的最小值。<br>&emsp;&emsp;像在IID设定中一样，我们假设采用间歇性通信模型（例如Woodworth等人[411,第4.4节]），其中 $M$ 个无状态客户参与$T$轮更新，并且在每个轮次中，每个客户可以计算 $K$ 个样本（例如 mini-batches）的梯度。不同之处在于，样本 $z{i,1},…,z{i,K}$ 由第 $i$ 个客户端的本地数据分布 $\mathcal{P}_i$ 采样而出。与IID设定不同，我们不必假定 $M=N$ ，因为客户端分布并不完全相等。在下文中，如果算法假定 $M=N$ ，我们将忽略 $M$ 并地写作 $N$ 。我们注意到，尽管这样的假设可能与表1中的跨数据孤岛的联邦假设兼容，但在跨设备的假设中通常是不可行的。<br>&emsp;&emsp;尽管[370,428,399,371]主要针对IID假设，但可以通过对数据差异添加假设，例如通过限制客户端梯度与全局梯度[266,261,265,401]之间或客户端之间和全局最优值的差异[264,232]，将分析技巧推广到非IID场景。在这种假设下，Yu等 [429]表明，在non-IID情况下，本地SGD的错误边界变得更糟。为了达到 $1/\sqrt{TKN}$ 的比率（在非凸目标下），本地更新数 $K$ 应该小于 $T^{1/3}/N$ ，而不是像IID情况下的 $T/N^3$ [399]。Li等[261]提出在每个局部目标函数中添加一个近似项，以使该算法对局部目标之间的异质性更加鲁棒。所提出的FedProx算法从经验上提高了联邦平均的性能。但是，目前尚不清楚是否可以证明提高收敛速度。Khaled等[232]假设所有客户都参与，并在客户上使用批量梯度下降，这可能比客户上的随机梯度更快地收敛。<br>&emsp;&emsp;最近，许多工作在放宽所需的假设方面取得了进展，以便更好地应用于联邦平均的实际使用。例如，Lietal[264]研究了在更现实的环境中联邦平均的收敛性，在每一轮中仅涉及一部分客户。为了保证收敛，他们假设选择的客户是随机的，或者是与本地数据集的大小成正比的概率。但是，在实践中，服务器可能无法使用这些理想的方式对客户端进行采样，特别是在跨设备设置中，只有满足资格要求的设备（例如：充电、空闲、免费无线上网）才会被选择参与计算。在一天的不同时间，客户的特征会明显不同。 Eichner等人[151]提出了这个问题，研究了半周期SGD的收敛性，其中从多个具有不同特征的客户区域中按照规则的周期性模式（例如，昼夜）进行采样。<br><img src="/2022/09/06/advances-and-open-problems-in-federated-learning-yue-du-bi-ji/3.png" alt="Non-IID假设"><br><img src="/2022/09/06/advances-and-open-problems-in-federated-learning-yue-du-bi-ji/4.png" alt="其他假设和变量"><br><img src="/2022/09/06/advances-and-open-problems-in-federated-learning-yue-du-bi-ji/5.png" alt="收敛率"><br><b>表6：</b>非iid数据假设下联邦学习中优化方法的收敛性。我们总结了对非iid数据、每个客户机上的本地函数和其他假设的关键假设。我们还介绍了该算法与联邦平均算法的比较，以及消除常数的收敛速度。<br>&emsp;&emsp;我们在表6中总结了最新的理论结果。表6中的所有方法均假定客户端的局部函数具有平滑度或Lipschitz梯度。误差范围由凸函数的最优目标（1）和非凸函数的梯度范数来衡量。对于每种方法，我们展示关键的non-IID假设，每个客户端函数 $f_i(x)$ 的假设以及其他辅助假设。我们还简要地将每种方法描述为联邦平均算法的一种变体，和显示地简化收敛速率消除常数。假设客户端功能是强凸的，则可以提高收敛速度[264,227]。 当客户使用随机局部更新[266,264,265,401,227]时，经常使用有界梯度方差，这是分析随机梯度方法的一种广泛使用的假设。Li等 [264]直接分析联邦平均算法，该算法在每轮随机抽样的 $M$ 个客户端上执行 $K$ 个步骤的本地更新，并提出了本地更新（ $K &gt; 1$）可能减慢收敛速度的速率。证明 $K &gt; 1$ 可能会损害或帮助收敛的领域是一个重要的开放问题。<br><b>与去中心优化的联系：</b>近年来，在去中心优化社区中研究了联邦优化的目标函数。如Wang和Joshi [399]所示，去中心SGD的收敛分析可以与本地SGD结合使用，也可以与网络拓扑矩阵（混合矩阵）的设定适当结合使用。为了减少通信开销，Wang和Joshi [399]提出了周期性去中心SGD（PD-SGD），它允许去中心SGD使用多次本地更新作为联邦平均。Li[265]等人将此算法进行了推广到了non-IID情况。 MATCHA [401]通过随机采样客户端进行计算和通信进一步提高了PD-SGD的性能，并提供了一种收敛分析，表明本地更新可以加速收敛。<br><b>加速和方差减少技术：</b>对于一阶优化方法，动量和方差减少是改善优化和泛化性能的有效的方法。但是，关于如何将动量或减少方差的技术应用于本地SGD和联邦平均，仍未达成共识。SCAFFOLD [227]用控制变量显式地模拟客户端更新中的差异以执行方差减少，这可以快速收敛而不会限制客户端数据分布的差异。至于动量方案，Yu等[429]建议让每个客户保持一个局部动量缓冲区，并在每个通信回合中平均这些局部缓冲区以及局部模型参数。尽管此方法从经验上提高了本地SGD的最终准确性，但它需要两倍的通信成本。Wang等[402]提出了另一种称为SlowMo的动量方案，该方案可以显着提高本地SGD的优化和泛化性能，而无需牺牲吞吐量。Hsu等[206]提出了一种类似于SlowMo的动量方案。 [429,402]均证明了局部SGD的动量变体可以以与同步mini-batch SGD以相同的速率收敛到非凸目标函数的平稳点，但要证明动量能加快联邦假设下的收敛速度是充满挑战性的。</p>
<h2 id="3-3-多任务学习，个性化和元学习"><a href="#3-3-多任务学习，个性化和元学习" class="headerlink" title="3.3 多任务学习，个性化和元学习"></a>3.3 多任务学习，个性化和元学习</h2><p>&emsp;&emsp;在本节中，我们考虑各种“多模型”方法——对于不同的客户端在推断的时候可以高效地使用不同的模型。当面对non-IID数据（第3.1节）时，这些技术尤其重要，因为它们可能优于潜在的全局共享最优模型。我们注意到，个性化已经在完全去中心的设定下也得到了一定的研究[392,54,431,22]，在这种情况下，训练个体模型尤为自然。</p>
<h3 id="3-3-1-通过特征个性化"><a href="#3-3-1-通过特征个性化" class="headerlink" title="3.3.1 通过特征个性化"></a>3.3.1 通过特征个性化</h3><p>&emsp;&emsp;本节的其余部分专门考虑了不同用户在使用不同模型参数（权重）进行运行推断时的技术需求。但是，在某些应用程序中，只需将用户和上下文功能添加到模型中，即可获得相近的收益。例如，考虑一下Hard等人[196]中用于移动键盘中下一个单词预测的语言模型。不同的客户端可能使用不同的语言，实际上，模型参数的设备上个性化已为该问题带来了显着改善[403]。但是，一种更加完善的方法可能是训练一个联邦模型，该模型不仅要输入到目前为止用户输入的单词，还要输入各种其他用户和上下文特征作为输入，例如：该用户经常使用哪些单词？ 他们当前正在使用什么应用程序？ 如果他们正在聊天，他们之前曾向此人发送过哪些消息？ 适当地加以个性化，这样的输入可以允许共享的全局模型产生更好的个性化预测。 但是，由于很大程度上很少有公共数据集包含此类辅助功能，因此探索如何有效合并不同任务上下文信息的模型结构仍然是一个重要的开放问题，有可能极大地提高联邦学习训练的模型的实用性。</p>
<h3 id="3-3-2-多任务学习"><a href="#3-3-2-多任务学习" class="headerlink" title="3.3.2 多任务学习"></a>3.3.2 多任务学习</h3><p>&emsp;&emsp;如果人们将每个客户的本地问题（本地数据集上的学习问题）视为一项单独的任务（而不是单个数据集的一个划分），那么多任务学习[433]的技术将立即变得有意义。值得注意的是，史密斯等[362]引入了用于多任务联合学习的MOCHA算法，直接解决了通信效率、掉队者和容错的挑战。在多任务学习中，训练过程的结果是每个任务得到一个模型。 因此，大多数多任务学习算法都假设所有客户（任务）都参与每个训练周期，并且由于每个客户都在训练一个单独的模型，因此也要求客户有自己的状态。 这使得此类技术与数据孤岛联邦学习应用相关性更高，但在跨设备方案中更难应用。<br>&emsp;&emsp;另一种方法是重新考虑客户（本地数据集）和学习任务（待训练的模型）之间的关系，对于每个客户端观察单个模型和全局模型的共同点。例如，可能可以应用来自多任务学习的技术（以及其他方法，如个性化，将在接下来进行讨论），其中我们将“任务”作为客户端的子集，也许是显示选择的（例如，基于地理区域与设备或者用户的特征），或者可能基于在客户端上学习到的聚类或学习到的图的连接结构[431]。这些算法的发展是一个重要的开放问题。请参阅第4.4.4节，讨论关于稀疏的联邦学习问题（例如，在这种类型的多任务问题中自然会产生的问题）的解决方式，而不必揭示每个客户端所属的客户端子集（任务）。</p>
<h3 id="3-3-3-本地微调和元学习"><a href="#3-3-3-本地微调和元学习" class="headerlink" title="3.3.3 本地微调和元学习"></a>3.3.3 本地微调和元学习</h3><p>&emsp;&emsp;本地微调，我们指的是通过联邦学习训练单个模型，然后将模型部署到所有的客户端中，并在被用于推断前使用本地的数据集通过额外的训练达到个性化的效果。 这种方法自然地融入了联邦学习模型的通常的生命周期（第1.1.1节）。仍然可以在每轮（例如，100秒）中仅使用少量客户样本进行全球模型的培训；部署模型后，仅发生一次向所有客户端（例如数百万个）广播全局模型。唯一的区别是，在使用模型对客户进行实时预测之前，会进行最终的训练，从而将模型为本地数据集进行个性化。<br>&emsp;&emsp;给定一的性能优异的全局模型，对其进行个性化设置的最佳方法是什么？在非联邦学习中，研究人员经常使用微调、迁移学习、域自适应[284,115,56]或者使用本地个性化的模型进行插值。 当然，例如插值等技术，关键在于联邦学习的背景下保证其相应的学习效果。此外，这些技术通常仅假设一对域（源域和目标域），因此可能会丢失联邦学习的一些较丰富的结构。<br>&emsp;&emsp;另一种研究个性化和非个性化的方法是通过元学习来进行，这是一种流行的模型适应设定。 在标准的learning-to-learn（LTL）设置中[52]，它对任务上具有一个元分布，用来学习一个学习算法的样本，例如通过发现参数空间的好的约束。 这实际上很好的对应了第3.1节中讨论的统计设定，其中我们对客户端（任务） $i\sim \mathcal{Q}$ 进行采样，然后从$\mathcal{P_i}$采样该客户端（任务）的数据。<br>&emsp;&emsp;最近，已经开发了一种称为模型不可知元学习（MAML）的算法，即元学习全局模型，它可以仅使用几次局部梯度迭代作为学习适合于给定任务的良好模型的起点。 最值得注意的是，流行的Reptile算法[308]的训练阶段与联邦平均[289]密切相关，即Reptile允许服务器的学习率，并且假设所有客户端都拥有相同数量的数据，但其他都是相同的。Khodaketal等人[234]和Jiang等人[217]探索了FL和MAML之间的联系，并展示了MAML的假设是一个可以被联邦学习用于性化模型的相关框架。其他和差分隐私的关系在[260]中被研究。<br>&emsp;&emsp;将FL和MAML的思想相结合的总体方向是相对较新的，存在许多未解决的问题：</p>
<ol>
<li>监督任务的MAML算法评估主要集中在合成图像分类问题上[252,331]，其中可以通过对图像类别进行下采样来构造无限的人工任务。用于模拟FL实验的现有数据集建模的FL问题（附录A）可以作为MAML算法的现实基准问题。</li>
<li>观察到的全局准确性与个性化准确性之间的差距[217]提出了一个很好的论据，即个性化对于FL至关重要。但是，现有的工作都没有清楚地阐明用于衡量个性化表现的综合指标。例如，对于每个客户来说，小的改进是否比对一部分客户的更大改进更好？相关讨论，请参见第6节。</li>
<li>Jiang等[217]强调了一个事实，即具有相同结构和性能但经过不同训练的模型可以具有非常不同的个性化能力。尤其是，以最大化全局性能为目标去训模型似乎实际上可能会损害模型的后续个性化能力。理解这个问题的根本原因和FL社区与更大的ML社区都相关。</li>
<li>在此多任务/LTL框架中，已经开始研究包括个性化和隐私在内的几个具有挑战性的FL命题[234,217,260]。是否还可以通过这种方式分析其他例如概念漂移的问题，比如作为终身学习中的问题[359]？</li>
<li>非参数传递LTL算法（例如ProtoNets [363]）是否可以用于FL？</li>
</ol>

<h3 id="3-3-4-何时进行全局FL训练更好"><a href="#3-3-4-何时进行全局FL训练更好" class="headerlink" title="3.3.4 何时进行全局FL训练更好"></a>3.3.4 何时进行全局FL训练更好</h3><p>&emsp;&emsp;哪些是联邦学习可以为你做，而在一个设备上进行本地学习是做不了的？当本地数据集很小且数据为IID时，FL显然具有优势，实际上，联邦学习[420,196,98]的应用实际受益于跨设备训练单个模型。另一方面，给non-IID的分布的类型（例如，$\mathcal{P}_{i}(y|x)$ 跨客户端是完全不同的），则局部模型会更好。因此，一个自然的理论上的问题是确定在什么条件下共享全局模型比独立每设备模型更好。假设我们为每个客户机 $k$ 训练一个模型 $h_k$，使用该客户机可用的大小为 $m_k$ 的样本。我们能保证 $h_{FL}$ 通过联邦学习学习到的模型在用于客户 $k$ 时至少和 $h_k$ 一样准确吗?我们能量化通过联邦学习可以期望多大的改进吗?我们能否在理论上保证至少与自然基线（ $h_k$ 和 $h_{FL}$ ）的表现相匹配的个性化策略?<br>&emsp;&emsp;其中一些问题与先前在多源域适应和不可知联合学习方面的工作有关[284,285,203,303]。这些问题的难易程度取决于各方之间的数据分配方式。例如，如果数据是垂直切分的，则每一方都维护有关公共实体的不同功能集的私有记录，则这些问题可能需要解决联邦学习任务中的记录链接[108]。独立于私下进行记录链接的最终技术要求[348]，该任务本身在现实世界中恰好有很大的噪声倾向[347]，只有很少的结果讨论了它对训练模型的影响[198]。可以在有监督的学习中使用损失分解技巧来缓解垂直划分假设本身，但实际的好处取决于数据的分布和参与方的数量[320]。</p>
<h2 id="3-4-使用于联邦学习的ML工作流"><a href="#3-4-使用于联邦学习的ML工作流" class="headerlink" title="3.4 使用于联邦学习的ML工作流"></a>3.4 使用于联邦学习的ML工作流</h2><p>&emsp;&emsp;在将标准机器学习的工作流和流水线（包括数据扩充、功能工程、神经网络结构设计、模型选择、超参数优化和调试）适应去中心数据集和资源受限的移动设备时，会遇到许多挑战。我们在将下面讨论其中一些挑战。</p>
<h3 id="3-4-1-超参数调整"><a href="#3-4-1-超参数调整" class="headerlink" title="3.4.1 超参数调整"></a>3.4.1 超参数调整</h3><p>&emsp;&emsp;在资源有限的移动设备上使用不同的超参数进行多轮培训可能会受到限制。对于小型设备，这可能导致过度使用有限的通信和计算资源。但是，最近的深度神经网络在很大程度上依赖于有关神经网络的结构、正则化和优化的超参数选择。对于大型模型和大规模设备上的数据集，评估可能会很昂贵。在AutoML [339,237,241]的框架下，超参数优化（HPO）历史悠久，但它主要涉及如何提高模型的准确性[59,364,321,159]，而不是针对移动设备的通信和计算效率。因此，我们期望在联邦学习的背景下，进一步的研究应考虑研发解决方案，以实现高效地超参数优化。<br>&emsp;&emsp;除了通用方法来解决超参数优化问题外，对于特殊的训练空间去针对性地去发展容易调整的优化算法也是一个主要的开放领域。中心式训练已经需要调整学习率、动量、批量大小和正则化等参数。联邦学习可能会添加更多的超参数，如：分别调整聚合/全局模型更新规则和本地客户端优化程序、每轮选择的客户端数量、每轮本地步骤的数量、更新压缩算法的配置等等。除了更高维度的搜索空间之外，联邦学习通常还需要更长的训练时间并受限于有限的计算资源。应该通过对超参数设置具有鲁棒性的优化算法（相同的超参数值适用于许多不同的现实世界数据集和网络结构）以及自适应或自调整[381,75]算法来解决这一挑战。</p>
<h3 id="3-4-2-神经结构设计"><a href="#3-4-2-神经结构设计" class="headerlink" title="3.4.2 神经结构设计"></a>3.4.2 神经结构设计</h3><p>&emsp;&emsp;我们建议研究人员和工程师在联邦学习环境中探索神经体系结构搜索（NAS）。这是由于当前使用预定的深度学习模型的方法的缺陷引起的：当用户生成的数据对模型开发人员不可见时，深度学习模型的预定网络结构可能不是最佳的设计选择。例如，神经体系结构可能具有特定数据集的某些冗余组件，这可能导致设备上不必要的计算。对于non-IID数据分布，可能会有更好的网络体系结构设计。第3.3节中讨论的个性化方法仍在所有客户端之间共享相同的模型架构。NAS的最新进展[332,154,333,55,322,273,417,154,279]提供了解决这些缺陷的潜在方法。NAS有三种主要方法，它们利用进化算法、强化学习或梯度下降来搜索特定数据集上特定任务的最佳架构。其中，基于梯度的方法利用权重共享的高效梯度反向传播，将架构搜索过程从超过3000个GPU一天减少到只用1个GPU一天。最近发表的另一篇有趣的论文涉及权重不可知神经网络[170]，声称仅神经网络架构，无需学习任何权重参数，就可以为给定任务提供编码解决方案。如果该技术进一步发展并得到广泛使用，则可以将其应用于联邦学习而无需在设备之间进行协作训练。尽管尚未针对分布式设定（例如联帮学习）开发这些方法，但将它们全部转换为联邦设定都是可行的。因此，我们认为在联邦学习环境中针对全局或个性化模型的神经体系结构搜索（NAS）是有希望的研究方向。</p>
<h3 id="3-4-3-联邦学习的调试和可解释性"><a href="#3-4-3-联邦学习的调试和可解释性" class="headerlink" title="3.4.3 联邦学习的调试和可解释性"></a>3.4.3 联邦学习的调试和可解释性</h3><p>&emsp;&emsp;尽管联邦模型联邦训练取得了实质性进展，但这完全是ML工作流的一部分。经验丰富的建模人员可以直接检查子数据集的任务，包括基本的健全性检查、调试错误分类\发现异常值\手动标记样本或检测训练集中的偏差。开发隐私保护技术来解决此类去中心的问题是主要的开放性问题上。最近，Augensteinetal[32]提出了使用经过联帮学习训练的差分生成模型（包括GAN）的使用，以回答此类问题。但是，仍然存在许多悬而未决的问题（请参见[32]中的讨论），特别是改进FL DP生成模型的精确度的算法的开发。</p>
<h2 id="3-5-通信和压缩"><a href="#3-5-通信和压缩" class="headerlink" title="3.5 通信和压缩"></a>3.5 通信和压缩</h2><p>&emsp;&emsp;现在，众所周知，通信可能是联邦学习的主要瓶颈，因为无线连接和其他最终用户互联网连接的运行速率通常低于数据中心内或数据中心间连接的速率，并且可能昂贵且不可靠。这引起了最近对减少联邦学习的通信带宽的极大兴趣。联邦平均和模型更新的量化和量化到少量比特的方法已经证明，通信成本显着降低，并且对训练精度的影响最小[245]。但是，尚不清楚是否可以进一步降低通信成本，以及这些方法中的任何一种或其组合是否可以接近在联邦学习中的通信和准确性之间提供最佳的折衷。描述这种精确性和通信量之间的基本平衡是理论统计学最近的研究热点[434,81,195,11,47,380]。这些工作描述了在通信约束下用于分布式统计估计和学习的最佳最小极大速率。然而，由于这些理论工作通常忽略了优化算法的影响，因此很难在实践中从这些理论工作中得出具体的结论来减少通信带宽。利用这种统计方法来指导实际的训练方法仍然是一个开放的方向。<br><b>压缩目标：</b> 由于当前设备中计算机、内存和通信资源的限制，有几个不同的具有实用价值的压缩目标如下： </p>
<ol>
<li>梯度压缩，减少从客户端到服务器通信的对象的大小，该对象用于更新全局模型；</li>
<li>模型广播压缩，减小从服务器向客户端广播的模型的大小，客户端从该模型开始本地训练；</li>
<li>减少本地计算，修改整体训练算法，使本地训练过程在计算上更加高效。</li>
</ol>

<p>&emsp;&emsp;这些目标在大多数情况下是互补的。其中，(1)在总运行时间方面具有最大的实际影响潜力。这是因为客户端连接的上传速度通常比下载速度慢，因此与(2)相比，可以获得更多的带宽，也因为在许多客户端上平均的效果可以实现更积极的有损压缩方案。通常，(3)与(1)和(2)通过特定的方法共同实现。<br>&emsp;&emsp;许多现有的文献适用于目标(1)[245, 376, 244, 20, 204]。(2)对一般收敛性的影响直到最近才得到研究，在[231]中有一个有限的分析。Caldas等人[87]提出了一种联合处理所有(1)、(2)和(3)的方法，该方法通过约束所需的模型更新，使得只有模型变量特定的元素需要在客户端被使用。<br>&emsp;&emsp;在跨设备FL中，算法通常不能假设客户端上保留了任何状态（表1）。但是，在跨数据孤岛FL设置中通常不存在这种约束，在跨设备FL设置中，相同的客户端重复参与。因此，一些更广泛的关于错误修正的思想，如[272,346,396,380,228,371]在这种情况下是相关的，其中许多可以同时处理(1)和(2)。<br>&emsp;&emsp;另一个目标是修改训练程序，以使最终模型更紧凑或更有效地进行推理。这个主题在更大的ML社区中得到了很多关注[194,120,436,270,312]，但是这些方法或者没有直接对应到联邦学习，或者使训练过程更加复杂，这使得它变得很难采纳。同时产生一个紧凑的最终模型的研究，也同时解决了上述三个目标，具有产生实际影响的巨大潜力。<br>&emsp;&emsp;对于梯度压缩，依据最小的最大感知量出现了一些现有的工作[376]，以表征最坏的情况。然而，通常在信息论中，压缩保证是特定于实例的，并取决于基础分布的熵[122]。换句话说，如果数据易于压缩，则可以证明它们被大量压缩。 有趣的是，是否可以为梯度压缩获得类似的实例特定结果。同样，最近的工作表明，以数据相关的方式学习压缩方案可以显着提高数据压缩[412]和梯度压缩的压缩率。因此，值得在联邦设定中评估这些与数据相关的压缩方案[171]。<br><b>差分隐私和安全聚合的兼容：</b> 联邦学习中使用的许多算法，例如安全聚合[72]和使噪声变淡以实现差分隐私[7，290]的机制，都没有设计用于压缩或量化通信。例如，Bonawitz等人的Secure Aggregation协议的直接应用。 [73]要求每个标量有一个额外的 $O(logM)$ 通信位，其中 $M$ 是要累加的客户端数，这可能会使$M$大时更新的主动量化无效（尽管更有效的方法请参见[75]）。现有的噪声添加机制假定在每个客户端上添加实值高斯或拉普拉斯噪声，这与用于减少通信的标准量化方法不兼容。我们注意到，最近的一些工作允许有偏估计，并且可以很好地与Laplacian噪声[371]一起使用，但是无论如何都不会放弃差分隐私，因为它们在两轮之间具有独立性。在增加离散噪声方面有一些工作[13]，但目前还不清楚这些方法是否最佳。 因此，联邦设定下具有兼容性和安全性的压缩方法是一个有价值的开放问题。<br><b>无线联邦学习协同设计：</b> 联邦学习中的现有文献通常忽略了模型训练期间无线通道动态的影响，这有可能破坏训练周期，从而破坏整个生产系统的可靠性。特别是，无线干扰，嘈杂的信道和信道波动会严重阻碍服务器与客户端之间的信息交换（或直接在单个客户端之间进行信息交换，如在完全分散的情况下，请参阅第2.1节）。对于任务关键应用程序而言，这是一项主要挑战，其根源在于减少延迟和增强可靠性。应对这一挑战的潜在解决方案包括联邦蒸馏（FD），其中工人交换它们的模型输出参数（logit）而不是模型参数（梯度和/或权重），并通过适当的通信和计算资源来优化工人的调度策略[ 215、316、344]。另一种解决方案是利用无线信道的独特特性（例如广播和叠加）作为自然的数据聚合器，其中，不同工作人员同时传输的模拟波会叠加在服务器上，并由无线信道进行系数权衡[8]。这样可以在服务器上更快地进行模型聚合，并且可以将训练速度加速因子提高到参与者的数量。这与传统的正交频分复用（OFDM）范式形成鲜明对比，在传统的正交频分复用（OFDM）范式中，工人在正交频率上上传其模型，而正交频率的性能会随着参与数量的增加而降低。</p>
<h2 id="3-6-应用到更多类型的机器学习问题和模型"><a href="#3-6-应用到更多类型的机器学习问题和模型" class="headerlink" title="3.6 应用到更多类型的机器学习问题和模型"></a>3.6 应用到更多类型的机器学习问题和模型</h2><p>&emsp;&emsp;迄今为止，联邦学习主要考虑了监督学习任务，其中每个客户都自然可以获得标签。 将FL扩展到其他ML范式，包括强化学习、半监督和无监督学习、主动学习和在线学习[200，435]都提出了有趣且开放的挑战。<br>&emsp;&emsp;与FL高度相关的另一类重要模型是可以表征预测不确定性的模型。大多数现代深度学习模型无法表示其不确定性，也无法对参数学习进行概率解释。这推动了贝叶斯模型与深度学习相结合的工具和技术的最新发展。从概率论的角度来看，使用单点估计进行分类是不合理的。贝叶斯神经网络[358]已经被提出并显示出对过度拟合更为健壮，并且可以轻松地从小型数据集中学习。贝叶斯方法通过其参数以概率分布的形式进一步提供不确定性估计，从而防止过度拟合。此外，借助概率推理，人们可以预测不确定性如何减小，从而使网络做出的决策随着数据大小的增长变得更加准确。<br>&emsp;&emsp;由于贝叶斯方法相比深度模型在置信度上拥有丰富的经验，并且在许多任务上也能达到最先进的性能，因此人们希望贝叶斯方法能够为经典的联邦学习提供理论上的改进。实际上，Lalitha等人的初步工作[254]表明，合并贝叶斯方法可用于跨non-IID数据和异构平台的模型聚合。但是，必须解决有关可伸缩性和计算可行性的诸多问题。</p>
<h1 id="4-privacy"><a href="#4-privacy" class="headerlink" title="4 privacy"></a>4 privacy</h1><p>&emsp;&emsp;机器学习过程由许多功能不同的角色参与运作。例如，用户可以通过与设备交互来生成训练数据，在机器学习训练过程中，其从这些数据中提取人机交互模式（例如，以训练后模型参数的形式），之后机器学习工程师或分析师可以评估该训练模型的质量，最后可能将该模型部署在最终用户主机上，以支持定制的用户体验（见下图1）。<br>&emsp;&emsp;在一个理想的世界里，系统中的每一个参与者只会学到扮演他们角色所需的信息。例如，如果分析师只需要确定某个特定的质量度量是否超过了所需的阈值，以便授权将模型部署到最终用户，那么在理想化的世界中，该度量值是分析师可以获得的唯一信息；该分析师既不需要访问训练数据，也不需要访问模型参数。类似地，最终用户体验到的可能只需要由经过训练的模型提供的预测，而不需要其他任何内容。<br>&emsp;&emsp;此外，在理想的世界中，系统中的每个参与者都能够轻松、准确地推断出自己和他人的哪些个人信息可能通过参与系统而泄露，参与者将能够利用这一推理结果，就是否参与以及如何参与做出明智的选择。<br>&emsp;&emsp;创建一个具有上述所有理想隐私属性的系统本身将是一项令人望而生畏的壮举，若其还可以实现其他令人满意的属性，则更是难上加难，比如所有参与者的易用性、最终用户体验的质量和公平性（以及影响体验结果的模型），智能地使用通信和计算资源、抵御攻击和失败的能力等。<br>&emsp;&emsp;与其追求无法企及的完美，我们不如另辟蹊径——整个系统由模块化单元组成，这些单元可以相对独立地进行学习和改进，同时我们也要注意，我们最终必须根据上述我们的理想隐私目标，测量整个系统的隐私属性。本节中，我们将提出目前无论是通过单个模块实现方法还是通过整个系统实现方法，还不了解如何同时实现所有目标的领域，作为开放性研究问题。<br><img src="/2022/09/06/advances-and-open-problems-in-federated-learning-yue-du-bi-ji/6.png" alt="图1：fl训练的模型的生命周期和联邦学习系统中的各种参与者。(重复第7页)"><br>&emsp;&emsp;联邦学习提供了一个有吸引力的结构，可以将整个机器学习工作流程分解成我们想要的可实现的模块单元。联邦学习模型的一个主要优点是它可以通过数据最小化为参与的用户提供一定程度的隐私：设备从不发送原始用户数据，只将对模型的更新（例如梯度更新）发送到中央服务器。这些模型更新更侧重于要完成的学习任务而非关注原始数据（即，与原始数据相比，它们严格不包含关于用户的附加信息，而且通常不包含其他意义），并且单个更新只需要由服务器暂时保存。<br>&emsp;&emsp;虽然这些特性可以在集中所有训练数据的基础上提供显著的实用性隐私改进，但是在这个基线联邦学习模型中仍然没有隐私的正式保证。例如，可以构造这样的场景，在该场景中，原始数据的信息从客户端泄漏到服务器。比如，知道以前的模型和用户的梯度更新将允许某一方推断该用户持有的训练示例。因此，本节调查现有的结果，并概述了设计可以提供严格的隐私保障的联邦学习系统的开放性的挑战。我们更专注于联邦学习和分析设置中特定的问题，而不考虑了在一般的机器学习设置中也会出现的问题。<br>&emsp;&emsp;除了针对用户隐私的攻击之外，还有其他种类的对联邦学习的攻击；例如，对方可能会试图阻止模型被学习，或者他们可能会试图使模型产生偏向对方的训练结果。我们稍后在第5章讨论这些类型的攻击的讨论。<br>&emsp;&emsp;本章的其余小节梗概如下。第4.1节讨论了我们希望提供抵御的各种威胁模型。第4.2节列出了一套核心工具和技术，可用于针对第4.1节中讨论的威胁模型提供严格的保护。第4.3节假定可信服务器的存在，并讨论在对抗对手和/或分析师提供保护方面的公开问题和挑战。第4.4节讨论了在没有完全可信服务器的情况下的开放性问题和挑战。最后，第4.5节讨论了关于用户感知的开放性问题。</p>
<h2 id="4-1-参与者，威胁模型与深层隐私"><a href="#4-1-参与者，威胁模型与深层隐私" class="headerlink" title="4.1 参与者，威胁模型与深层隐私"></a>4.1 参与者，威胁模型与深层隐私</h2><p>&emsp;&emsp;在联邦学习中，对隐私风险的规范处理需要一种整体的、跨学科的方法。对于一些风险类型，可以通过将现有技术扩展到指定场景中从而保护隐私和减轻风险，而其他更复杂的风险类型则需要跨学科的协同努力。<br>&emsp;&emsp;隐私不是二进制量，甚至不是标量。这种规范处理的第一步是准确描述不同的参与者（见第1节图1，为方便起见，在第35页重复）及其在模型中扮演的角色，最终确定相关的威胁模型（见表7）。例如，我们希望将服务器管理员的视图与使用所学模型的分析师的视图区分开来，因为可以想象，设计用于针对恶意分析师提供强大隐私保证的系统可能不会提供任何恶意攻击的机会。这些参与者行为模式很好映射到其他文献中讨论的威胁模型上；例如，在Bittau等人中。[67，第3.1节]，“编码器”对应于客户机，“洗牌者”通常对应于服务器，“分析器”可能对应于服务器或分析师完成的后处理。<br>&emsp;&emsp;例如，一个特定的系统可能提供差异性的隐私保证（差异性隐私将在4.2.2节规范化介绍，这里知道更小的ε表示更强的隐私性即可），比如向服务器管理员提供的特定参数为ε，而分析师观察到的参数结果可能具有更高的保护性ε’&lt;ε。<br>&emsp;&emsp;此外，这一保证可能仅适用于能力受到特定限制的对手，例如可以观察服务器上发生的所有事情（但不能影响服务器的行为）的对手，这类对手同时完全控制占客户端总数比例为γ的客户端（“完全控制”即可以观察他们可获知的所有数据并以任意方式影响其行为）；对手也可能被认为无法破解在特定安全级别σ下，实例化的加密机制。为了对抗实力突破这些限制的对手，在服务器管理员的看来可能仍然需要差异性隐私保证，但认为分析师观察的结果在较弱的隐私保护级别ε’&gt;ε。<br>&emsp;&emsp;正如我们在本例中看到的，精确地指定系统的假设和隐私目标，以及诸如差异性隐私保证、老实但好奇行为等安全性概念，可以很容易地通过到几个参数（ε、ε’、ε0、γ、σ等）进行具体实例化。<br>&emsp;&emsp;实现联邦学习所需的所有隐私属性通常需要将下述的许多工具和技术组合到端到端系统中，包括以下两种：多种分层策略都是为了保护系统的同一部分（例如，在可信执行环境（TEE）中运行安全多方计算（MPC）协议的一部分，使对手更难对该组件产生足够大的损害）以及使用不同的策略来保护系统中不同的部分（例如，使用MPC保护模型更新的聚合，然后在服务器之外共享聚合更新之前使用隐私披露技术）。<br>&emsp;&emsp;因此，在两种技术都无法提供其预期隐私保护能力的情况下，我们提倡构建这样一种优美的联邦系统，即尽可能降低隐私性。例如，在TEE中运行MPC协议的服务器组件可能允许维护隐私，即使TEE安全性或MPC安全性假设中的一个（但不是两个）在实践中不成立。另一个例子是，要求客户端向服务器端TEE发送渐变更新，而要求客户端将原始训练示例发送到服务器端TEE将被强烈不推荐。因为一旦TEE的安全性失效，前者的隐私性期望将更优美地降级。我们将这种优美降级的原则称为“深度隐私”，类似于成熟的深度防御网络安全原则[311]。</p>
<h2 id="4-2-工具与技术"><a href="#4-2-工具与技术" class="headerlink" title="4.2 工具与技术"></a>4.2 工具与技术</h2><p>&emsp;&emsp;一般来说，联邦学习计算的目的是让分析师或工程师通过计算请求获得结果，这可以看作是对分布式客户机数据集上的函数f的评估（通常是机器学习模型训练算法，但可能更简单，例如基本的数据统计）。有三个隐私方面需要解决。<br>&emsp;&emsp;首先，我们需要考虑f是如何计算的，以及在这个过程中中间结果的信息流是什么，它主要影响对恶意客户端、服务器和管理参与者的敏感性。除了设计系统中的信息流（例如提前数据最小化）外，包括安全多方计算（MPC）和可信执行环境（TEEs）等安全计算相关技术对于解决这些问题特别重要。这些技术将在第4.2.1节中详细讨论。<br>&emsp;&emsp;其次，我们必须考虑该计算哪些内容。换言之，f本身的计算结果会向分析师和域内参与者透露了参与客户的多少信息。这与隐私保护披露技术，特别是差异隐私（DP）是高度相关的，将在第4.2.2节中详细讨论。<br>&emsp;&emsp;最后，可验证性也是需要考虑的问题，即客户机或服务器能够向系统中的其他人证明他们已忠实地运行了所需的指令，而不泄露他们运行过程中的潜在隐私数据。验证技术，包括远程认证和零知识证明，将在第4.2.3节中讨论。</p>
<h3 id="4-2-1-安全计算"><a href="#4-2-1-安全计算" class="headerlink" title="4.2.1 安全计算"></a>4.2.1 安全计算</h3><p>&emsp;&emsp;安全计算的目标是评估计算分散输入的函数，通过判断其是否仅向预期各方显示计算结果，而不显示任何附加信息（例如各方的输入或任何中间结果）。<br><b>安全多方计算：</b>安全多方计算（MPC）是密码学的一个子领域，与这样一个问题有关：一组参与方计算其隐私输入通过共识函数得到输出，从而可以只向每个参与方显示期望的输出。这一领域在20世纪80年代由姚[422]开创。由于理论和工程上的突破，该领域已经从单纯的理论研究转向工业上的部署技术[71、70、257、29、169、209、210]。值得注意的是，MPC定义了一组技术，应该更多地被视为安全计算中的领域或安全性的一般概念，而不是技术本身。MPC的一些最新进展可以归因于低级原语的突破，例如不经意传输协议[211]和具有同态性质的加密方案（如下所述）。</p>
<table border="1">
<caption align="top"><b>表4-1 不同的敌对参与者的多种威胁模型<b></b></b></caption>
<tr>
<td><b>数据/访问节点</b></td>
<td><b>参与者</b></td>
<td><b>危胁模型</b></td>
</tr>
<tr>
<td>客户端</td>
<td>通过系统设计或破坏设备获得客户端设备的最高访问权限者</td>
<td>恶意客户端可以检查所参与轮次从服务器接收的全部消息（包括模型迭代），并可以篡改训练过程。老实但好奇的客户端可以检查从服务器接收的所有消息，但不能篡改培训过程。在某些情况下，安全包围/TEEs等技术可能会限制此类攻击者的影响和信息可见性，从而削弱该模型威胁程度。</td>
</tr>
<tr>
<td>服务器</td>
<td>通过系统设计或破坏设备获得服务器设备的最高访问权限者</td>
<td>恶意服务器可以检查所有轮次发送到服务器的全部消息（包括梯度更新），并可以篡改训练过程。老实但好奇的客户端可以检查发送到服务器的所有消息，但不能篡改培训过程。在某些情况下，安全包围/TEEs等技术可能会限制此类攻击者的影响和信息可见性，从而削弱该模型威胁程度。</td>
</tr>
<tr>
<td>输出模型</td>
<td>工程师与分析师</td>
<td>恶意分析师或模型工程师可以访问系统的多组输出，例如，使用不同超参数的多个训练运行的模型迭代序列。该向这类参与者发布什么信息是一个重要的系统设计问题。</td>
</tr>
<tr>
<td>部署模型</td>
<td>其他设备</td>
<td>在跨设备联邦学习场景下，最终模型可能部署到数亿个设备上。访问部分受损的设备可能仍满足黑盒模型，而访问完全受损的设备可以认为是白盒模型。</td>
</tr>
</table>

<p>&emsp;&emsp;密码学解决方案的共同点是，操作通常在一个有限的字段上完成（即，素数p都是整数），这在表示实数时会带来困难。一种常见的方法是调整机器学习模型及其训练程序，即通过标准量化操作并依赖精心设计的量化模式，以确保下（上）溢量在可控范围[172、14、182、77]。<br>&emsp;&emsp;即使在恶意对手面前，任何函数都可以安全计算[183]这一点在几十年间达成了共识。虽然通用解决方案存在，但它们的性能特征常常使它们在实际设置中不适用。因此，研究显著趋势是线性和逻辑斯蒂回归[309，172，302]和神经网络训练和推理[302，14，46]等应用设计定制协议。这些协议通常在孤井互通的设置中进行，或是将计算委托给一组不相互协作的计算服务器的变体模型。将这些协议移植到跨设备设置并不简单，因为它们需要大量的通信。<br>&emsp;&emsp;同态加密 同态加密（Homomorphic encryption）方案允许在密文上直接执行某些数学运算，而无需事先解密。同态加密通过使参与者计算函数值，同时保持值隐藏，是一个使MPC成为可能的强大工具。<br>&emsp;&emsp;从一般的全同态加密（FHE）〔176〕到更高水平的变体[79, 160, 80，112 ]，同态加密存在多种实现[3, 350, 4 ]。一些称为部分同态的方案同样具有实际意义，例如包括ElGamal和Paillier，允许同态加法或乘法。加性同态加密称为孤井互通设置中MPC协议的一种成分[309 198]。文献[345]调研了一些同态加密软件库，并简要说明了选择库时应考虑的标准/特性。</p>
<table border="1">
<caption align="top"><b>表4-2 不同技术及其特性描述<b></b></b></caption>
<tr>
<td><b>技术</b></td>
<td><b>特性描述</b></td>
</tr>
<tr>
<td>差异隐私（本地、中心、混编、聚合、混合模型）</td>
<td>从包含用户的数据集的输出分析中可以了解到的个人信息量。具有差分隐私的算法必然包含一定数量的随机性或噪声，可以对其进行调整以掩盖用户对输出的影响。</td>
</tr>
<tr>
<td>安全多方计算</td>
<td>两个或多个参与者协作，通过密码学模拟完全可信的第三方，第三方满足：   •计算所有参与者提供的输入的函数；   •向选定的部分参与者显示计算结果，同时任一方没有进一步学习。</td>
</tr>
<tr>
<td>同态加密</td>
<td>允许一方在不具有纯文本访问权限的情况下，不解密密文下对密文执行数学运算，从而计算出它们的数据的函数。尽管计算成本更高，任意复杂度的数据函数都可以通过这种方式计算（“完全同态加密”）。</td>
</tr>
<tr>
<td>可信执行环境（安全环境）</td>
<td>可信执行环境提供了在远程计算机上可靠地运行代码的能力，即使不信任计算机的所有者/管理员。这是通过限制任何一方（包括管理员）的能力来实现的。尤其是，可信执行环境具有以下性质373]：   •一致性：除非程序显式发布消息，否则程序的执行状态始终不可见；   •完整性：除非程序显式接收输入，否则程序的执行不会受到影响；   •可测量/认证性：可信执行环境可以向远程方证明什么程序（二进制）正在执行，以及它的起始状态是什么，定义了一致性和完整性的初始条件。</td>
</tr>
</table>

<p>&emsp;&emsp;考虑在联邦学习设置中使用同态加密，会遇到谁该持有该模式的密钥这一问题。虽然每个客户机加密其数据并将其发送到服务器端进行同态计算的想法很有吸引力，但服务器不应该能够解密单个客户机的提交数据。克服这一问题的一个简单方法是依赖一个持有密钥并解密计算结果的外部非合谋方。然而，大多数同态加密方案要求密钥经常更新（例如，由于易受选择密文攻击[102]）。此外，使用信任的非共谋方不在标准的联邦学习设置中。<br>&emsp;&emsp;解决此问题的另一种方法是依赖于分布式（或阈值）加密方案，其中密钥在各方之间分发。Reyzin等人。[336]和Roth等人。[341]提出在跨设备设置中计算总和的这种解决方案。他们的协议使用了加性同态方案（分别是基于ElGamal和基于格的方案的变体）。<br><b>可信执行环境：</b>可信执行环境（TEEs，也称为安全环境）可以将联邦学习过程的一部分转移到云中的可信环境中，而该环境的代码可以被证明和验证。可信执行环境拥有几个关键性质，使他人相信，一段程序已被忠实而保密地执行[373]：</p>
<ol>
<li><b>一致性：</b>除非程序明确发布消息，否则程序的执行状态仍是保密的。</li>
<li><b>完整性：</b>除非程序显式地接收输入，否则程序的执行不会受到影响。</li>
<li><b>可测量/认证性：</b>可信执行环境可以向远程方证明什么程序（二进制）正在执行，以及它的起始状态是什么，定义了一致性和完整性的初始条件。</li>
</ol>

<p>&emsp;&emsp;可信执行环境已经在实现不同体系结构上被，包括英特尔的SGX处理器[208，116]、ARM的TrustZone[2，1]和Sanctumon RISC-V[117]，它们在上述关键性质上的性能各不相同。<br>&emsp;&emsp;当前的安全环境在内存方面受到限制，只提供对CPU资源的访问，即它们不允许在GPU或机器学习处理器上进行处理（Tram`er和Boneh[382]探索如何将可信执行环境与GPU结合起来进行机器学习推断）。此外，对于可信执行环境（特别是那些在共享微处理器上操作的可信执行环境）来说，完全排除所有类型的侧信道攻击也是一项挑战[391]。<br>&emsp;&emsp;虽然安全环境为运行在其中的所有程序提供保护，但在实践中还必须解决其他问题。例如，通常有必要将运行在该环境中的代码构造为一个不受数据影响的过程，这样它的运行时和内存访问模式就不会显示它正在计算的数据的信息（参见示例[67]）。此外，可测量/证明性通常只证明某个特定的二进制文件正在运行；系统架构师需要提供一种方法来证明该二进制文件具有所需的隐私属性，这可能需要使用来自开源代码的复现过程来重构该二进制文件。<br>&emsp;&emsp;如何在安全环境、云计算资源和客户端设备之间划分联邦学习功能仍然是一个悬而未决的问题。例如，安全环境可以执行安全聚合或混编等关键功能，以限制服务器对原始客户端上传内容的访问，同时此可信计算基础不涉及大多数联合学习逻辑。<br><b>受关注的安全计算问题：</b>虽然安全多方计算和可信执行环境为分布式隐私数据上的任何函数的保密计算问题提供了一般解决方案，但许多优化可以应用到某些特定功能中。下面描述的任务就是这种情况。<br>&emsp;&emsp;<b>安全聚合</b> 安全聚合是指在n个客户端和一个服务器的场景中，允许每个客户端提交一个值（通常是联邦学习设置中的向量或张量），这样服务器只学习客户端值的一个聚合函数，通常是这些值的和。<br>&emsp;&emsp;大量文献对单服务器设置（通过成对加法遮蔽[12，188，73]、通过阈值同态加密[356，193，92]、通过一般安全多方计算[86]）以及在多个非合谋服务器设置[71，29，113]中的安全聚合进行了探讨。也可以使用可信执行环境（如上所述）来实现安全聚合，如[269]。<br>&emsp;&emsp;<b>安全混编</b> 安全混编是指在n个客户端和服务器的场景中，允许每个客户机提交一条或多条消息，这样服务器只从所有客户端学习一个无序的消息集合（multiset），而不需要更多。具体来说，除了消息本身包含的信息之外，服务器无法判断任一条消息的发送者。安全混编可以被视为安全聚合的一个实例，其中值是多集单例，聚合操作为多集求和，尽管通常情况下，为达到安全混编和安全聚合的最佳性能，典型操作制度提供了非常不同的实现<br>&emsp;&emsp;在安全多方计算的背景下，安全混编通常是在混合网络的标题下进行研究[95 251]，也有在可信计算的背景下进行的研究[67]。混合网络中已经存在了以Tor网络[138]的形式进行的大规模部署。<br>&emsp;&emsp;<b>隐私信息检索</b> 隐私信息检索（PIR）是服务器为客户端提供的功能。它使客户机能够从服务器托管的数据库中下载条目，这样服务器就不会获得客户机请求的条目的任何信息。<br>&emsp;&emsp;MPC方法将PIR分为两大类：基于计算的PIR（cPIR），其中一方可以执行协议的整个服务器端[249]；基于信息论的PIR（itPIR），需要其中多个非共谋方执行协议的服务器端[106]。<br>&emsp;&emsp;PIR适用性的主要障碍如下：cPIR具有非常高的计算成本[361]，而非共谋方设置难以在工业场景中有说服力地实现。最近关于PIR的研究结果表明，通过使用基于点阵的密码系统，计算成本显著降低[16，313，17，25，175]。[218]已经证明了在单个服务器上如何利用用户可用的边带信息构建高效通信PIR。最近的相关工作建议利用客户机本地状态来加速PIR。帕特尔等人[319]展示了如何获取后者边带信息，并在单个服务器上实现和验证了一个实用的混合（基于计算和信息论）PIR方案。Corrigan-Gibbs和Kogan[114]在一个离线/在线模型上提出了一种压线性的在线PIR协议，在该模型的离线阶段，客户端从服务器获取信息，这些请求独立于将来要执行的查询。<br>&emsp;&emsp;过去的工作[410]，进一步探索了PIR和隐私共享之间的联系，最近[139]将编码数据联系到PIR中，并且已经建立了高效通信PIR[66]。PIR也在开-关隐私的背景下进行了研究，在这种背景下，客户可以关闭他们的隐私保护以换取更好的实用性或性能[306, 423]。</p>
<h3 id="4-2-2-隐私保护披露"><a href="#4-2-2-隐私保护披露" class="headerlink" title="4.2.2 隐私保护披露"></a>4.2.2 隐私保护披露</h3><p>&emsp;&emsp;量化和限制个人信息披露的最新模型是差异隐私（DP）[147，144，145]，其目的是在发布的模型中引入一定程度的不确定性，以充分掩盖任何个人用户的贡献。差异隐私由隐私损失参数 $(\varepsilon,\delta)$ 量化，其中较小的 $(\varepsilon,\delta)$ 对应于隐私性增强。更正式地说，对于所有 $S \subseteq \operatorname{Range}(A)$，以及所有相邻数据集 $D$ 和 $D’$，如果满足下式，则称随机化算法A是 $(\varepsilon,\delta)$-差异隐私的：</p>
<script type="math/tex; mode=display">
P(A(D) \in S) \leq \operatorname{e\varepsilon } P\left(A\left(D^{\prime}\right) \in S\right)+\delta .(3)</script><p>&emsp;&emsp;在联邦学习的情景中， $D$ 和 $D’$ 对应于分散的数据集，如果 $D’$ 可以通过加上或减去单个客户机（用户）的所有记录而从 $D$ 获得，则这些数据集是相邻的[290]。这种差异隐私的概念被称为用户级差异隐私。它比通常使用的相邻概念强，其中$D$ 和 $D’$ 只相差一条记录[145]，因为通常一个用户可以向数据集贡献多条记录（例如训练集）。<br>&emsp;&emsp;在过去的十年中，用于差异性私有数据分析的广泛技术已经得到发展，特别是在假设集中设置的情况下，在应用实现隐私所需的扰动之前，原始数据由可信方收集。在联邦学习中，通常编排服务器将充当DP机制的可信实现者，确保只将私有化的输出发布给模型工程师或分析师。<br>&emsp;&emsp;然而，在可能的情况下，我们通常希望减少对可信方的需求。近年来，人们考虑了几种减少对数据管理员信任需求的方法。<br><b>本地差异隐私：</b> 通过让每个客户机在与服务器共享数据之前对其数据进行差异隐私转换，可以在不需要可信集中服务器的情况下实现差异隐私。也就是说，我们将公式（3）应用于处理单个用户的本地数据集D的机制A，并且保证对任何可能的其他本地数据集D’保持相同的性质。该模型被称为本地差异隐私模型（LDP）[406，229]。LDP已经被谷歌、苹果和微软有效地用于收集大型用户群中热门项目的统计数据[156，135，136]。它还被Snap[325]用于垃圾邮件分类训练的联邦设置中。这些LDP部署都涉及大量的客户机和表项，在Snap中甚至高达10亿，这与DP的集中实例化形成鲜明对比，而后者可以从更小的数据集中提供高实用性。不幸的是，正如我们将在第4.4.2节中讨论的那样，在保持效用的同时实现LDP是很困难的[229，388]。因此，需要一个介于完全中心和完全本地DP之间的差分隐私模型。这可以通过分布式差异隐私或混合模型来实现，如下所述。<br><b>分布式差异隐私：</b> 为了在不依赖可信的中心服务器的情况下恢复中心DP的一些实用性，可以使用分布式差分隐私模型[146、356、67、105]。在此模型下，客户机首先计算并编码一个最小（特定应用程序）的报告，然后将编码后的报告通过安全计算函数，该功能的输出可供中央服务器访问，从而在服务器能够检查时，此输出已经满足了不同的隐私要求。编码是为了帮助维护客户端的隐私，可以包括如LDP等隐私项。安全计算功能可以有多种体现。它可以是一个MPC协议，一个在TEE上完成的标准计算，甚至是两者的结合。每种选择都有不同的假设和威胁模型。<br>&emsp;&emsp;必须指出的是，分布式差异隐私和本地差异隐私从多个角度得到了不同的保证：虽然分布式DP框架可以为与LDP相同级别的差异隐私生成更准确的统计数据，但它依赖于不同的设置，并且通常会做出更有力的假设，例如作为对MPC协议的访问。下面，我们概述了两种可能的分布式差异隐私方法，依赖于安全聚合和安全混编，尽管我们强调还有许多其他方法可以使用。<br>&emsp;&emsp;通过安全聚合实现分布式DP。在第4.2.1节中讨论过，在FL中，安全聚合是实现分布式DP的一种的工具。安全聚合可用于确保中心服务器获得聚合结果，同时确保单个设备和参与者的中间参数不会透露给中心服务器。为了进一步确保聚合结果不会向服务器显示附加信息，我们可以使用本地差异隐私（例如，中等ε级别）。例如，每个设备可以在安全聚合之前扰动其自身的模型参数，以实现本地差异隐私。通过正确设计噪声，我们可以确保聚合结果中的噪声与可信服务器（例如，低ε/高隐私级别）集中添加的噪声匹配[12，330，181，356，188]。<br>&emsp;&emsp;通过安全混编实现分布DP。另一个分布式差异隐私模型是混编模型，它由最近引入的混编分析编码（ESA）框架[67]启动（如图3所示）。在这个框架的最简单版本中，每个客户端在其数据上运行一个LDP协议（例如，具有中等级的ε），并将其输出提供给一个安全的混编器。混编器随机排列报告表项，并将混编后报告的集合（没有任何标识信息）发送到服务器进行最终分析。直观地说，此安全计算功能的介入使得服务器更难了解参与者的任何信息，并支持差异隐私分析（例如，低ε/高隐私级别）。在更一般的多消息混编框架中，每个用户可以向混编器发送多个消息。混编器独立于服务器并专门用于混编，可以直接作为一个受信任的实体实现，也可以通过上面讨论的更复杂的加密原语来实现。<br>&emsp;&emsp;Bittau等人 [67]提议采用Prochlo系统作为实施ESA框架的一种方式。该系统采用整体隐私方法，考虑到安全计算方面（使用TEEs解决）、隐私披露方面（通过差异隐私解决）和验证方面（使用安全环境弱化认证功能）。<br>&emsp;&emsp;更普遍地说，差异隐私的混编模型可以使用更广泛的局部随机者类，甚至可以自适应地选择这些局部随机者[157]。这可以使差异私有协议的错误远远小于本地模型中可能的错误，同时依赖于弱于中心模型的信任假设[105、157、43、179、178]。<br><b>混合差分隐私：</b> 另一个可行的方法是混合差分隐私[39]，它通过根据用户的信任模型偏好（例如对管理员信任与否）来划分用户，从而组合多个信任模型。在混合模型之前，有两种选择。第一种是使用最不可信的模型，它通常提供最低的效用，并且保守地将其统一应用于整个用户群。第二种方法是使用最信任的模型，它通常提供最高的实用程序，但只应用于最信任管理者的用户。通过允许多个模型共存，混合模型机制可以从给定的用户基础获得更多的效用，与纯本地或中心DP机制相比。例如，[39]描述了一个系统，其中大多数用户在本地隐私模型中贡献他们的数据，而一小部分用户选择在可信的管理员模型中贡献他们的数据。这使得能够设计一种机制，在某些情况下，该机制的性能优于应用于所有用户的保守的本地机制以及仅应用于小部分选择参加用户的可信管理员机制。这种结构可以直接应用于联邦学习环境中；然而，组合信任模型或计算模型的一般概念也可能激发类似新的联邦学习方法。<br><img src="/2022/09/06/advances-and-open-problems-in-federated-learning-yue-du-bi-ji/7.png" alt="图3 包含四个参与者的混编分析编码（ESA）框架"></p>
<h3 id="4-2-3-可验证性"><a href="#4-2-3-可验证性" class="headerlink" title="4.2.3 可验证性"></a>4.2.3 可验证性</h3><p>&emsp;&emsp;与上述隐私技术正交的一个重要概念是验证性。一般来说，可验证的计算将使一方能够向另一方证明其已忠实地对其数据执行了所需的行为，而不会损害数据的潜在保密性。可验证计算的概念可追溯到Babai等人 [40]，并且已经在文献中的不同术语下进行了研究：检验[40]、认证计算[295]、委托计算[185]以及可验证性计算[173]。<br>&emsp;&emsp;在FL的背景下，验证能力可用于两个目的。首先，它将使服务器能够向客户机证明它忠实地执行了预期的行为（例如，聚合输入、显示输入消息或添加用于差异隐私的噪声）。其次，它将使客户端能够向服务器证明其输入和行为遵循协议规范（例如，输入属于某个范围，或者数据是正确生成的密文）。<br>&emsp;&emsp;多种技术可用于提供验证：零知识证明（ZKPs）、可信执行环境（TEEs）或远程认证。其中ZKPs提供了基于数学硬度的形式化密码安全保证，而其他技术则依赖于可信硬件的安全性假设。<br><b>零知识证明（ZKPs）：</b> 零知识证明是一种密码原语，它使一方（称为证明者）能够向另一方（称为验证者）声明证明，而验证者依赖于见证者已知的秘密信息，而不向验证者泄露这些信息。20世纪80年代末，Goldwasser等人引入了零知识（ZK）的概念[184]。它为隐私数据的可验证性问题提供了解决方案。虽然ZK构建方面存在大量的工作，但第一个将ZKP和通用功能的可验证计算引入实用领域的是Parnoetal的工作 [317]，它介绍了第一个针对简洁ZK的优化构建和实现。现在，ZKP协议可以实现100字节的证明大小和毫秒级的验证，无论被证明语句的大小。<br>&emsp;&emsp;ZKP有三个显著的属性：完整性（如果陈述是真的，证明者和验证者遵循协议，验证者将接受证明）、可靠性（如果陈述是假的，验证者遵循协议，验证者将拒绝证明）和零知识（如果陈述是真的，证明者遵循协议协议中，验证者只会了解到声明是真实的，不会从交互中了解到任何隐私信息）。<br>&emsp;&emsp;除了这些共性之外，在证明支持的语言、设置要求、证明和验证计算效率、交互性、简洁性和潜在的硬度假设方面，还有不同类型的零知识结构。有许多ZK结构支持特定的语句类，Schnorr证明[349]和Sigma协议[128]就是这样广泛使用的协议的例子。虽然此类协议在特定设置中有许多用途，但是能够支持任何功能的通用ZK系统提供了一个更广泛适用的工具（包括在FL的上下文中），因此我们将在接下来的讨论中重点讨论此类构造。<br>&emsp;&emsp;不同构造之间的一个主要区别是需要可信设置。一些ZKP依赖于一个公共引用字符串（common reference string，CRS），该字符串使用应该保持y隐私性来计算，以保证证明的可靠性。这种CRS的计算被称为可信设置。虽然这种要求对于这样的系统是不利的，但是现有的能够实现最简洁的证明和验证者有效性的ZKP，都需要可信的设置。<br>&emsp;&emsp;影响不同情况下适用性的另一个重要特性是，生成证明是否需要证明者和验证者之间的交互，这里我们区分非交互零知识证明（NIZK），该证明使验证者能够向验证者发送一条消息，且无需进一步通信。通常，我们可以将交互式的证明转换为非交互式的证明，从而对理想哈希函数的功能做出更有力的假设（即哈希函数生成结果完全随机）。<br>&emsp;&emsp;此外，对ZKP系统的有效性有不同的测量，如证明的长度和证明者、验证者的计算复杂度。从评估执行时间来说，理想的证明者的复杂性应该是线性的，但许多现有的ZKPS引入额外的（有时产生重大影响）证明者，产生更多开销。最有效的验证者复杂度要求在估计的功能的输入的大小上至少是线性的，并且在FL服务器的工作场景下的设置中，这个输入规模将是巨大的。<br>&emsp;&emsp;简洁的非交互式零知识证明（SNARKs）[65]是一种ZKP类型，它提供恒定的证明和验证大小，与输入大小成线性关系。这些有吸引力的性能是以更强的假设为代价的，而这一假设在大多数现有的方案中都是固有而可信的。大多数现有SNARK结构利用二次算术程序〔174, 317, 118〕，现在可在开源库中使用，如LiSnAgAg[[ 5 ] ]，并部署在加密货币场景中，如Zcash（57）。值得注意的是，SNARK系统通常需要证明者部分的开销；特别是，证明者的计算需要与被证明语句的大小上满足超线性关系。最近，谢等人〔418〕提出了一种ZKP系统，该系统能够实现线性证明者的复杂度，但增加了证明空间开销和验证时间。<br>&emsp;&emsp;如果我们放松对构造的简洁性或非交互性的要求，就会有大量广泛的效率权衡的构造实现，避免可信设置要求，并使用更标准的加密假设[84、397、23、58]。<br>&emsp;&emsp;近年来，越来越多的实际应用使用非交互式零知识证明，主要是由区块链驱动的。在FL中有效地使用交互式ZKP系统和NIZKs仍然是一个具有挑战性的开放性问题。在这种设置中，NIZKs可以向服务器证明客户机的输入。在验证者是客户端的情况下，创建一个可信的语句来验证将是一个挑战，因为它涉及到来自其他客户的输入。在这种情况下，最近的工作[76]使我们能够处理多个验证者共享陈述语句的情况。<br><b>可信执行环境和远程认证：</b> 我们在第4.2.1节中讨论了TEEs，但这部分的重点是TEEs提供可验证计算的可能。实际上，TEEs能够证明和验证在其环境中运行的代码（二进制）。特别是，当验证者知道（或可以复制）哪个二进制文件应该在安全环境中运行时，TEEs将能够提供完整性（除了输入之外，代码执行不会受到影响）和可证明性（TEE可以证明特定二进制文件正在执行，并且什么是启动状态）[373,385]。一般来说，远程认证允许验证者安全地测量远程硬件平台的内部状态，并可用于建立静态或动态信任源。虽然TEEs支持基于硬件的远程认证，但文献中提出了基于软件的远程认证[351]和混合远程认证设计[152,238]，并能够权衡硬件要求与可验证性。<br>&emsp;&emsp;在联邦学习环境中，TEEs和远程认证对于客户端能够有效地验证服务器上运行的关键功能可能特别有用。例如，安全聚合或混编可以在TEEs中运行，并为它们的输出提供不同的隐私保证。因此，服务器随后对差异隐私数据应用的后处理逻辑可以在服务器上运行，并且对客户端保持不敏感。注意，这样的系统设计要求客户端知道并信任要在安全环境中应用的关键函数的确切代码（二进制）。此外，远程证明可以使服务器证明FL计算中涉及的客户端的特定要求，例如无泄漏、不变性和不可中断性（关于远程证明的最低要求的详细列表，请参阅[166]。</p>
<h2 id="4-3-防范外部恶意参与者"><a href="#4-3-防范外部恶意参与者" class="headerlink" title="4.3 防范外部恶意参与者"></a>4.3 防范外部恶意参与者</h2><p>&emsp;&emsp;在本节中，我们假设可信服务器的存在，并讨论实现对外部恶意参与者（例如敌对客户、敌对分析者、消耗学习模型的敌对设备或其任意组合）的严格隐私保证的各种挑战和公开问题。<br>&emsp;&emsp;如表7所述，恶意客户端可以在其参与的轮次中检查从服务器接收的所有消息（包括模型迭代），恶意分析师可以使用不同的超参数检查来自多个训练运行的模型迭代序列，在跨设备FL中，恶意设备可以通过白盒或黑盒访问最终模型。因此，要提供严格的保护以防范外部对手，首先必须考虑从中间迭代和最终模型中可以学到什么。</p>
<h3 id="4-3-1-评估迭代轮次和最终模型"><a href="#4-3-1-评估迭代轮次和最终模型" class="headerlink" title="4.3.1 评估迭代轮次和最终模型"></a>4.3.1 评估迭代轮次和最终模型</h3><p>&emsp;&emsp;为了更好地理解从中间迭代或最终模型中可以学到什么，我们建议量化联邦学习模型对特定攻击的易感性。在联邦学习环境中，这是一个特别有趣的问题。一方面，敌方从服务器接收到对模型的直接访问，拓宽了攻击面。另一方面，服务器确定对手将在训练过程的哪个特定阶段获得对模型的访问，并在每个阶段控制对手对模型的影响。<br>&emsp;&emsp;对于经典的（非联邦的）计算模型，了解模型对攻击的敏感性是一个活跃而富有挑战性的研究领域[167,357,91,293]。最常用的易于攻击量化模型方法是使用代理（评估）数据集模拟对模型的攻击，该数据集与实际中预期的数据集类似。如果代理数据集确实与最终用户数据相似，那么这就说明了模型的预期攻击敏感性。更安全的方法是确定模型攻击敏感性的最坏情况上限。 [425]在理论上给出了可接近的界限，尽管这一上界在实际模型中通常松散、空洞而无法达到。经验方法也许能够提供更严格的界限，但对于许多类型的攻击和模型，这一努力可能是棘手的。这一领域中一个有趣的新兴研究领域考察了理论条件（关于评估模型和攻击），即在何种条件下，通过模拟失败隐私侵犯的失败攻击，就意味着没有更强的攻击能够成功完成这样的任务[134]。然而，这一领域仍处于初级阶段，需要做更多的工作来更好地理解评估（通过模拟攻击）的基本要求。<br>&emsp;&emsp;联邦学习框架不仅为攻击提供了独特的设置，而且也为攻击数量和防御提供了独特的设置。具体来说，由于服务器可以控制每个用户在培训过程中何时可以访问和影响模型，因此可以设计新的可处理方法来量化模型的平均情况或最坏情况下的攻击敏感性。这样的方法将使得能够开发新的自适应防御，它可以应用于即时运行过程中，从而在最大化效用的前提下，面对不可抗拒的敌方时取得优先权。</p>
<h3 id="4-3-2-考虑中心差异隐私的模型训练"><a href="#4-3-2-考虑中心差异隐私的模型训练" class="headerlink" title="4.3.2 考虑中心差异隐私的模型训练"></a>4.3.2 考虑中心差异隐私的模型训练</h3><p>&emsp;&emsp;为了限制或消除从迭代（和/或最终模型）中可以了解到的关于用户的信息，可以在FL的迭代训练过程中使用用户级差异隐私[72,90,288,62]。使用这种技术，服务器通过剪裁单次更新的l2范数结果，聚合被剪裁的更新，然后将高斯噪声添加到聚合结果中。这样可以确保迭代不会过拟合任何单个用户的更新。为了跨回合跟踪总体隐私预测，可以使用更高级的组合理论[148,221]或在[72, 97,299,405]中提出的分析动量统计方法。动量统计方法特别适用于均匀亚采样高斯机制。<br>&emsp;&emsp;在跨设备FL中，训练示例的数量在不同设备之间可能有很大的差异。因此，与中心模型[24]中关于用户级DP的最新工作类似，研究如何自适应地限制用户的贡献并剪裁模型参数仍然是一个有趣的研究方向[381,324]。更广泛地说，与记录级DP不同，在记录级DP中，各种规范学习和估计任务的准确性和隐私性之间的基本权衡关系很好理解，用户级DP从根本上来说就不那么容易理解（尤其是当贡献的数量在用户之间变化很大，并且没有先验的严格限制时）。因此，需要做更多的工作，以更好地理解在这种新出现的DP环境中的基本权衡。<br>&emsp;&emsp;除上述内容外，还必须区分在训练期间可能看到（某些）中间迭代的恶意客户端和只能看到最终模型的恶意分析师（或部署设备）。尽管中心DP提供了对两种威胁模型的保护，但仔细的理论分析可以发现，对于上述高斯机制（或任何其他差异隐私机制）的具体实现，我们可能会得到这两种威胁模型的不同隐私参数。当然，对于恶意分析师，我们应该获得比恶意客户更强的差异隐私保证（因为恶意客户可能比恶意分析师获得更多的信息）。费尔德曼等人最近对这种“通过迭代进行隐私放大”的设置进行了凸优化问题研究[163]。然而，还不清楚[163]中的结果是否可以被迁移到非凸设置。<br>&emsp;&emsp;非均匀设备采样隐私放大程序 跨设备FL的基本更新步骤在可用客户端的子集上进行。当所选择的用户子集从用户的基本群体中均匀抽样时，可以使用在[405]中开发的动量统计方法来分析该抽样过程的隐私增益。然而，这样的抽样程序在实践中几乎是不可能的。这是因为（a）服务提供商可能不知道设备的总体情况，并且（b）可用设备的特定子集可能会随时间而显著变化。因此，量化跨设备FL中的隐私放大是一个有趣的开放问题。<br>&emsp;&emsp;随机源（改编自[288]） 大多数计算设备只能访问很少的熵源，而且它们的速率往往很低（硬件中断、车载传感器）。使用熵为加密安全的伪随机数生成器（PRNG）种子并根据需要使用PRNG的输出是标准要求，这在理论上也是合理的。基于标准密码原语的鲁棒高效PRNG存在，在现代CPU上具有每秒千兆字节的输出速率，并且要求种子短于128比特[343 ]。<br>&emsp;&emsp;只要识别器在计算上有界，访问PRNG的随机算法A的输出分布与访问真实熵源的随机算法A的输出分布是不可区分的。相比之下，无论对手有多强大，差异隐私的保障对任何对手都是有效的。因此，几乎所有差异隐私的实现都只满足[298]引入的计算差异隐私的（变体）。从积极的方面来说，一个计算能力有限的对手无法分辨出两者的区别，这使得我们避免在这一点上过于局限。<br>&emsp;&emsp;一个训练过程可能有多个非确定性来源（例如，退出层或生成模型的输入），但只有那些反映在隐私目次中的来源必须来自加密安全的PRNG。特别是，设备采样过程和加高斯噪声必须从加密安全的PRNG中提取，以满足计算差异隐私。<br>&emsp;&emsp;评估差异隐私实现 众所周知，隐私和安全协议很难正确实现（例如，[296, 192]用于区分隐私）。什么技术可以用来测试FL实现的正确性？由于这些技术通常由那些可能选择不使用开源代码的组织部署，黑盒测试的可能性有多大？一些著作[137，275]开始在差异隐私的背景下探索这一领域，但仍有许多悬而未决的问题。</p>
<h3 id="4-3-3-迭代隐蔽"><a href="#4-3-3-迭代隐蔽" class="headerlink" title="4.3.3 迭代隐蔽"></a>4.3.3 迭代隐蔽</h3><p>&emsp;&emsp;在典型的联邦学习系统中，模型迭代（即每轮训练后模型的更新版本）被假定为对系统中的多个参与者可见，包括选择参与该轮的服务器和客户端。但是，可以使用第4.2节中的工具来对这些参与者隐藏迭代模型。<br>&emsp;&emsp;为了向客户端隐藏迭代，每个客户端都可以在提供保密特性的TEE中运行其联邦学习的本地部分（参见第4.2.1节）。服务器将验证预期的联邦学习代码是否在TEE中运行（依赖于TEE的认证和完整性功能），然后将加密的模型迭代结果传输到设备，以便它只能在TEE中解密。最后，模型更新将在返回到服务器之前在TEE内部加密，使用仅在安全环境内部和服务器上已知的密钥。不幸的是，TEE通常不适用于客户端，尤其是当这些客户端是智能手机等终端用户设备时。此外，即使存在TEE，它们也可能不够强大，无法支持训练计算，为了保护模型迭代，必须在TEE内部进行训练计算，并且可能需要高计算成本和/或大量的RAM。尽管TEE的能力可能会随着时间的推移而提高，以及诸如在[382]中所述的技术可以通过将计算的部分转移到TEE之外而减少对TEE的要求，同时保持计算的整体的证明、完整性和机密性需求。<br>&emsp;&emsp;在MPC模型下也可以实现类似的保护[302，14]。例如，服务器可以在将迭代器的模型参数发送到客户端之前，使用只有服务器知道的密钥在同态加密方案下对其进行加密。然后，客户端可以使用密码系统的同态属性计算加密的模型更新，而无需解密模型参数。然后，可以将加密的模型更新返回到服务器进行聚合。这里的一个关键挑战是在解密之前在服务器上强制聚合，否则服务器可能会学习到客户端的模型更新。另一个具有挑战性的开放性问题是提高性能，因为即使是最先进的系统也需要相当可观的计算资源才能在深层神经网络中完成一轮训练。这方面的进展既可以通过算法的进步，也可以通过为MPC开发更高效的硬件加速器来实现[337]。<br>&emsp;&emsp;向服务器隐藏模型迭代也会产生额外的挑战。在TEE模型下，联邦学习的服务器部分可以在TEE中运行，所有各方（即客户端和分析师）都验证服务器TEE仅在满足适当的培训标准后才发布最终模型。在MPC模型下，加密密钥可以保护模型迭代，密钥由分析师持有，在客户端之间共享，或由可信的第三方持有；在这种设置中，密钥持有者将被要求参与模型参数的解密，从而可以确保此过程只发生一次。</p>
<h3 id="4-3-4-对不断变化数据的重复分析"><a href="#4-3-4-对不断变化数据的重复分析" class="headerlink" title="4.3.4 对不断变化数据的重复分析"></a>4.3.4 对不断变化数据的重复分析</h3><p>&emsp;&emsp;对于联邦学习的许多应用，分析师希望分析流式数据，并且还必须提供动态更新的学习模型，这些模型（1）对目前接受到的数据结果正确，以及（2）准确预测未来将要到达的数据。在没有隐私问题的情况下，分析师可以在新数据到达后简单地重新训练所学模型，以确保在任何时候都能达到最大的精度。然而，隐私保证等级随着关于相同数据的附加信息的发布而降低[147, 148]，这些附加信息引起更新的频率必须降低以保持整体分析的隐私性和准确性。<br>&emsp;&emsp;动态数据库和时间序列数据的差异隐私[125, 124, 89]研究的最新进展都假设存在可信的管理员，他们可以在上线时看到原始数据，并发布动态更新的统计数据。一个悬而未决的问题是，如何将这些算法技术扩展到联邦设置，以实现对时间序列数据或其他动态演变数据库的私有联邦学习。<br>&emsp;&emsp;具体开放性问题包括：</p>
<ol>
<li>分析师应如何在有新数据的情况下更新私有FL模型？或者，在数据集 $D$ 上使用FL私下学习的模型扩展到数据集 $D'$ （在给定的相似性度量中保证与D相似）的程度如何？由于FL已经出现在在线到达的样本上，并且没有过拟合它所用来训练的数据，因此这种模型很可能仍然会在新的数据集 $D'$ 上表现良好。这也与第5节探讨的鲁棒性问题有关。</li>
<li>解决隐私构成问题的一种方法是生成可以独立使用，而不会造成额外隐私损失的合成数据[145，9]。这来自于差异隐私的后处理保证[147]。奥根斯坦等人在[32]中探索证明了以联邦方式生成合成数据。在动态数据设置中，合成数据可以重复使用，直到它相对于新数据变得“过时”，并且必须更新。即使在以联邦方式生成数据之后，它也必须以私有和联邦方式进行更新。</li>
<li>之前关于动态数据库差异隐私的工作[124]或不公开地检测时间序列数据变化[125, 89]中的具体方法是否可以扩展到联邦设置？</li>
<li>如何在联邦模型中首先查询时间序列数据？在设计上，同一个用户不会被多次定期查询更新的数据点，因此很难在评估过程中内收集到真实的个人数据随时间变化的估计值。在这里，可以使用时间序列数据统计抽样的常用工具，但必须与隐私工具和联合工具一起使用。其他方法包括重新格式化查询，以便评估查询中的每个子查询都可以在设备上完全应答。</li>
</ol>

<h3 id="4-3-5-防止模型被盗或误用"><a href="#4-3-5-防止模型被盗或误用" class="headerlink" title="4.3.5 防止模型被盗或误用"></a>4.3.5 防止模型被盗或误用</h3><p>&emsp;&emsp;在某些情况下，开发ML模型的参与者或组织可能有动机来限制检查、误用或窃取模型的能力。例如，限制对模型参数的访问可能会使对手更难搜索漏洞，例如产生意外模型输出的输入。<br>&emsp;&emsp;如第4.3.3节所述，在推断下保护已部署的模型与在训练期间向客户端隐藏模型迭代的挑战密切相关。同样，可以使用TEEs和MPC方法。在TEE模型下，模型参数只能由设备上的TEE访问，如第4.3.3节所述；主要区别在于，所需的计算现在是推断而不是训练。<br>&emsp;&emsp;如果不放弃设备推理所提供的优点，就很难使MPC策略适应这个用例：如果用户数据、模型参数和推理结果原来都是在设备上进行的，则不清楚还有哪些其他方参与了多方计算。例如，朴素地试图使用同态加密将要求解密密钥位于要使用推断功能的设备上，从而首先破坏加密的价值。要求分析师参与的解决方案（例如，持有加密密钥或模型参数本身）意味着对最终用户的额外推理延迟、带宽成本和连接要求（例如，对于处于飞行模式的设备，推理将不再可用）。<br>&emsp;&emsp;必须注意的是，即使模型参数本身被成功隐藏；研究表明，在许多情况下，它们可以由对手重建，而对手只需访问基于这些参数的推理/预测API[384]。对于驻留在数百万或数十亿最终用户设备上的模型，需要采取哪些附加保护措施来防止此类问题，这是一个悬而未决的问题。</p>
<h2 id="4-4-针对敌意服务器的保护"><a href="#4-4-针对敌意服务器的保护" class="headerlink" title="4.4 针对敌意服务器的保护"></a>4.4 针对敌意服务器的保护</h2><p>&emsp;&emsp;在前面的章节中，我们假设存在一个可以编排整个训练过程的受信服务器。本节，我们讨论一种针对一个有敌意服务器的更合适的场景。特别是，我们首先调查这种环境和现有工作的挑战，然后继续描述未解决的问题以及如何使用第4.2节中讨论的技术来应对这些挑战。</p>
<h3 id="4-4-1-信道，女巫攻击，选取"><a href="#4-4-1-信道，女巫攻击，选取" class="headerlink" title="4.4.1 信道，女巫攻击，选取"></a>4.4.1 信道，女巫攻击，选取</h3><p>&emsp;&emsp;在跨设备FL设置中，我们拥有一台具有大量计算资源的服务器和大量客户端，这些客户端（i）仅能与该服务器通信（如在星形网络拓扑中），并且（ii）连通性和带宽可能受到限制。 在执行给定的信任模型时，这提出了非常具体的要求。 特别是，客户端没有独立于服务器的清晰方法来在客户端之间建立安全通道。 如Reyzin等人所示。 [336]对于实际设置，在需要客户端之间专用通道的情况下，需要假设服务器在密钥分发阶段（如[73]中所做的）是诚实的（或至少是半诚实的）行为。 这包括基于MPC技术的密码解决方案。 对此假设的替代方法是将额外的参与方或公共公告板（例如，参见[341]）合并到客户端已知且可以信任的不与服务器串通的模型中。<br>&emsp;&emsp;除了信任服务器以促进专用通信渠道之外，跨设备FL的参与者还必须信任服务器以公平，诚实的方式形成客户群。控制服务器的主动恶意攻击者可能会模拟大量伪造的客户端设备（“ Sybil攻击” [140]），或者可能会从可用设备池中优先选择以前受到破坏的设备。无论采用哪种方式，对手都可以在联邦学习的一轮中控制更多的参与者，这要比简单地从总体中的对手设备的基本速率所预期的要多。这将使打破MPC中至少有一部分设备是诚实的普遍假设变得容易得多，从而破坏了协议的安全性。即使协议本身的安全性保持不变（例如，如果其安全性植根于不同的信任源，例如安全的隔离区），也可能存在以下风险：如果已知大量敌对客户端的模型更新，或由对手控制该更新，则可能会破坏其余客户的更新的隐私。注意，这些顾虑也可以适用于TEE。例如，基于TEE的混洗器也可能遭受Sybil攻击；如果将单个诚实用户的输入与来自假用户的已知输入进行混洗，那么对手将很容易在混洗输出中识别出诚实用户的价值。<br>&emsp;&emsp;请注意，在某些情况下，有可能在一轮客户端之间建立证明它们都在执行正确的协议，例如，如果客户端设备上有安全的隔离区，并且客户端之间可以进行远程证明。 在这些情况下，有可能为该回合中所有诚实的参与者建立隐私（例如，通过证明已正确遵循安全的多方计算协议，秘密且正确地添加了分布式差异隐私贡献等），即使 模型更新本身是对手已知的或由对手控制的。</p>
<h3 id="4-4-2-现有方案的缺陷"><a href="#4-4-2-现有方案的缺陷" class="headerlink" title="4.4.2 现有方案的缺陷"></a>4.4.2 现有方案的缺陷</h3><p>&emsp;&emsp;鉴于FL的目标是服务器在客户数据中构建人口级别模式的模型，自然而然的隐私目标是量化并可证明地限制服务器重建单个客户输入数据的能力。这涉及形式上的定义（a）作为FL执行结果显示给服务器的客户数据的视图是什么，以及（b）这种视图的隐私泄漏是什么。在FL中，我们特别希望保证服务器可以汇总来自客户端的报告，同时以某种方式掩盖每个单独客户端的贡献。如第4.2.2节所述，这可以通过多种方式完成，通常使用一些差异性隐私的概念。这种方法有很多种，每种方法都有其自身的弱点，尤其是在FL中。例如，如已经讨论的，中央DP遭受对可信任中央服务器的访问的需求。这引出了第4.2.2节中讨论的其他有前途的私人披露方法。在这里，我们概述了这些方法的一些缺点。<br><b>本地差分隐私（LDP）</b><br>&emsp;&emsp;如前所述，LDP通过让每个客户端在将报告发送到中央服务器之前对其报告执行不同的私有转换，从而消除了对受信任的中央服务器的需求。 LDP假定用户的隐私完全来自该用户自己的随机性；因此，用户的隐私保证独立于所有其他用户添加的额外随机性。尽管LDP协议有效地加强了隐私并具有理论上的依据[156，135，136]，但许多结果表明，在保持实用性的同时实现局部差分隐私尤其具有挑战性，特别是在高维数据设置中[229，388， 219，51，220，424，142，111]。造成这种困难的部分原因是，引入的随机噪声的幅度必须与数据中信号的幅度相当，这可能需要合并客户端之间的报告。因此，要获得与中央设置相当的LDP效用，就需要相对较大的用户群或较大的参数选择。<br><b>混合差分隐私（HDP）</b><br>&emsp;&emsp;差异隐私的混合模型可以通过根据用户的信任首选项对用户进行划分来帮助减少所需用户群的大小，但是它不能为用户本地添加的噪声提供隐私放大功能。 而且，尚不清楚哪个应用领域和算法可以最佳地利用混合信任模型数据[39]。 混合模型的当前工作通常假设，无论用户信任偏好如何，其数据都来自相同的分布[39、141、53]。 放宽此假设对于FL尤其重要，因为信任首选项和实际用户数据之间的关系可能并不重要。<br><b>随机混合模型</b><br>&emsp;&emsp;随机混合模型可从用户的本地噪声中放大隐私，尽管它有两个缺点。首先是可信中介的要求；如果用户已经不信任管理员，那么他们不太可能会信任由管理员批准或创建的中介人（尽管TEE可能有助于弥合这一差距）。 Prochlo框架[67]（据我们所知）是唯一现有的实例。第二个缺点是随机混合模型的差异性隐私保证与参与计算的对手用户数量成比例地降低[43]。由于用户或管理员不知道该数字，因此将不确定性引入了用户所接收的真实隐私级别。在联合学习的情况下，这种风险尤其重要，因为用户（可能是对抗性的）是计算管道中的关键组成部分。当用户在本地添加自己的噪声时，安全的多方计算除了会给每个用户增加大量的计算和通信开销外，也无法解决此风险。<br><b>安全集聚协议</b><br>&emsp;&emsp;[73]中的安全聚合协议在聚合客户报告时具有强大的隐私保证。 此外，该协议是针对联合学习的设置而量身定制的。 例如，它对于客户端在执行过程中退出（跨设备FL的一个共同特征）是健壮的，并且可以扩展到大量参与者和更长的的向量。 但是，这种方法有几个局限性：（a）假定服务器为半诚实的服务器（仅在私钥基础结构阶段），（b）允许服务器查看全方位的聚合（可能仍会泄漏信息）， （c）稀疏向量聚合效率不高；（d）缺乏强制客户输入格式正确的能力。 如何构建一个有效，强大的安全聚合协议来解决所有这些挑战是一个悬而未决的问题。</p>
<h3 id="4-4-3-分布式差分隐私训练"><a href="#4-4-3-分布式差分隐私训练" class="headerlink" title="4.4.3 分布式差分隐私训练"></a>4.4.3 分布式差分隐私训练</h3><p>&emsp;&emsp;如果没有受信任的服务器，则可以使用分布式差异隐私（在第4.2.2节中介绍）来保护参与者的隐私。<br><b>分布式差分隐私下的通信，隐私和准确性权衡</b><br>&emsp;&emsp;我们指出，在分布式差异隐私中，三个性能指标是普遍关注的：准确性，隐私和通信，并且一个重要的目标是确定这些参数之间可能的折衷。 我们注意到，在没有隐私要求的情况下，关于分布估计（例如[376]）和通信复杂性的文献已经很好地研究了通信和准确性之间的权衡（有关教科书的参考，请参见[248]） 。 另一方面，在假设所有用户数据都由一个实体保存并且因此不需要进行通信的集中式设置中，从[147，146]的基础性工作开始，就已经在中央DP中广泛研究了准确性和隐私之间的权衡取舍。<br><b>安全混合的折衷选择</b><br>&emsp;&emsp;最近在混合模型中研究了这些折衷，以解决聚合的两个基本任务（目标是计算用户输入的总和）和频率估算（输入属于离散集，目标是 估算拥有给定元素的用户数）。 有关这两个问题的最新发展情况，请参见表9和表10。 两个值得注意的开放问题是（i）在改组模型中研究纯差异隐私，以及（ii）在多消息设置中确定变量选择的最佳的私密性，准确性和通信折衷情况（在最近[178]提到的单消息情况下紧紧贴合的下限）<br><b>安全集聚协议的折衷选择</b><br>&emsp;&emsp;研究以下类似问题以进行安全聚合将非常有意思。假设一轮有 $n$ 个用户参与的联邦学习，同时假设每个用户 $i$ 持有数据 $x_i$。用户 $i$ 对 $x_i$ 采用算法 $A(.)$ 来获得 $y_i = A(x_i)$；在这里，$A(.)$ 可以被视为压缩方案和私有化方案。通过使用安全集聚协议作为黑盒，服务提供商可以观察 $\overline y = \Sigma_i A(x_i)$ 同时可以通过计算 $\hat{\overline x} = g(\overline y)$ 来使用 $\overline{y}$ 估计 $x_i$ 的真实总值 $\overline{x}$。理想情况下，我们希望以最小化x估计误差的方式设计 $A(.),g(.)$；形式上，我们想解决最优化问题 $min{g,A} ||g(\Sigma_i A(x_i)) - \Sigma_i x_i||$，此处 $||.||$ 可以是 $l_1$ 范数或者 $l_2$ 范数。当然，在不对 $g(.)$ 和 $A(.)$ 施加任何约束的情况下，我们始终可以选择它们作为恒等函数，并获得0错误。然而，$A(.)$ 需要满足两个约束：（1） $A(.)$ 应该输出B位（可以认为是每个用户的通信成本）,同时（2） $\overline y = \Sigma_i A(x_i)$ 应当是 $\overline x = \Sigma_i x_i$ 的 $(\varepsilon, \delta)-DP$ 版本。因此，关注的基本问题是确定在聚合时也能实现DP且同时满足固定通信预算的最优算法 $A$。换个角度看问题，对于固定的 $n,B,\varepsilon,\delta$，我们希望实现的最小的 $l_1$ 或 $l_2 $ 误差是多少？我们注意到Agarwal等人的最新工作[13]提供了一种基于均匀量化和二项式噪声相加的候选算法A。但是，尚不清楚所提出的方法是否是在这种情况下的最佳方法。因此，在上述约束下得出 $l_1$ 或 $l_2$ 误差的下限是非常重要的。<br><b>隐私账户？隐私登录？</b><br>&emsp;&emsp;在DP的中心模型中，经常使用欠采样的高斯机制来实现DP，并且使用==矩值会计==方法在FL的各轮之间紧密跟踪隐私预算（请参见第4.3节中的讨论）。 但是，在DP的分布式设置中，由于与安全混合和安全聚合的实际实现相关的有限精度问题，因此无法使用高斯机制。 因此，该空间中的现有工作已恢复为具有离散性质的噪声分布（例如，添加伯努利噪声或二项式噪声）。 尽管这样的分布有助于解决由安全混合/聚合的基础实现所施加的有限精度约束，但它们自然不会从==矩数会计==方法中受益。 因此，一个重要的开放问题是推导针对这些分布式DP考虑的离散（和有限支持）噪声分布量身定制的==隐私权计费==技术。<br><b>处理用户掉线问题</b><br>&emsp;&emsp;上面的分布式DP模型假设参与的客户端在一轮中保持与服务器的连接。 但是，当大规模运行时，某些客户端会由于网络连接断开或暂时不可用而退出。 这要求分布式噪声生成机制要针对此类遗漏具有鲁棒性，并且还要影响扩张联邦学习的规模和对大量参与客户端的分析。<br>就健壮的分布式噪声而言，客户端退出可能会导致添加的噪声太少，无法满足差分隐私epsilon目标。 保守的方法是增加每个客户端的噪音，以便即使使用最少数量的客户端才能满足差分隐私 $\varepsilon$ 目标，以使服务器完成安全聚合并计算总和。 但是，当更多的客户报告时，这会导致过多的噪音，这引发了一个问题，即是否有可能提供更有效的解决方案。<br>&emsp;&emsp;在扩展方面，增加参与安全聚合回合的客户端数量时，丢失的客户端数量将成为瓶颈。 同时收集足够的客户也可能是一个挑战。 为此，可以对协议进行结构化，以便客户端可以在长时间运行的聚合回合过程中多次连接，以完成其任务。 更普遍的，还有在文献中尚未系统地解决当客户可能间歇性可用时的大规模操作的问题。<br><b>新的可信赖的模型</b><br>&emsp;&emsp;联合学习框架利用联合学习的独特计算模型，并可能在对抗性用户的能力上做出现实的假设，从而推动了比以前使用的模型更加精细的新信任模型的开发。例如，假设多少比例的客户可能会受到对手的损害？攻击者是否有可能同时攻击服务器和大量设备，或者通常假设攻击者只能攻击一个或另一个设备就足够了吗？在联合学习中，服务器通常由众所周知的实体（例如长期存在的组织）操作。可否利用它来建立一个信任模型，在该模型中，服务器的行为是可信的但经过验证的，即，其中不会阻止服务器偏离所需协议，但是如果服务器确实偏离了协议，则很有可能被检测到（从而破坏信任，声誉，以及托管组织的潜在财务或法律地位）？</p>
<h3 id="4-4-3-在训练子模型时保护隐私"><a href="#4-4-3-在训练子模型时保护隐私" class="headerlink" title="4.4.3 在训练子模型时保护隐私"></a>4.4.3 在训练子模型时保护隐私</h3><p>&emsp;&emsp;有许多这种情况出现，就是其中每个客户端可能具有仅与正在训练的完整模型的相对较小部分有关的本地数据。 例如，对大型清单进行操作的模型，包括自然语言模型（对单词的清单进行操作）或内容排名模型（对内容的清单进行操作）），经常使用嵌入查找表作为神经网络的第一层。 通常，客户仅与极少量的清单项进行交互，并且在许多训练策略下，客户数据支持更新的唯一嵌入向量是与客户交互的物料相对应的嵌入向量。<br>&emsp;&emsp;再举一个例子，多任务学习策略可能是实现个性化的有效方法，但可能会产生复合模型，其中任何特定的客户端仅使用与该客户端的用户群相关联的子模型，如3.3.2节所述。<br>&emsp;&emsp;如果不关心沟通效率，那么子模型训练就像标准的联合学习：客户将在参与时下载完整模型，使用与他们相关的子模型，然后提交涵盖整个模型参数的集合的模型更新（即，除了与相关子模型相对应的条目中，其余所有地方都为零）。 但是，在部署联合学习时，通信效率通常是一个重要问题，这引发了我们是否可以实现通信效率高的子模型训练的问题。<br>&emsp;&emsp;如果没有隐私敏感信息进入客户将更新哪个特定子模型的选择，那么可能会有直接的方法来适应联合学习以实现有效的通信子模型训练。 例如，一个人可以运行多个联合学习过程的副本，每个子模型一个,或者并行（例如，客户端基于他们希望更新的子模型，选择合适的联合学习实例参与），或者按顺序（例如， 对于每轮FL，服务器都会发布要更新哪个子模型的信息），或者两者混合。 但是，尽管此方法具有较高的通信效率，但服务器可以观察到客户端选择的子模型。<br>&emsp;&emsp;能否在保持客户的子模型选择私密性的同时，实现沟通效率高的子模型联合学习？ 一种有前景的方法是将PIR用于私有子模型下载，同时使用针对稀疏向量优化的安全聚合变体来聚合模型更新[94，216，310]。<br>&emsp;&emsp;该领域中的开放问题包括表征与实际感兴趣的子模型训练问题相关联的稀疏机制，以及开发在这些稀疏机制中通信效率高的稀疏安全聚合技术。 与仅简单地使每种技术独立运行（例如，通过在两个功能的实现之间分担一些消耗）相比，是否可以共同优化私有信息检索（PIR）和安全聚合以实现更好的通信效率，这也是一个悬而未决的问题。<br>&emsp;&emsp;某些形式的局部和分布式差分隐私在这里也带来了挑战，因为通常会将噪声添加到向量的所有元素中，甚至是零。 结果，在每个客户端上添加此噪声将把原本稀疏的模型更新（即仅子模型上的非零）转换为密集的私有化模型更新（几乎在任何地方几乎都为非零）。 是否可以解决这种紧张关系是一个悬而未决的问题，即是否存在有意义的分布式差分隐私实例化，该实例化也保持了模型更新的稀疏性。<br><img src="/2022/09/06/advances-and-open-problems-in-federated-learning-yue-du-bi-ji/8.png" alt="图九：具有 $(\varepsilon,\delta)$-差分隐私的的多消息混合模型中的差分私有聚合协议的比较。参与方数目为n，$l$ 为整数参数。消息大小以位为单位。为便于阅读，我们假设 $\varepsilon \le O(1)$，并且渐近符号被抑制。"><br><img src="/2022/09/06/advances-and-open-problems-in-federated-learning-yue-du-bi-ji/9.png" alt="图十：在不同模型的DP中，对大小为B的域以及n个以上的用户进行频率估计时，预期最大误差的上限和下限。 边界固定的，正的隐私参数 $\varepsilon$ 和 $\delta$ 表示界限，并且渐近符号抑制因子 $\overline\Theta / \overline{O}/\overline\Omega$ 在B和n中为多对数。==每个用户的通信以发送的位数为单位。 在所有的上限中，该协议相对于用户是对称的，并且不需要公共随机性，引用的是我们所知道的第一个结果，它暗示了规定的界限。"></p>
<h2 id="4-5-用户感知（users’-perception）"><a href="#4-5-用户感知（users’-perception）" class="headerlink" title="4.5 用户感知（users’ perception）"></a>4.5 用户感知（users’ perception）</h2><p>&emsp;&emsp;联邦学习蕴含了数据收集和最小化的原则（focused data collection and minimization），并且可以减小许多由系统本身带来的隐私风险。然而，正如上文所说，搞清楚联邦学习本身提供或者不提供哪些保护措施、哪些技术可以用来抵御4.1节中的威胁模型是十分重要的。前几节重点关注在抵御精度威胁模型时，隐私的严格量化（rigorous quantification of privacy against precise threat models），这节重点关注用户体验（users’ perception）和需求的相关挑战。<br>&emsp;&emsp;以下是几个具有重要实用价值的待解决的问题。是否有办法可以让普通用户直观地了解联邦学习的优缺点。联邦学习的基础结构的哪些参数和功能可能足以（或不足）满足隐私和数据最小化要求？联邦学习可能会让用户误以为他的隐私没有问题了吗（Might federated learning give users a false sense of privacy?）？当用户更多地了解联邦学习在他的数据上的操作时，如何能使用户对他的数据隐私感到安全且保障隐私数据确实是安全的？不同的用户对隐私的评估是否一致呢？人们想要保护的非隐私的内容（facts）呢？了解这些可以让我们设计出更好的机制吗？有什么方法可以很好地模拟人们的隐私偏好，从而决定如何设置这些参数？如果不同技术的实用程序/隐私/安全属性不同，谁来决定使用哪种技术？只是服务提供商？还是用户？还是他们的操作系统？他们的政治管辖权？（ Their political jurisdiction?）是否有像“受保护的隐私（仅）” [230]这样的机制可以为大多数用户提供隐私保障，同时允许对社会优先事项（例如反恐）进行有针对性的监视？有没有一种方法可以让用户选择所需的隐私级别？<br>&emsp;&emsp;对于解决这些问题，似乎有两个重要的方向特别重要。</p>
<h3 id="4-5-1-了解特定分析任务的隐私需求"><a href="#4-5-1-了解特定分析任务的隐私需求" class="headerlink" title="4.5.1 了解特定分析任务的隐私需求"></a>4.5.1 了解特定分析任务的隐私需求</h3><p>&emsp;&emsp;FL的许多潜在应用涉及复杂的学习任务和来自用户的高维数据，这两者都可能导致需要大量噪声来保护差分隐私。但是，如果用户不太介意受保护的数据不受各种干扰，则可以放宽隐私约束，允许添加少量的噪声。例如，考虑由智能家居恒温器生成的数据，使得设备在房屋空置时关闭，而在居民返回家园时打开。根据此数据，观察者将推断出居民晚上什么时候回家，这可能是高度敏感的。但是，较粗略的信息结构只能显示居民是否在凌晨2-4点之间处于睡眠状态，这可以说不那么敏感。<br>&emsp;&emsp;这种方法在Pufferfish隐私框架中规范化地提出[235]，该框架允许分析人员指定一类受保护的推断（predicates ），必须在保证差异性隐私的前提下进行学习，而所有其他推断（predicates ）也可以在没有差异性隐私的情况下进行学习。为了使这种方法在实践中提供令人满意的隐私保证，分析人员必须了解用户对其特定分析任务和数据收集程序的隐私需求。可以修改联邦学习框架，以允许各个用户指定他们允许和不允许的推断（inferences） 。这些数据限制可以在设备上进行处理，在联邦学习模型更新步骤中仅与服务器共享“允许”信息，也可以在收集数据后将其作为聚合步骤的一部分。应该做进一步的工作来开发将这种用户偏好纳入联邦学习模型的技术工具，并开发对于用户有意义地偏好的技术（meaningful preference elicitation from users.）。</p>
<h3 id="4-5-2-行为研究以激发隐私首选项"><a href="#4-5-2-行为研究以激发隐私首选项" class="headerlink" title="4.5.2 行为研究以激发隐私首选项"></a>4.5.2 行为研究以激发隐私首选项</h3><p>&emsp;&emsp;任何要求个人用户指定自己的隐私标准的隐私保护方法也应包括行为或现场研究，以确保用户可以表达知情的偏好。任何可以获得隐私的方法都需要用户自己来指定隐私保护标准，而且这些方法需要包括行为和领域内的研究，这样就可以保证用户充分地表达自己的偏好（ informed preferences）。这应同时包括教育成分（educational component）和偏好测量（preference measurement）。教育部分应衡量并提高用户对所使用的隐私技术（例如第4.2节）和数据使用细节的理解（译者注：这里的说的“教育”估计是指用户使用引导）。对于涉及联邦学习的应用程序，还应包括联邦学习的说明以及将要发送到服务器的数据是什么。一旦研究的过程说明（educational component）证实了典型用户可以很好地理解学习过程所提供的隐私保护，那么研究者就可以开始偏好激发了（preference elicitation）。这可以在行为实验室，大规模现场实验或专题研究小组中发生。这里应当谨慎，以确保提供有关其偏好数据的用户足够了解情况，以提供高质量的数据，并能够代表目标人群。尽管行为经济学和实验经济学的丰富领域早已表明，人们在公共和私人条件下的行为有所不同（也就是说，其他人是否观察到他们的选择），但在引起人们对差异性隐私的偏好方面所做的行为工作却很少。[ 126，10]。扩展这一工作范围将是迈向未来广泛实施隐私联邦学习的关键一步。在这里，教育部分（educational component)的结果将对确保研究参与者充分了解情况并理解他们面临的决定很有用。这是这些实验的重要参与者，这些实验应遵循道德原则，并且不涉及任何欺骗行为。</p>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">xbwcj</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="http://xbwcj.github.io/2022/09/06/advances-and-open-problems-in-federated-learning-yue-du-bi-ji/">http://xbwcj.github.io/2022/09/06/advances-and-open-problems-in-federated-learning-yue-du-bi-ji/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">xbwcj</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/">
                                    <span class="chip bg-color">联邦学习</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    
        <style>
    .valine-card {
        margin: 1.5rem auto;
    }

    .valine-card .card-content {
        padding: 20px 20px 5px 20px;
    }

    #vcomments textarea {
        box-sizing: border-box;
        background: url("/medias/comment_bg.png") 100% 100% no-repeat;
    }

    #vcomments p {
        margin: 2px 2px 10px;
        font-size: 1.05rem;
        line-height: 1.78rem;
    }

    #vcomments blockquote p {
        text-indent: 0.2rem;
    }

    #vcomments a {
        padding: 0 2px;
        color: #4cbf30;
        font-weight: 500;
        text-decoration: none;
    }

    #vcomments img {
        max-width: 100%;
        height: auto;
        cursor: pointer;
    }

    #vcomments ol li {
        list-style-type: decimal;
    }

    #vcomments ol,
    ul {
        display: block;
        padding-left: 2em;
        word-spacing: 0.05rem;
    }

    #vcomments ul li,
    ol li {
        display: list-item;
        line-height: 1.8rem;
        font-size: 1rem;
    }

    #vcomments ul li {
        list-style-type: disc;
    }

    #vcomments ul ul li {
        list-style-type: circle;
    }

    #vcomments table, th, td {
        padding: 12px 13px;
        border: 1px solid #dfe2e5;
    }

    #vcomments table, th, td {
        border: 0;
    }

    table tr:nth-child(2n), thead {
        background-color: #fafafa;
    }

    #vcomments table th {
        background-color: #f2f2f2;
        min-width: 80px;
    }

    #vcomments table td {
        min-width: 80px;
    }

    #vcomments h1 {
        font-size: 1.85rem;
        font-weight: bold;
        line-height: 2.2rem;
    }

    #vcomments h2 {
        font-size: 1.65rem;
        font-weight: bold;
        line-height: 1.9rem;
    }

    #vcomments h3 {
        font-size: 1.45rem;
        font-weight: bold;
        line-height: 1.7rem;
    }

    #vcomments h4 {
        font-size: 1.25rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    #vcomments h5 {
        font-size: 1.1rem;
        font-weight: bold;
        line-height: 1.4rem;
    }

    #vcomments h6 {
        font-size: 1rem;
        line-height: 1.3rem;
    }

    #vcomments p {
        font-size: 1rem;
        line-height: 1.5rem;
    }

    #vcomments hr {
        margin: 12px 0;
        border: 0;
        border-top: 1px solid #ccc;
    }

    #vcomments blockquote {
        margin: 15px 0;
        border-left: 5px solid #42b983;
        padding: 1rem 0.8rem 0.3rem 0.8rem;
        color: #666;
        background-color: rgba(66, 185, 131, .1);
    }

    #vcomments pre {
        font-family: monospace, monospace;
        padding: 1.2em;
        margin: .5em 0;
        background: #272822;
        overflow: auto;
        border-radius: 0.3em;
        tab-size: 4;
    }

    #vcomments code {
        font-family: monospace, monospace;
        padding: 1px 3px;
        font-size: 0.92rem;
        color: #e96900;
        background-color: #f8f8f8;
        border-radius: 2px;
    }

    #vcomments pre code {
        font-family: monospace, monospace;
        padding: 0;
        color: #e8eaf6;
        background-color: #272822;
    }

    #vcomments pre[class*="language-"] {
        padding: 1.2em;
        margin: .5em 0;
    }

    #vcomments code[class*="language-"],
    pre[class*="language-"] {
        color: #e8eaf6;
    }

    #vcomments [type="checkbox"]:not(:checked), [type="checkbox"]:checked {
        position: inherit;
        margin-left: -1.3rem;
        margin-right: 0.4rem;
        margin-top: -1px;
        vertical-align: middle;
        left: unset;
        visibility: visible;
    }

    #vcomments b,
    strong {
        font-weight: bold;
    }

    #vcomments dfn {
        font-style: italic;
    }

    #vcomments small {
        font-size: 85%;
    }

    #vcomments cite {
        font-style: normal;
    }

    #vcomments mark {
        background-color: #fcf8e3;
        padding: .2em;
    }

    #vcomments table, th, td {
        padding: 12px 13px;
        border: 1px solid #dfe2e5;
    }

    table tr:nth-child(2n), thead {
        background-color: #fafafa;
    }

    #vcomments table th {
        background-color: #f2f2f2;
        min-width: 80px;
    }

    #vcomments table td {
        min-width: 80px;
    }

    #vcomments [type="checkbox"]:not(:checked), [type="checkbox"]:checked {
        position: inherit;
        margin-left: -1.3rem;
        margin-right: 0.4rem;
        margin-top: -1px;
        vertical-align: middle;
        left: unset;
        visibility: visible;
    }
</style>

<div class="card valine-card" data-aos="fade-up">
    <div class="comment_headling" style="font-size: 20px; font-weight: 700; position: relative; padding-left: 20px; top: 15px; padding-bottom: 5px;">
        <i class="fas fa-comments fa-fw" aria-hidden="true"></i>
        <span>评论</span>
    </div>
    <div id="vcomments" class="card-content" style="display: grid">
    </div>
</div>

<script src="/libs/valine/av-min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/valine@1.4.16/dist/Valine.min.js"></script>
<script>
    new Valine({
        el: '#vcomments',
        appId: '3zej8rJ4jeuroIc4wbOGSRTn-gzGzoHsz',
        appKey: 'ybMabHX5zRIWyISjpqOxDcxk',
        notify: 'false' === 'true',
        verify: 'false' === 'true',
        visitor: 'true' === 'true',
        avatar: 'mm',
        pageSize: '10',
        lang: 'zh-cn',
        placeholder: 'just go go'
    });
</script>

<!--酷Q推送-->


    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2022/09/09/practical-secure-aggregation-for-federated-learning-on-user-held-data-yue-du-bi-ji/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/6.jpg" class="responsive-img" alt="《Practical Secure Aggregation for Federated Learning on User-Held Data》阅读笔记">
                        
                        <span class="card-title">《Practical Secure Aggregation for Federated Learning on User-Held Data》阅读笔记</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2022-09-09
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E7%A7%91%E7%A0%94%E5%AD%A6%E4%B9%A0/" class="post-category">
                                    科研学习
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/">
                        <span class="chip bg-color">联邦学习</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2022/09/06/hello-world/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/12.jpg" class="responsive-img" alt="Hello World">
                        
                        <span class="card-title">Hello World</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2022-09-06
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/hexo/" class="post-category">
                                    hexo
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/hexo-blog/">
                        <span class="chip bg-color">hexo blog</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\(', '\)']]}
    });
</script>



    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script>

    
    <div class="container row center-align" style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2020-2023</span>
            
            <span id="year">2020</span>
            <a href="https://github.com/xbwcj" target="_blank">xbwcj</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                class="white-color">178.9k</span>&nbsp;字
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;次
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;人
            </span>
            
            <br>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/xbwcj" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:1151506163@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=1151506163" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 1151506163" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>





    <a href="https://www.zhihu.com/people/shi-er-yue-yu-yi-yue" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/shi-er-yue-yu-yi-yue" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
